{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# v0.3 - Exp2 - AdaHessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/2 BASELINE, 42: 22.33, 0.4723"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.basics import *\n",
    "import seaborn as sns\n",
    "import sacrebleu\n",
    "from nlp import load_dataset\n",
    "\n",
    "from einops import rearrange\n",
    "import gc\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/morgan/AdaHessian\" target=\"_blank\">https://app.wandb.ai/morgan/AdaHessian</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/morgan/AdaHessian/runs/ri2ud90n\" target=\"_blank\">https://app.wandb.ai/morgan/AdaHessian/runs/ri2ud90n</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/morgan/AdaHessian/runs/ri2ud90n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.wandb_config import ConfigError\n",
    "\n",
    "wandb.init(project='AdaHessian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.callback.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/irish/parallel_corpora/paracrawl')\n",
    "fn = 'para_crawl_huggingface_clean_v02_20200723.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired t-test approach\n",
    "\n",
    "https://forums.fast.ai/t/how-to-do-statistical-test-to-show-significant-improvement/76038/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=42  # 1918, 139\n",
    "#seed=1918\n",
    "#seed=87\n",
    "\n",
    "def seed_everything(seed):\n",
    "    # Python\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    #pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    #numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # fastai\n",
    "    set_seed(seed)\n",
    "    \n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357399\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ga</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Among the French PIM , in 2013, it is only 9 islands that have been chiroptérologiques inventories .</td>\n",
       "      <td>I measc na PIM Fraince, i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Among the French PIM, in 2013, it is only 9 islands that have been chiroptérologiques inventories.</td>\n",
       "      <td>I measc na PIM Fraince , i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail .</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Among the French PIM, in 2013, it is only 9 islands that have been chiroptérologiques inventories.</td>\n",
       "      <td>I measc na PIM Fraince, i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As you can see, so get to show off the spacious shapes in 3D (red and blue).</td>\n",
       "      <td>Mar is féidir leat a fheiceáil, a fháil mar sin a thaispeáint as na cruthanna mhór i 3D (dearg agus gorm).</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Equation Solving – Traditional, simple</td>\n",
       "      <td>Ligningsløsning – Traidisiúnta, simplí</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     en  \\\n",
       "0  Among the French PIM , in 2013, it is only 9 islands that have been chiroptérologiques inventories .   \n",
       "1    Among the French PIM, in 2013, it is only 9 islands that have been chiroptérologiques inventories.   \n",
       "2    Among the French PIM, in 2013, it is only 9 islands that have been chiroptérologiques inventories.   \n",
       "3                          As you can see, so get to show off the spacious shapes in 3D (red and blue).   \n",
       "4                                                                Equation Solving – Traditional, simple   \n",
       "\n",
       "                                                                                                           ga  \\\n",
       "0                       I measc na PIM Fraince, i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail.   \n",
       "1                     I measc na PIM Fraince , i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail .   \n",
       "2                       I measc na PIM Fraince, i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail.   \n",
       "3  Mar is féidir leat a fheiceáil, a fháil mar sin a thaispeáint as na cruthanna mhór i 3D (dearg agus gorm).   \n",
       "4                                                                      Ligningsløsning – Traidisiúnta, simplí   \n",
       "\n",
       "   clean  \n",
       "0   True  \n",
       "1   True  \n",
       "2   True  \n",
       "3   True  \n",
       "4   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(path/fn)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAISE BUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data/irish/parallel_corpora/paracrawl')\n",
    "fn = 'para_crawl_huggingface_clean_v02_20200723.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    }
   ],
   "source": [
    "# ds_dict = load_dataset('csv', data_files=str(path/fn),\n",
    "#                   description='en-ga Paracrawl data from HuggingFace, clean for suspect translations',\n",
    "#                       download_mode='force_redownload', version='0.0.2')\n",
    "ds_dict = load_dataset('csv', data_files=str(path/fn),\n",
    "                  description='en-ga Paracrawl data from HuggingFace, clean for suspect translations',\n",
    "                    version='0.0.1')\n",
    "ds=ds_dict['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that were identified as noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357399\n",
      "355837\n"
     ]
    }
   ],
   "source": [
    "def is_clean(example): return example['clean']\n",
    "print(len(ds))\n",
    "ds = ds.filter(is_clean)\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "**Remove long texts to make things easier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['ga_len'] = df['ga'].str.split().str.len()\n",
    "# df['en_len'] = df['en'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sample lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(features: {'clean': Value(dtype='bool', id=None), 'en': Value(dtype='string', id=None), 'en_len': Value(dtype='int64', id=None), 'ga': Value(dtype='string', id=None), 'ga_len': Value(dtype='int64', id=None)}, num_rows: 355837)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lens(example, lang):\n",
    "    example[f'{lang}_len'] = len(example[lang].split())\n",
    "    return example\n",
    "\n",
    "ds = ds.map(partial(get_lens, lang='ga'))\n",
    "ds = ds.map(partial(get_lens, lang='en'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49.0, 47.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word count 90th percentile\n",
    "np.percentile([o for o in ds['ga_len']], 90), np.percentile([o for o in ds['en_len']], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.axes._subplots.AxesSubplot at 0x7f70f8309d90>, 18.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(ds['ga_len']), np.median(ds['ga_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.axes._subplots.AxesSubplot at 0x7f70e9f45e50>, 17.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(ds['en_len']), np.median(ds['en_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355837\n",
      "334244\n"
     ]
    }
   ],
   "source": [
    "def len_filter(example,col,l): \n",
    "    return example[col] <= l\n",
    "\n",
    "print(len(ds))\n",
    "ds = ds.filter(partial(len_filter, col='ga_len', l=60))\n",
    "ds = ds.filter(partial(len_filter, col='en_len', l=60))\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Removing {len(df.query(\"en_len > 60\"))} EN samples where len was > 60')\n",
    "# print(len(df))\n",
    "# df=df[~df.index.isin(df.query(\"en_len > 60\").index)]\n",
    "# print(len(df))\n",
    "      \n",
    "# print(f'Removing {len(df.query(\"ga_len > 60\"))} FR samples where len was > 60')\n",
    "# print(len(df))\n",
    "# df=df[~df.index.isin(df.query(\"ga_len > 60\").index)]\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.axes._subplots.AxesSubplot at 0x7f70e9dbe250>, 17.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXyV1b3v8c8v8zyHJISEMAQEQaYIOA84oO0pbY8DOHGuVGorp+3taNvb3tbXuffWnnNqeyqnFsVWrYqKtcWKx6PiXEHCPEMIQ0KAJJAZkhCy7h97Q9OYkA0k2UO+79crr+z9PGsnvwd2vllZz3rWY845REQkdIX5uwAREelbCnoRkRCnoBcRCXEKehGREKegFxEJcRH+LqCzjIwMV1BQ4O8yRESCypo1a6qdc5ld7Qu4oC8oKKC4uNjfZYiIBBUz29fdPg3diIiEOAW9iEiIU9CLiIQ4Bb2ISIhT0IuIhDgFvYhIiPMp6M1sppntMLMSM3uwi/3RZvaCd/8qMyvwbr/TzNZ3+Gg3s4m9ewgiInImPQa9mYUDC4GbgLHAHDMb26nZPKDGOTcSeAR4GMA596xzbqJzbiJwN7DXObe+Nw9ARETOzJce/VSgxDlX6pxrBZYAszq1mQU85X28FJhhZtapzRzg+fMpVkREzp4vV8bmAmUdnpcD07pr45xrM7M6IB2o7tDmdj79CwIAM5sPzAfIz8/3qXCB51bt/9S2O6bp309E/p4vPfrOPXOAzrelOmMbM5sGHHPObe7qGzjnFjnnipxzRZmZXS7VICIi58iXoC8H8jo8HwJUdNfGzCKAZOBoh/2z0bCNiIhf+BL0q4FCMxtmZlF4QntZpzbLgLnex7cAK5z3ZrRmFgbcimdsX0RE+lmPY/TeMfcFwBtAOPCkc26LmT0EFDvnlgGLgWfMrARPT352hy9xJVDunCvt/fJFRKQnPi1T7JxbDizvtO3HHR434+m1d/Xad4Hp516iiIicD10ZKyIS4hT0IiIhTkEvIhLiFPQiIiFOQS8iEuIU9CIiIU5BLyIS4hT0IiIhTkEvIhLiFPQiIiFOQS8iEuIU9CIiIU5BLyIS4hT0IiIhTkEvIhLiFPQiIiFOQS8iEuIU9CIiIU5BLyIS4hT0IiIhzqegN7OZZrbDzErM7MEu9keb2Qve/avMrKDDvovM7GMz22Jmm8wspvfKFxGRnvQY9GYWDiwEbgLGAnPMbGynZvOAGufcSOAR4GHvayOAPwD3O+cuBK4GTvRa9SIi0iNfevRTgRLnXKlzrhVYAszq1GYW8JT38VJghpkZcAOw0Tm3AcA5d8Q5d7J3ShcREV/4EvS5QFmH5+XebV22cc61AXVAOjAKcGb2hpmtNbPvnn/JIiJyNiJ8aGNdbHM+tokALgcuBo4Bb5vZGufc23/3YrP5wHyA/Px8H0oSERFf+dKjLwfyOjwfAlR018Y7Lp8MHPVuf885V+2cOwYsByZ3/gbOuUXOuSLnXFFmZubZH4WIiHTLl6BfDRSa2TAziwJmA8s6tVkGzPU+vgVY4ZxzwBvARWYW5/0FcBWwtXdKFxERX/Q4dOOcazOzBXhCOxx40jm3xcweAoqdc8uAxcAzZlaCpyc/2/vaGjP7BZ5fFg5Y7px7rY+ORUREuuDLGD3OueV4hl06bvtxh8fNwK3dvPYPeKZYioiIH+jKWBGREKegFxEJcQp6EZEQp6AXEQlxCnoRkRCnoBcRCXEKehGREKegFxEJcQp6EZEQp6AXEQlxCnoRkRCnoBcRCXEKehGREKegFxEJcQp6EZEQp6AXEQlxCnoRkRCnoBcRCXEKehGREKegFxEJcQp6EZEQ51PQm9lMM9thZiVm9mAX+6PN7AXv/lVmVuDdXmBmx81svffjsd4tX0REehLRUwMzCwcWAtcD5cBqM1vmnNvaodk8oMY5N9LMZgMPA7d79+12zk3s5bpFRMRHvvTopwIlzrlS51wrsASY1anNLOAp7+OlwAwzs94rU0REzpUvQZ8LlHV4Xu7d1mUb51wbUAeke/cNM7N1ZvaemV3R1Tcws/lmVmxmxVVVVWd1ACIicma+BH1XPXPnY5uDQL5zbhLwTeA5M0v6VEPnFjnnipxzRZmZmT6UJCIivvIl6MuBvA7PhwAV3bUxswggGTjqnGtxzh0BcM6tAXYDo863aBER8Z0vQb8aKDSzYWYWBcwGlnVqswyY6318C7DCOefMLNN7MhczGw4UAqW9U7qIiPiix1k3zrk2M1sAvAGEA08657aY2UNAsXNuGbAYeMbMSoCjeH4ZAFwJPGRmbcBJ4H7n3NG+OBAREelaj0EP4JxbDizvtO3HHR43A7d28bqXgZfPs8Z+89yq/V1uv2Nafj9XIiLSe3RlrIhIiFPQi4iEOAW9iEiIU9CLiIQ4Bb2ISIhT0IuIhDgFvYhIiFPQi4iEOAW9iEiIU9CLiIQ4Bb2ISIhT0IuIhDgFvYhIiFPQi4iEOAW9iEiIU9CLiIQ4Bb2ISIhT0IuIhDgFvYhIiFPQi4iEOAW9iEiI8ynozWymme0wsxIze7CL/dFm9oJ3/yozK+i0P9/MGs3s271TtoiI+CqipwZmFg4sBK4HyoHVZrbMObe1Q7N5QI1zbqSZzQYeBm7vsP8R4PXeK1uC0XOr9n9q2x3T8v1QicjA0mPQA1OBEudcKYCZLQFmAR2DfhbwE+/jpcCjZmbOOWdmnwdKgaZeqzoI1B5rZX1ZLfXNbRxraSMqIoz0hGgyE6IZmh5HfLQv//QiIufPl7TJBco6PC8HpnXXxjnXZmZ1QLqZHQe+h+evgW6HbcxsPjAfID8/eHt47e2O51fv58XVZWw8UIdz3bfNTIxmWHo8Q9PjKMiIpyA9nvy0ONISokiOjSQ+Khwz67/iRSRk+RL0XaVN5wjrrs1PgUecc41nCi3n3CJgEUBRUdEZ4jFw7TzcwIMvb2Tt/lrG5ybztWsLuWREOhkJ0cRFhdPS1s6RxhYO1Tez78gx9lY3se/IMd7bWcVLa8o/9fUiwozk2EjPR1zk6ccpsZHkpMQyPjeZ460niY0K98PRikgw8SXoy4G8Ds+HABXdtCk3swggGTiKp+d/i5n9HEgB2s2s2Tn36HlXHkDW7KvhjsdXEhcVzi9um8AXJuV22RsflhHf5eubWtrYd+QY+48eo+54K3XHT1B77ITn8/ET1B8/wdGmVkqrmqg77tkOnt+uo7MTubggjdHZiYTpLwAR6YIvQb8aKDSzYcABYDZwR6c2y4C5wMfALcAK55wDrjjVwMx+AjSGWsiXHT3G/KeLyU6OYen9l5KZGH3WXyM+OoKxg5MYOzjJp/Y1Ta1srqjj8ff3sG5/DdsP7SMnOYYvTMo96+8tIqGvx6D3jrkvAN4AwoEnnXNbzOwhoNg5twxYDDxjZiV4evKz+7LoQNHQfIJ5T63mxMl2Fs+9+JxC/lykxkdxRWEmZUePc/3YLDYfqGP55oP85t3dnHSO79wwmohwXSIhIh4+Tf1wzi0Hlnfa9uMOj5uBW3v4Gj85h/oC2r//9052VzXx9L1TGTkowS81hIcZE/JSGJWVyOubD/Lb90rZcaiBR++YTIJm9ogIujL2nFXUHue5Vfu5dcoQLhuZ4e9yiI0K54uTh/B/vzCeD3ZVc+tjH3O4vtnfZYlIAFDQn6NH3ykB4J9nFPq5kr93x7R8nvyni9l/pInZi1Yq7EVEQX8u9h85xoury5g9NY/clFh/l/MpV43K5Ol5U6msb2b2opUcqlPYiwxkCvpz8B8rdhEeZjxwzUh/l9KtKUPTeHreVKoaWpjzuMJeZCBT0J+l+uYTLNtQwW1FeWQlxfi7nDOaMjSNp+71hP3sRR8r7EUGKAX9WXpzy2Fa29r5wuTgmLM+ZWgqT907lerGVmYv+piDdcf9XZKI9DPNvztLr26sIDcllkl5KV3uD8QVGk+F/dwnP2H2opUsmT+dnOTAO7cgIn1DQX8Wjja18uGuar50xXCe/6Ss5xd4BUL4TxmaytPzpjJ3sSfsn79vOoMD8ESyiPQ+Bf1ZeH3zQdraHZ+bMJj1ZbXn9bW6Cn/o+hdAd23P1uR8T9jfs/gT7nh8JS98+ZKAP88gIudPQX8WXt1QwYjMeMbkJJ530Hent0K9O5PyU/n9vVO5Z/Gq02GfkdA/SzeIiH/oZKyPDtc3s2rPUf5hwuCgXyd+ytBUnvyni6mobeauJ1ZRd+yEv0sSkT6koPfBc6v28/P/2oFz0N7e973u/jBteDqP31NEaVUTX3p6Nc0nTvq7JBHpIwp6H+2pbiQuKpxBSaEzzHF5YQaP3D6R4n01LHhuLW0n2/1dkoj0AQW9j0qrmxiWER9yN/f4zEU5PPS5C3lrWyX/e9kW3JnufygiQUknY31Q09RK7bETXBEAq1T2hbsvKeBAbTOPvbeb4ZkJzLt8mL9LEpFepKD3QWl1EwDDMv2z5nx/+O6No9lb3cS/vLaVgvQ4ZozJ8ndJItJLNHTjg9Pj8/10Byl/CAszHrl9IuMGJ/P1JevZXdXo75JEpJeoR++DYBqfP5sLsTqLjQrnt3dP4bO//pD7n1nDnx64jHjdpUok6OmnuAehMj7v6zIMg1Ni+fWcSdy9eBXffXkjj86ZFPTXDYgMdBq66cFAGJ/v7LKRGXznxgt4beNBFn+4x9/liMh58inozWymme0wsxIze7CL/dFm9oJ3/yozK/Bun2pm670fG8zsC71bft/bW90U8uPzXbn/quHceGEW/+/17awsPeLvckTkPPQY9GYWDiwEbgLGAnPMbGynZvOAGufcSOAR4GHv9s1AkXNuIjAT+K2ZBdVw0YHa4wxJjQ2K8fneZGb8260TGJoex4Ln1uqmJSJBzJce/VSgxDlX6pxrBZYAszq1mQU85X28FJhhZuacO+aca/NujwGC6mqcEyfbqWxoZvAAXbs9MSaS3941hWOtJ/nqs2s4oStnRYKSL0GfC3RcfL3cu63LNt5grwPSAcxsmpltATYB93cI/tPMbL6ZFZtZcVVV1dkfRR85XN9Mu2NAr9temJXIw/94EWv31/Kz17f7uxwROQe+DKN0NWbRuWfebRvn3CrgQjMbAzxlZq875/5uHMA5twhYBFBUVBQwvf6KWk+ZoRr0vk7F/IcJg1mzr4bFH+5hytBUbh6f0x/liUgv8aVHXw7kdXg+BKjoro13DD4ZONqxgXNuG9AEjDvXYvtbRd1xYiLDSI2L9HcpfveDm8cwMS+F7y7dSKkuphIJKr4E/Wqg0MyGmVkUMBtY1qnNMmCu9/EtwArnnPO+JgLAzIYCo4G9vVJ5P6ioPU5OcqzmkQNREWEsvHMykeHGV/6wluOtWtZYJFj0GPTeMfUFwBvANuBF59wWM3vIzD7nbbYYSDezEuCbwKkpmJcDG8xsPfAK8FXnXHVvH0RfONnuOFTXTG6IDtuci9yUWH45exI7Kxv44Z82aaVLkSDh01RH59xyYHmnbT/u8LgZuLWL1z0DPHOeNfpFdWMLbe2OnGTdU7Wjq0Zl8rVrC/nV27uYlJfC3ZcU+LskEelBUM1p708VtceB0D0ReyY9LZfwtRmFbDpQx09f3cqIQQlcOiK4l4cQCXVaAqEbFbXHiQw3MgfYFbG+CA8zfjV7IgUZ8Tzw7Fr2Hznm75JE5AwU9N2oqGsmOylmwF0R66vEmEieuKeIdgf3PV1MY8unLo8QkQChoO+Cc46DdccH5LDN2SjIiGfhHZMpqWrkG0vW096uk7MigUhB34X65jaaT7STlaQTsT25vDCDH31mDG9tO8wv3tzp73JEpAs6GduFqoYWAI3P+2jupQVsP9TAo++UMCQ1ltlTe77JiYj0HwV9F6obPUGfkaCgP+VMyyWYGQ/NGsfBumZ+8MomkmMjuUnLJIgEDA3ddKG6sYWo8DCSYvR70FdREWE8dtcUJuWn8vUl6/lwV1BcFycyICjou1Dd2EJGQpSWPjhLsVHhPDn3YoZnxjP/mWLW7a/xd0kigoK+S9WNrWRofP6cJMdF8vS9U8lMjOaffreanYcb/F2SyICnoO+k7WQ7NU2tGp8/D4OSYvjDvGlER4Rx1xOr2K3VLkX8SoPQnRxpasWhE7G+6m65hLy0OJ790jTmPL6S23+7kufvm+aH6kQE1KP/lL/NuInycyXBrzArkSXzp2MGcx5fyaF63XdWxB/Uo++kurEVUI++t4wc5An7OYtW8sQHpcy7fBg5QXwP3p4WfBMJROrRd1Ld0EJiTAQxkeH+LiVkjMhM4IUvX0JEmPHEB3tOrwwqIv1DQd9JVWOLevN9YFhGPPddMZyoiDAWf7iHAzUKe5H+oqDvpFpB32fSE6K574rhREeGsfijUsqOanljkf6gMfoOjrW2caz1pE7EnqfulksASIuP4r4rhvPEB6U8+dEerhqdyfTh6f1YncjAox59B6dOxGaqR9+nUuM8YZ8UG8k9T37C65sO+rskkZCmoO+gukGLmfWXlLgovnzFcMYNTuKrz63liQ9KdbNxkT6ioO+gqrGFMIPUeA3d9Ie46Aie/dJ0bhibxb+8to1vvbSB5hMn/V2WSMjxKejNbKaZ7TCzEjN7sIv90Wb2gnf/KjMr8G6/3szWmNkm7+dre7f83lXd2EJafBThYVrMrL/ERoXzmzun8I3rCvnj2gPc9tuP2Vvd5O+yREJKj0FvZuHAQuAmYCwwx8zGdmo2D6hxzo0EHgEe9m6vBv7BOTcemAs801uF9wXNuPGPsDDjG9eNYtHdU9h35Bif+Y8PeHlNuYZyRHqJLz36qUCJc67UOdcKLAFmdWozC3jK+3gpMMPMzDm3zjlX4d2+BYgxs4BM0vZ2x5HGVp2I9aMbLszm9a9fwYW5yXzrpQ3Mf2YNh+q0bILI+fIl6HOBsg7Py73bumzjnGsD6oDOc+b+EVjnnGvp/A3MbL6ZFZtZcVVVla+196oDtcdpa3fq0fvZ4JRYnr9vOj+4+QI+2FXF9b94j2dX7dONx0XOgy9B39WAdeefujO2MbML8QznfLmrb+CcW+ScK3LOFWVmZvpQUu/b4x0X1jr0/hceZsy/cgRvfONKxg9J5oevbGb24ysp1XLHIufEl6AvB/I6PB8CVHTXxswigGTgqPf5EOAV4B7n3O7zLbivnAoRXSwVOIamx/Psl6bx83+8iO0H65n5qw/45Vs7NTNH5Cz5EvSrgUIzG2ZmUcBsYFmnNsvwnGwFuAVY4ZxzZpYCvAZ83zn3UW8V3RdKq5uIjggjIVoXCwcSM+O2i/N461tXceOF2fzyrV3M/OX7fLDLP0N8IsGox6D3jrkvAN4AtgEvOue2mNlDZvY5b7PFQLqZlQDfBE5NwVwAjAR+ZGbrvR+Dev0oesGe6iYyEqJ1n9gANSgxhl/PmcQz86ZiZty9+BMeeG4th7XGvUiPLNCmsBUVFbni4uJ+/76X/WwFmYnR3FaU13Nj6VM9re/efOIki94v5dF3SogKD+Ob14/inkuGEhHe99f/aT16CVRmtsY5V9TVPl0Ziyc4DtQe1/h8kIiJDOdrMwp5839eyZShqTz0l63MWvgR6/bX+Ls0kYCkAWk6zLjR1MqA0N3ql517zkPT4/n9/7iY1zcf4qevbuGLv/krc6bm870bLyA5LrI/ShUJCurRo6APZmbGzeNzePtbV3PvZcN4YXUZ1/77uyzVlbUipyno6Ti1UkEfrBKiI/jRZ8fy6oLLyU+P49svbeD2RSvZdbjB36WJ+J2GboDSqiZykmOIitDvvUDmy4nQsYOTePn+S3mhuIyfvb6dm371AV+6YjhfmzGSuCi93WVgUrLhmUM/LCPe32VILwkLM+ZMzWfFt67i85Nyeey93Vzzb57hHC2lIAPRgA965xylVY0Mz1TQh5r0hGj+7dYJvPyVS8hOjuXbL23gcws/ZGXpEX+XJtKvBvzfskebWqlvbmNYRoK/S5Fz4MsMnSlD03jlK5fy6sYKHn59O7MXreTGC7P45vWjGZ2d2F+livjNgA/6Uu+Mm+GZ8Rys1VWWoSoszJg1MZcbxmaz+MNSfvPubt7YcpgbL8ziK1ePZGJeir9LFOkzAz7o91R5gn5ERoKCfgCIjQpnwbWF3DltKL/7aA+/++te3thymIuGJHPX9KHMHJdNUozm4EtoGfBBv7u6kajwMHJTY/1divSinmbopMZH8c0bRnPflcP549oDPLNyH99dupH/9cpmrijM4ObxOVw3NovkWIW+BL8BH/SlVU0MTY/TfWIHqMSYSOZeWsA9lwxlXVktyzceZPmmg7y9vZLIcOOKwkxuHp/D9UEY+r5eYSyhb8AH/Z7qJoZrauWAZ2ZMzk9lcn4qP/zMGNaX1fLaxoO8vvkQK7yhf/nIDNLio7lwcBIxkeH+LlnEZwM66NtOtrPvSBPXjcnydynSD3zt4ZoZk/JTmdQh9JdvOsjyTYc4UFvFsg3GhCEpTB2WxpDUuP4oXeS8DOigP1B7nBMnnXr00q2Oof+Dm8fw8//aweq9R9lQXkvxvhpyU2IJM/jcxMG68lYC1oB+Z5ZW/W1qpQxcvq4xb2bkpcWRlxbHzeNzWFdWyyd7jvDgHzfxf17bxhcm53LntKGamy8BZ2AHvXcOvZY/kLMVExnOJcPTmT4sjdHZiTy7aj9LPinj6Y/3cXFBKndO80zV1Fi+BIKBHfRVjSTHRpIWrxuOyN/rbjy/MzOjqCCNooI0fvTZsby8ppxnV+3jGy+sJ/XVSG4tymPO1Hx1JsSvBnjQNzE8M173iZVekRYfxX1XDmfe5cP46+4jPLtqH4s/3MOi90u5fGQGd03P5/qx2ZrKK/1uQAf9nuomLh2Z7u8yJMSEhRmXF2ZweWEGh+ubeXF1Gc9/sp/7/7CW/LQ47r2sgFuL8oiPHtA/ftKPfFq90sxmmtkOMysxswe72B9tZi94968yswLv9nQze8fMGs3s0d4t/fw0tbRxqL6ZEZlazEz6TlZSDP88o5APvnctj901mczEaH7y6lYu/dkK/vWN7VTWa9kN6Xs9dinMLBxYCFwPlAOrzWyZc25rh2bzgBrn3Egzmw08DNwONAM/AsZ5PwLGHp2IlX4UHmbMHJfDzHE5rNl3lMff38N/vrubx9/fw6yJg7nvyuGMytJsHekbvvztOBUocc6VApjZEmAW0DHoZwE/8T5eCjxqZuacawI+NLORvVdy79hxyHOLuVFZ6tHL+fH1xC14pm1OGZrGlLvT2FvdxJMf7eHF4jJeWlPOVaMymX/lcC4dka7zRtKrfBm6yQXKOjwv927rso1zrg2oA3we/Daz+WZWbGbFVVVVvr7svGw/VE90RBgF6erRi38UZMTz0KxxfPzgDL59wyi2VNRz5xOruO4X7/Hoil2UHT3m7xIlRPgS9F11LTrfj82XNt1yzi1yzhU554oyMzN9fdl52XawgVFZiUSED/ibbImfpcZHseDaQj783jX8/JaLPHfG+u+dXPHzd7jtsY95btV+qhpa/F2mBDFfhm7KgbwOz4cAFd20KTezCCAZONorFfaR7YfquWb0IH+XIQPMmdbbiYkM57aiPG4ryqO85hh/Xl/BH9eW84NXNvGDVzYxPjeZywszmJyfyqT8FDISovu5eglWvgT9aqDQzIYBB4DZwB2d2iwD5gIfA7cAK5xzAXsX5qqGFqobWxmTk+TvUkS6NCQ1jgeuGclXrx7B1oP1vLO9knd2VPH4+6W0eW9wnp8Wx6T8FCblpTAhL4UxOVpVU7rWY9A759rMbAHwBhAOPOmc22JmDwHFzrllwGLgGTMrwdOTn33q9Wa2F0gCoszs88ANnWbs9LttB+sBuCBHsxwkMHS33o6ZceHgZC4cnMyCaws53nqSzRV1rNtfw7r9tawsPcKf13v+wI4MN8bkJDFhSAqXjEjneOtJYqMU/OLjBVPOueXA8k7bftzhcTNwazevLTiP+vrE9kOeoB+TrR69BK7uwv/igjQuLkg7ve1QXTPry2rZUF7LhrJaXlnnuWOWAXlpcRRmJTBqUCK5qbGEBfBsHt0ope8MyEvzth9sIDsphlStcSMhIDs5hpnJ2cwclw147rOwvqyWhe/sZldlAyu2VfL2tkriosIZOSiBmMgwrhyVqTH+AWRABv22Qw0atpGgdDZz9q8fm8X1Y7M41tLGrqpGdh5qYGdlI998cQMA43OTuXp0JlePzuSiISlEagZayBpwQd/a1k5JZQNXjeqfaZwi/hYXHcGEISlMGJJCu3NMzEvh3R2VvLujioXvlPDrFSXERoYzZWgqU4elMXVYGhPzUnRiN4QMuKAvrW7kxEnHGPXoZQAKM2NcbjLjcj0nd+uOneCj3dV8sucoq/Yc5ZG3duIcRIWHMSEvmanD0igamsaEvBQt5x3EBlzQbz/oWfpAUytFIDkukpvH53Dz+BwA6o6doHjf0dPB/9h7pZxs3w3A0PQ4JualMDEvhbE5SVyQnURyXKQ/yxcfDbig33awnqjwMC1mJgPWmW6dmBwXyYwxWcwYkwXAsdY2NpbXsb6slvWdpnMCZCfFMDo7kQuyExk5KIHCLM/nBC3BHFAG3P9G8b4axg5O0oknkQ7ONLVx+vB0pg//29JVh+qa2X6onh2HGthxqIHthxr4ePcRWk+2n26TmxLLqKwExg9JYWJeMhcN0ZW8/jSggr6h+QTry2r5ylUj/F2KSFDorvefnRzD1R2WEGk72U5ZzXF2HW5gV2UjJZWNbK2o572du/BeyEtuSuzpoZ+J+SmMG5ysC7r6yYAK+lWlRznZ7rhsZIa/SxEJWj1N8UyNizp9UdesiYPZUlHPxvLa0xd1vbbpIOBZo/+C7ETG5iQxKiuR8prjZCVFkxwbqWWae9mACvoPS6qJiQxj8tAUf5ciMiCcGs+Pi4rg0hEZXDoig8aWNoZnxHvG/ctqeWdHFS+tKT/9muiIMDITo8lIiCYzMZrUuEhGDEpgaHoc0RH6C+BcDKig/+vuai4uSNObRcSPEqIjuG5sFteNzTq9raaplf98dzeVDc0crm+hurGFPdVNrC+r5c2thwEIM8+SDqOyEhmTncgFOUlckJ3I0PR43XC9BwMm6Cvrm9l5uJEvTh7i71JEBryuhgKgpPEAAAiqSURBVH+GZcR/ajZca1s7RQWp7K5qZHdVE7u9V/iu2F7JSe/gf0xkGKOzErkgO4kLcryfsxO1xEkHAyboP9pdDcDlGp8XCRpREWFsLK8DPFM5s5NiuGxEBl+cnEtJZSPbDtaz/VAD2w/V8+a2w7xQ/Leb4WUkRFM4KME77dP7eVAiGQlRA+4cwMAJ+pIjpMRFMlYXSokEvZjI8NNX+J7inKOqsYXtBz3BX1LZyK7KRv607gANLW2n26XGRTJ2cBLjBidzYW4y4wYnUZAeT9hZDv+c6XqEQDMggt45x0cl1Vw6Iv2s/zNFJPD0NPMnITqSiXmpTMxLxTlHfXMblQ3NVNa3cLi+mYbmNn730d7Tc//jo8I96/7nen4BjMtNZkRmfMjcanRABP27O6s4WNfMd8Zk9dxYREKKmZEcG0lybCSFgzxrXN0xLZ8TJ9vZdbiRzRV1bDlQx+aKepZ8UsbxE3sBz+yfMTlJjOsQ/oVZCUE5mWNABP1v3t3N4OQYPnvRYH+XIiIBoPNfBKOzkxidncQXJjmqG1qoqDtORW0zB2qP8+d1Ffxhpad9ZLgxKivRs6xzmDFiUEJQXGUf8kG/Zl8Nn+w5yo8+O5aoiMD/DxER/wkzY1BSDIOSYpiY59nW7hw1Ta1U1DVTUXucitrj/HFtOS1t7URFhHFRbjLTh6czOCXWv8WfQcgH/WPv7SYlLpLZF+f5uxQRCUJhZqQnRJOeEM1478nftvZ2Squa2FRex4byWor31TA0LY7s5GiuGT0o4Gb1hHTQbztYz5tbD/P1GYXEazU9EeklEWFhjMpKZFRWIjePz2Ht/ho+2l3Nvb8vZkxOEg9cM4KbxuUEzIVcIZt+e6ubuPf3q0mNi2TupQX+LkdEQlRsVDiXjcxg+vB0YqPC+c93S1jw3DqGZ+7kK1eN4POTcv0+ju/TdzezmWa2w8xKzOzBLvZHm9kL3v2rzKygw77ve7fvMLMbe6/07pVUNnL7oo9paWvn2S9N151xRKTPhYcZt0wZwpv/8yoW3jGZ6IhwvrN0I1f/67v87qM9VNY3+622Hnv0ZhYOLASuB8qB1Wa2zDm3tUOzeUCNc26kmc0GHgZuN7OxwGzgQmAw8JaZjXLOneztA2k+cZI3tx7mj2vLeX9XNalxkTx/33RGZ+uWgSLSf8LDjM9clMPN47N5Z0clj64o4aevbuWnr25lYl4KU4amMjo7kWEZ8aTFR5ESG0l4mGEYkRFGXFTvD7T48hWnAiXOuVIAM1sCzAI6Bv0s4Cfex0uBR81zNmIWsMQ51wLsMbMS79f7uHfK/5tNB+r45+fXkZMcw31XDOeu6fkMSY3r7W8jIuITM+PaC7K4ZvQgdhxu4K2th3l7eyV/WLmPlrb2Ll/z2YtyePSOyb1eiy9BnwuUdXheDkzrro1zrs3M6oB07/aVnV6b2/kbmNl8YL73aaOZ7fCpeo8MoPrUk33eb/j9s/gCfvZ39QcpHUNgCPZjCPb6ufM8j2EhsPDOc/72Q7vb4UvQd3Xa2PnYxpfX4pxbBCzyoZZPMbNi51zRubw2EAR7/aBjCBTBfgzBXj8E7jH4cjK2HOg4CX0IUNFdGzOLAJKBoz6+VkRE+pAvQb8aKDSzYWYWhefk6rJObZYBc72PbwFWOOecd/ts76ycYUAh8EnvlC4iIr7ocejGO+a+AHgDCAeedM5tMbOHgGLn3DJgMfCM92TrUTy/DPC2exHPids24IE+mHFzTkM+ASTY6wcdQ6AI9mMI9vohQI/BPB1vEREJVVrlS0QkxCnoRURCXNAGfU/LMgQiM3vSzCrNbHOHbWlm9qaZ7fJ+TvVnjT0xszwze8fMtpnZFjP7und7UByHmcWY2SdmtsFb/0+924d5l+/Y5V3OI+DXzTCzcDNbZ2Z/8T4PqmMws71mtsnM1ptZsXdbULyPTjGzFDNbambbvT8TlwTiMQRl0HdYluEmYCwwx7vcQqD7PTCz07YHgbedc4XA297ngawN+JZzbgwwHXjA+28fLMfRAlzrnJsATARmmtl0PMt2POKtvwbPsh6B7uvAtg7Pg/EYrnHOTeww9zxY3ken/Ar4L+fcBcAEPP8fgXcMzrmg+wAuAd7o8Pz7wPf9XZePtRcAmzs83wHkeB/nADv8XeNZHs+f8ayDFHTHAcQBa/Fc6V0NRHi3/937KxA/8FyT8jZwLfAXPBcnBtsx7AUyOm0LmvcRkATswTupJZCPISh79HS9LMOnllYIElnOuYMA3s+D/FyPz7yrlE4CVhFEx+Ed8lgPVAJvAruBWudcm7dJMLyffgl8Fzi1aEo6wXcMDvhvM1vjXQYFguh9BAwHqoDfeYfQnjCzeALwGII16H1aWkH6jpklAC8D33DO1fu7nrPhnDvpnJuIp1c8FRjTVbP+rcp3ZvZZoNI5t6bj5i6aBuwxeF3mnJuMZwj2ATO70t8FnaUIYDLwG+fcJKCJQBim6UKwBn0oLa1w2MxyALyfK/1cT4/MLBJPyD/rnPujd3PQHYdzrhZ4F8+5hhTv8h0Q+O+ny4DPmdleYAme4ZtfElzHgHOuwvu5EngFzy/dYHoflQPlzrlV3udL8QR/wB1DsAa9L8syBIuOy0fMxTPmHbC8y08vBrY5537RYVdQHIeZZZpZivdxLHAdnhNo7+BZvgMCuH4A59z3nXNDnHMFeN77K5xzdxJEx2Bm8WaWeOoxcAOwmSB5HwE45w4BZWY22rtpBp5VAALvGPx9kuA8ToTcDOzEM776Q3/X42PNzwMHgRN4egPz8Iytvg3s8n5O83edPRzD5XiGBDYC670fNwfLcQAXAeu89W8GfuzdPhzPOkwlwEtAtL9r9fF4rgb+EmzH4K11g/djy6mf4WB5H3U4jolAsff99CcgNRCPQUsgiIiEuGAduhERER8p6EVEQpyCXkQkxCnoRURCnIJeRCTEKehFREKcgl5EJMT9fw+8zaZpAG5XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(ds['ga_len']), np.median(ds['ga_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lowercase everything**\n",
    "\n",
    "NOT Done as it is appliced in the rules below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['en'] = df['en'].apply(lambda x:x.lower())\n",
    "# df['ga'] = df['ga'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lowercase_all(example, lang):\n",
    "#     example[lang] = example[lang].lower()\n",
    "#     return example\n",
    "\n",
    "# ds = ds.map(partial(lowercase_all, lang='ga'))\n",
    "# ds = ds.map(partial(lowercase_all, lang='en'))\n",
    "# ds['ga'][400:420]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules used as part of tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function fastai2.text.core.fix_html(x)>,\n",
       " <function fastai2.text.core.replace_rep(t)>,\n",
       " <function fastai2.text.core.replace_wrep(t)>,\n",
       " <function fastai2.text.core.spec_add_spaces(t)>,\n",
       " <function fastai2.text.core.rm_useless_spaces(t)>,\n",
       " <function fastai2.text.core.replace_all_caps(t)>,\n",
       " <function fastai2.text.core.replace_maj(t)>,\n",
       " functools.partial(<function lowercase at 0x7f712b6be8c0>, add_eos=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_rules=defaults.text_proc_rules[:-1] + [partial(lowercase, add_eos=True)]\n",
    "proc_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load vocab to speed up data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>en</th>\n",
       "      <th>en_len</th>\n",
       "      <th>ga</th>\n",
       "      <th>ga_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Among the French PIM , in 2013, it is only 9 islands that have been chiroptérologiques inventories .</td>\n",
       "      <td>18</td>\n",
       "      <td>I measc na PIM Fraince, i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>Among the French PIM, in 2013, it is only 9 islands that have been chiroptérologiques inventories.</td>\n",
       "      <td>16</td>\n",
       "      <td>I measc na PIM Fraince , i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail .</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Among the French PIM, in 2013, it is only 9 islands that have been chiroptérologiques inventories.</td>\n",
       "      <td>16</td>\n",
       "      <td>I measc na PIM Fraince, i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail.</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>As you can see, so get to show off the spacious shapes in 3D (red and blue).</td>\n",
       "      <td>17</td>\n",
       "      <td>Mar is féidir leat a fheiceáil, a fháil mar sin a thaispeáint as na cruthanna mhór i 3D (dearg agus gorm).</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>Equation Solving – Traditional, simple</td>\n",
       "      <td>5</td>\n",
       "      <td>Ligningsløsning – Traidisiúnta, simplí</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clean  \\\n",
       "0   True   \n",
       "1   True   \n",
       "2   True   \n",
       "3   True   \n",
       "4   True   \n",
       "\n",
       "                                                                                                     en  \\\n",
       "0  Among the French PIM , in 2013, it is only 9 islands that have been chiroptérologiques inventories .   \n",
       "1    Among the French PIM, in 2013, it is only 9 islands that have been chiroptérologiques inventories.   \n",
       "2    Among the French PIM, in 2013, it is only 9 islands that have been chiroptérologiques inventories.   \n",
       "3                          As you can see, so get to show off the spacious shapes in 3D (red and blue).   \n",
       "4                                                                Equation Solving – Traditional, simple   \n",
       "\n",
       "   en_len  \\\n",
       "0      18   \n",
       "1      16   \n",
       "2      16   \n",
       "3      17   \n",
       "4       5   \n",
       "\n",
       "                                                                                                           ga  \\\n",
       "0                       I measc na PIM Fraince, i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail.   \n",
       "1                     I measc na PIM Fraince , i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail .   \n",
       "2                       I measc na PIM Fraince, i 2013, tá sé ach 9 oileáin a bhí chiroptérologiques fardail.   \n",
       "3  Mar is féidir leat a fheiceáil, a fháil mar sin a thaispeáint as na cruthanna mhór i 3D (dearg agus gorm).   \n",
       "4                                                                      Ligningsløsning – Traidisiúnta, simplí   \n",
       "\n",
       "   ga_len  \n",
       "0      16  \n",
       "1      18  \n",
       "2      16  \n",
       "3      21  \n",
       "4       4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=ds.data.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified Tokenizer.from_df to take a lang arguemnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(Transform):\n",
    "    \"Provides a consistent `Transform` interface to tokenizers operating on `DataFrame`s and folders\"\n",
    "    input_types = (str, list, L, tuple, Path)\n",
    "    def __init__(self, tok, rules=None, counter=None, lengths=None, mode=None, sep=' '):\n",
    "        store_attr(self, 'tok,counter,lengths,mode,sep')\n",
    "        self.rules = defaults.text_proc_rules if rules is None else rules\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(tokenize_df, keep=True)\n",
    "    def from_df(cls, text_cols, lang='en', tok=None, rules=None, sep=' ', **kwargs):\n",
    "        if tok is None: tok = WordTokenizer(lang=lang)   # <--- MODIFIED HERE\n",
    "        res = cls(tok, rules=rules, mode='df')\n",
    "        res.kwargs,res.train_setup = merge({'tok': tok}, kwargs),False\n",
    "        res.text_cols,res.sep = text_cols,sep\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(tokenize_folder, keep=True)\n",
    "    def from_folder(cls, path, tok=None, rules=None, **kwargs):\n",
    "        path = Path(path)\n",
    "        if tok is None: tok = WordTokenizer()\n",
    "        output_dir = tokenize_folder(path, tok=tok, rules=rules, **kwargs)\n",
    "        res = cls(tok, counter=(output_dir/fn_counter_pkl).load(),\n",
    "                  lengths=(output_dir/fn_lengths_pkl).load(), rules=rules, mode='folder')\n",
    "        res.path,res.output_dir = path,output_dir\n",
    "        return res\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if not self.mode == 'df' or not isinstance(dsets.items, pd.DataFrame): return\n",
    "        dsets.items,count = tokenize_df(dsets.items, self.text_cols, rules=self.rules, **self.kwargs)\n",
    "        if self.counter is None: self.counter = count\n",
    "        return dsets\n",
    "\n",
    "    def encodes(self, o:Path):\n",
    "        if self.mode=='folder' and str(o).startswith(str(self.path)):\n",
    "            tok = self.output_dir/o.relative_to(self.path)\n",
    "            return L(tok.read().split(' '))\n",
    "        else: return self._tokenize1(o.read())\n",
    "\n",
    "    def encodes(self, o:str): return self._tokenize1(o)\n",
    "    def _tokenize1(self, o): return first(self.tok([compose(*self.rules)(o)]))\n",
    "\n",
    "    def get_lengths(self, items):\n",
    "        if self.lengths is None: return None\n",
    "        if self.mode == 'df':\n",
    "            if isinstance(items, pd.DataFrame) and 'text_lengths' in items.columns: return items['text_length'].values\n",
    "        if self.mode == 'folder':\n",
    "            try:\n",
    "                res = [self.lengths[str(Path(i).relative_to(self.path))] for i in items]\n",
    "                if len(res) == len(items): return res\n",
    "            except: return None\n",
    "\n",
    "    def decodes(self, o): return TitledStr(self.sep.join(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "# at 30k tokens per vocab sometimes this works, sometimes it doesn't\n",
    "\n",
    "# Couldnt process 30k tokens until I added the 'hi' below, it was getting stuck at 94.87%, no idea why\n",
    "@Numericalize\n",
    "def encodes(self, o): \n",
    "    print('hi')\n",
    "    return TensorText(tensor([self.o2i  [o_] for o_ in o]))\n",
    "\n",
    "class floatify_tfm(Transform):\n",
    "    def encodes(self,o): return o.float()\n",
    "    def decodes(self,o): return o.long()\n",
    "\n",
    "max_vocab=30000\n",
    "#splits = ColSplitter()(df) \n",
    "splits = RandomSplitter(valid_pct=0.2, seed=42)(df)\n",
    "\n",
    "tfms = [[Tokenizer.from_df(text_cols='en' , rules=proc_rules), attrgetter(\"text\"), Numericalize(max_vocab=max_vocab)], \n",
    "       [Tokenizer.from_df(text_cols='ga', lang='ga', rules=proc_rules), attrgetter(\"text\"), Numericalize(max_vocab=max_vocab)]]\n",
    "\n",
    "dl = partial(SortedDL, shuffle=True, res=df.ga_len.values)\n",
    "\n",
    "dsets = Datasets(df, tfms, splits=splits, dl_type=dl)\n",
    "\n",
    "# remove the print from Numericalize\n",
    "@Numericalize\n",
    "def encodes(self, o): return TensorText(tensor([self.o2i  [o_] for o_ in o]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_vocab=[]\n",
    "# ga_vocab=[]\n",
    "# with open(f'paracrawl_vocab_en_exp{exp}.csv', newline='') as csvfile:\n",
    "#     v_reader = csv.reader(csvfile, delimiter=',')\n",
    "#     for row in v_reader:\n",
    "#         en_vocab.append(row[0])\n",
    "        \n",
    "# with open(f'paracrawl_vocab_ga_exp{exp}.csv', newline='') as csvfile:\n",
    "#     v_reader = csv.reader(csvfile, delimiter=',')\n",
    "#     for row in v_reader:\n",
    "#         ga_vocab.append(row[0])\n",
    "        \n",
    "# len(en_vocab), len(ga_vocab), en_vocab[:10], ga_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,\n",
       " ((#800) [326,273,176,961,727,190,701,714,373,314...],\n",
       "  (#200) [542,618,816,68,94,215,60,585,942,165...]),\n",
       " 24,\n",
       " 23,\n",
       " (TensorText([  2,   8, 478,   9,   8, 381,   7, 479,  13,  16, 549,  13,  41,  29,\n",
       "          227, 107, 862,  35,  56,  66, 863, 864,  15,   3]),\n",
       "  TensorText([  2,  18, 510,  15,   7, 511,   8, 351,  10,  18, 581,  10,  65,  39,\n",
       "           75, 115, 891,   9, 105, 892, 893,  14,   3])))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsets), splits, len(dsets[2][0]), len(dsets[2][1]), dsets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos ( 1 ) xxmaj subject to section 131 of the xxmaj united xxmaj states xxmaj internal xxmaj revenue xxmaj code as in effect on the day on which this xxmaj convention shall have come into effect , xxmaj irish tax shall be allowed as a credit against xxmaj united xxmaj states tax . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 1 ) xxmaj faoi réir alt 131 de xxmaj chód xxmaj ioncaim xxmaj intíre na xxmaj stát xxmaj aontaithe mar a bheidh éifeacht aige an lá a bheidh an xxmaj coinbhinsiún seo tar éis teacht in éifeacht , lamhálfar cáin éireannach mar chreidmheas i gcoinne cáin na xxmaj stát xxmaj aontaithe . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos \" i xxunk xxunk that my xxmaj department has been able to support this initiative and enable two xxunk national institutions to co - operate together to produce this xxunk . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos \" tá an - xxunk xxunk gur xxunk le mo xxmaj roinn tacú leis an xxunk seo agus go raibh ar xxunk dhá threoir - institiúid náisiúnta an taispeántas seo a dhéanamh i xxunk le chéile . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos \" it has been a xxunk to take part in the xxmaj xxunk to xxmaj xxunk xxunk under xxmaj xxunk xxmaj day for xxmaj europe xxunk . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos \" ba mhór an xxunk dom xxunk a ghlacadh sa xxunk xxmaj ar xxmaj ais ar xxmaj xxunk faoi xxunk xxup lá xxmaj xxunk na heorpa xxunk . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos xxmaj when a xxunk has 3 xxunk with the same size , xxunk xxunk for xxunk . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos xxmaj nuair a bhfuil xxunk 3 xxunk leis an méid céanna , xxunk den xxunk xxunk . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxbos ( 10 ) xxmaj sections 5 and 7 of the xxmaj xxunk xxmaj act , xxunk , shall apply to the determination of an appeal under this section as they apply to appeals under that xxmaj act . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 10 ) xxmaj beidh feidhm ag ailt 5 agus 7 den xxmaj acht xxmaj xxunk , xxunk , maidir le cinneadh achomhairc faoin alt seo mar atá feidhm acu maidir le xxunk faoin xxmaj acht sin . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxbos ( 1 ) by the substitution for “ section xxunk of the xxmaj income xxmaj tax xxmaj act , 1967 ” of “ section xxunk ( 5 ) of the xxmaj corporation xxmaj tax xxmaj act , 1976 ” , and xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 1 ) trí “ xxunk ( 5 ) den xxmaj acht xxmaj cánach xxmaj corparáide , 1976 ” a chur in ionad “ xxunk den xxmaj acht xxmaj cánach xxmaj ioncaim , 1967 ” , agus xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxbos \" processing and public access to xxunk documents \" xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos \" próiseáil agus rochtain phoiblí ar xxunk xxunk \" xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxbos ( 1 ) a person guilty of an offence under this xxmaj act shall be liable — xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 1 ) xxmaj aon duine a bheidh ciontach i gcion faoin xxmaj acht seo , dlífear — xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xxbos ( 1 ) xxmaj paragraph 3 is xxunk by the following xxunk : xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 1 ) xxmaj xxunk an téacs seo a leanas in ionad mhír 3 : xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,sl = 32, 512\n",
    "dls = dsets.dataloaders(bs=bs, seq_len=sl, before_batch=partial(pad_input, pad_fields=[0,1]))\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save vocab to speed up data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'models/paracrawl_vocab_en_v0.2_exp{exp}.csv', 'w', newline='') as csvfile:\n",
    "#     v_writer = csv.writer(csvfile, delimiter=',')\n",
    "#     for l in dls.vocab[0]:\n",
    "#         v_writer.writerow([l])\n",
    "        \n",
    "# with open(f'models/paracrawl_vocab_ga_v0.2_exp{exp}.csv', 'w', newline='') as csvfile:\n",
    "#     v_writer = csv.writer(csvfile, delimiter=',')\n",
    "#     for l in dls.vocab[1]:\n",
    "#         v_writer.writerow([l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 25, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.train_ds)+len(dls.valid_ds), len(dls.train), len(dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab lengths are : (1112, 1208)\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocab lengths are : {len(dls.vocab[0]), len(dls.vocab[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 62]),\n",
       " torch.Size([32, 67]),\n",
       " (TensorText([[  2,  11,  25,  ...,   1,   1,   1],\n",
       "          [  2,  19, 123,  ...,   1,   1,   1],\n",
       "          [  2,  19,  41,  ...,   1,   1,   1],\n",
       "          ...,\n",
       "          [  2,  19, 711,  ...,   1,   1,   1],\n",
       "          [  2,  11,  21,  ...,   1,   1,   1],\n",
       "          [  2,  11,  25,  ...,   1,   1,   1]], device='cuda:0'),\n",
       "  TensorText([[  2,  12,  26,  ...,   1,   1,   1],\n",
       "          [  2,  20,  65,  ...,   1,   1,   1],\n",
       "          [  2,  20, 359,  ...,   1,   1,   1],\n",
       "          ...,\n",
       "          [  2,   8,  29,  ...,   1,   1,   1],\n",
       "          [  2,  12,  21,  ...,   1,   1,   1],\n",
       "          [  2,  12,  26,  ...,   1,   1,   1]], device='cuda:0')))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=dls.one_batch(); o[0].size(), o[1].size(), o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Encode the position with a sinusoid.\"\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.register_buffer('freq', 1 / (10000 ** (torch.arange(0., d, 2.)/d)))\n",
    "    \n",
    "    def forward(self, pos):\n",
    "        #inp = torch.ger(pos, self.freq)\n",
    "        inp = torch.ger(pos, self.freq.float())\n",
    "        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n",
    "        return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst_encoding = PositionalEncoding(20)\n",
    "# res = tst_encoding(torch.arange(0,100).float())\n",
    "# _, ax = plt.subplots(1,1)\n",
    "# for i in range(1,5): ax.plot(res[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    \"Embedding + positional encoding + dropout\"\n",
    "    def __init__(self, vocab_sz, emb_sz, inp_p=0.):\n",
    "        super().__init__()\n",
    "        self.emb_sz = emb_sz\n",
    "        self.embed = Embedding(vocab_sz, emb_sz)\n",
    "        self.pos_enc = PositionalEncoding(emb_sz)\n",
    "        self.drop = nn.Dropout(inp_p)\n",
    "    \n",
    "    def forward(self, inp): \n",
    "        #pos = torch.arange(0, inp.size(1), device=inp.device).float()     \n",
    "        pos = torch.arange(0, inp.size(1), device=inp.device).float()     \n",
    "        return self.drop(self.embed(inp) * math.sqrt(self.emb_sz) + self.pos_enc(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Transformer Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: [src/tgt/memory]_mask should be filled with float(‘-inf’) for the masked positions and float(0.0) else. These masks ensure that predictions for position i depend only on the unmasked positions j and are applied identically for each sequence in a batch. \n",
    "\n",
    "[src/tgt/memory]_key_padding_mask should be a ByteTensor where True values are positions that should be masked with float(‘-inf’) and False values will be unchanged. This mask ensures that no information will be taken from position i if it is masked, and has a separate mask for each sequence in a batch.\n",
    "\n",
    "attn mask with -inf\n",
    "key_padding mask with True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pt_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_half(b):\n",
    "    \"Recursively map lists of tensors in `b ` to FP16.\"\n",
    "    return apply(lambda x: x.half() if torch.is_floating_point(x) else x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class pt_Transformer(Module):\n",
    "    def __init__(self, src_vcbsz, trg_vcbsz, n_enc_layers=6, n_dec_layers=6, n_heads=8, d_model=256, d_head=32, \n",
    "                 d_inner=1024, p=0.1, bias=True, scale=True, double_drop=True, pad_idx=1, fp16=True):\n",
    "        self.pad_idx = pad_idx\n",
    "        self.enc_tfmr_emb = TransformerEmbedding(src_vcbsz, d_model, p)\n",
    "        self.dec_tfmr_emb = TransformerEmbedding(trg_vcbsz, d_model, 0.)        \n",
    "        self.final = nn.Linear(d_model, trg_vcbsz)\n",
    "        self.fp16 = fp16\n",
    "        # !!!\n",
    "        #self.final.weight = self.dec_tfmr_emb.embed.weight    # !! Ties weights\n",
    "        \n",
    "        self.transformer_model=torch.nn.Transformer(d_model=d_model, nhead=n_heads, num_encoder_layers=n_enc_layers, \n",
    "                                   num_decoder_layers=n_dec_layers, dim_feedforward=d_inner, dropout=p, \n",
    "                                   activation='relu', custom_encoder=None, custom_decoder=None)\n",
    "    \n",
    "    \n",
    "    def forward(self, src, trg, src_mask=None, tgt_mask=None, memory_mask=None, \n",
    "                        src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        \n",
    "        enc_emb, dec_emb = self.enc_tfmr_emb(src), self.dec_tfmr_emb(trg)\n",
    "        \n",
    "        # Test whether fp16 is being used or not\n",
    "#         if not isinstance(model.transformer_model.encoder.layers[0].self_attn.out_proj.weight,\n",
    "#                           torch.cuda.FloatTensor):\n",
    "        if model.transformer_model.encoder.layers[0].self_attn.out_proj.weight.dtype == torch.float16:\n",
    "            enc_emb=to_half(enc_emb)\n",
    "            dec_emb=to_half(dec_emb)\n",
    "        \n",
    "        if src.device.type == 'cuda':\n",
    "            src_mask=self.transformer_model.generate_square_subsequent_mask(src.size(1)).cuda()\n",
    "            trg_mask=self.transformer_model.generate_square_subsequent_mask(trg.size(1)).cuda()\n",
    "        else:\n",
    "            src_mask=self.transformer_model.generate_square_subsequent_mask(src.size(1)).cpu()\n",
    "            trg_mask=self.transformer_model.generate_square_subsequent_mask(trg.size(1)).cpu()\n",
    "        \n",
    "        dec_out = self.transformer_model(enc_emb.permute(1,0,2), dec_emb.permute(1,0,2),\n",
    "                                         src_mask=src_mask, tgt_mask=trg_mask, memory_mask=None, \n",
    "                        src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "        \n",
    "        out=self.final(dec_out)\n",
    "        \n",
    "        return out.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "#### Present Input and Target in a single tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineInputOutputCallback(Callback):\n",
    "    '''Callback to combine the input and target text into self.xb'''\n",
    "    def __init__(self): pass\n",
    "    def begin_batch(self): \n",
    "        self.learn.xb = (self.xb[0], self.yb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting and masking of y, from [Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html#training):\n",
    "\n",
    "> We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target shift/offset explained\n",
    "\n",
    "**Taken from [@bentrevett's brilliant github repo \"pytorch-seq2seq\" tutorials](https://github.com/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb):**\n",
    "\n",
    "As we want our model to predict the <eos> token but not have it be an input into our model we simply slice the <eos> token off the end of the sequence. Thus:\n",
    "\n",
    "$$\\begin{align*}\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\\end{align*}$$\n",
    "\n",
    "$x_i$ denotes **actual** target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the <eos> token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "$y_i$ denotes **predicted** target sequence element. We then calculate our loss using the original trg tensor with the <sos> token sliced off the front, leaving the <eos> token:\n",
    "\n",
    "$$\\begin{align*} \\text{output} &= [y_1, y_2, y_3, eos]\\\\ \\text{trg[1:]} &= [x_1, x_2, x_3, eos] \\end{align*}$$\n",
    "\n",
    "We then calculate our losses and update our parameters as is standard.\n",
    "    \n",
    "    \n",
    "We don't want to punish the model for not translating the 'sos' token, but we do need it to predict/define the end of the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RemoveEOSCallback** \n",
    "\n",
    "Cut the *EOS* token token from the **output_x** presented to the model as we are trying to predict the next word. Therefore don't want to model to try anything after the *EOS* token. So the last token given to the model will be the token before *EOS*. This callback modifies the second element of our learn.xb, (which is the *copied* yb)\n",
    "\n",
    "But this should also ignore padding, as otherwise we'll be just cutting the last padding token and not the EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveEOSCallback(Callback):\n",
    "    '''\n",
    "        Shift the target presented to the model during training to remove the \"eos\" token as \n",
    "        we don't want the model to learn to translate EOS when it sees EOS.\n",
    "        \n",
    "        In practice we actually mask the EOS token as due to batching the last token will often be a <pad> token,\n",
    "        not EOS\n",
    "    '''\n",
    "    def __init__(self, eos_idx): self.eos_idx=eos_idx\n",
    "    def begin_batch(self):        \n",
    "        eos_mask=(self.learn.xb[1]!=self.eos_idx)\n",
    "        sz=torch.tensor(self.learn.xb[1].size())\n",
    "        sz[1]=sz[1]-1\n",
    "        self.learn.xb = (self.learn.xb[0], self.learn.xb[1][eos_mask].view((sz[0],sz[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LossTargetShiftCallback:** Shift the target shown to the loss to exclude the \"eos\" token, as translating \"bos\" is not part of our language translation objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossTargetShiftCallback(Callback):\n",
    "    '''\n",
    "        Shift the target shown to the loss to exclude the \"bos\" token as the first token we want predicted\n",
    "        should be an actual word, not the \"bos\" token (as we have already given the model \"bos\" )\n",
    "    '''\n",
    "    def __init__(self): pass\n",
    "    def after_pred(self): \n",
    "        self.learn.yb = (self.learn.yb[0][:,1:],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer size from Annotated Transformer:\n",
    "\n",
    "N=6, d_model=512, d_ff=2048, h=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pad_idx=1\n",
    "assert dls.vocab[1][pad_idx] == 'xxpad' \n",
    "n_x_vocab, n_y_vocab = len(dls.vocab[0]), len(dls.vocab[1])\n",
    "d_model=512\n",
    "n_heads=8 #12\n",
    "d_inner=2048  #1024\n",
    "\n",
    "n_enc_layers=2\n",
    "n_dec_layers=2\n",
    "\n",
    "model=pt_Transformer(src_vcbsz=n_x_vocab, trg_vcbsz=n_y_vocab, d_model=d_model, d_inner=d_inner,\n",
    "                    n_enc_layers=n_enc_layers, n_dec_layers=n_dec_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaiming_Normal works terrribly, at least if you apply it to everything except LayerNorm...\n",
    "\n",
    "DistilBERT works ok\n",
    "\n",
    "Could try xavier:\n",
    "\n",
    "```\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.apply(initialize_weights);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DistilBERT initialisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilERT HF init weights https://github.com/huggingface/transformers/blob/31e67dd19f1b3fe2bc9a13f86d814f3f7bba48e4/src/transformers/modeling_distilbert.py\n",
    "\n",
    "def distil_apply_leaf(m, f):\n",
    "    \"Apply `f` to children of `m`.\"\n",
    "    c = m.children()\n",
    "    if isinstance(m, nn.Module): f(m)\n",
    "    for l in c: apply_leaf(l,f)\n",
    "\n",
    "\n",
    "def _distilbert_init_weights(module):\n",
    "    \"\"\" Initialize the weights.\n",
    "    \"\"\"\n",
    "    if isinstance(module, nn.Embedding):\n",
    "        if module.weight.requires_grad:\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02) #std=self.config.initializer_range)\n",
    "    if isinstance(module, nn.Linear):\n",
    "        module.weight.data.normal_(mean=0.0, std=0.02) #self.config.initializer_range)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n",
    "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "        module.bias.data.zero_()\n",
    "\n",
    "distil_apply_leaf(model, _distilbert_init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 16,522,424 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbLogMore(Callback):\n",
    "    run_after=WandbCallback\n",
    "    def begin_fit(self):\n",
    "        wandb.config.update({'n_enc_layers':n_enc_layers, 'n_dec_layers':n_dec_layers})\n",
    "\n",
    "# Make sure model config is logged each time        \n",
    "WandbCallback._wandb_watch_called=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sqr_grad(p, sqr_mom, dampening=True, sqr_avg=None, **kwargs):\n",
    "    if sqr_avg is None: sqr_avg = torch.zeros_like(p.grad.data)\n",
    "    damp = 1-sqr_mom if dampening else 1.\n",
    "    sqr_avg.mul_(sqr_mom).addcmul_(p.grad.data, p.grad.data, value=damp)\n",
    "    # above eqv to:\n",
    "    # sqr_avg = (sqr_mom * sqr_avg) + (p.grad.data * p.grad.data * damp)  \n",
    "    return {'sqr_avg': sqr_avg}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg, eps, **kwargs):\n",
    "    \"Step for Adam with `lr` on `p`\"\n",
    "    debias1 = debias(mom,     1-mom,     step)\n",
    "    debias2 = debias(sqr_mom, 1-sqr_mom, step)\n",
    "    p.data.addcdiv_(grad_avg, (sqr_avg/debias2).sqrt() + eps, value = -lr / debias1)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_step._defaults = dict(eps=1e-5)\n",
    "\n",
    "# Cell\n",
    "@log_args(to_return=True, but_as=Optimizer.__init__)\n",
    "def Adam(params, lr, mom=0.9, sqr_mom=0.99, eps=1e-5, wd=0.01, decouple_wd=True):\n",
    "    \"A `Optimizer` for Adam with `lr`, `mom`, `sqr_mom`, `eps` and `params`\"\n",
    "    cbs = [weight_decay] if decouple_wd else [l2_reg]\n",
    "    cbs += [partial(average_grad, dampening=True), average_sqr_grad, step_stat, adam_step]\n",
    "    return Optimizer(params, cbs, lr=lr, mom=mom, sqr_mom=sqr_mom, eps=eps, wd=wd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaHessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params, grads = [], []\n",
    "# for param in learn.model.parameters():\n",
    "#     if not param.requires_grad:\n",
    "#         continue\n",
    "#     params.append(param)\n",
    "#     grads.append(0. if param.grad is None else param.grad + 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#learn.show_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GetParamsGrad(Callback):\n",
    "#     \"\"\"\n",
    "#         get model parameters and corresponding gradients\n",
    "#     \"\"\"\n",
    "#     run_after=MixedPrecision\n",
    "#     def after_backward(self):\n",
    "#         params = []\n",
    "#         grads = []\n",
    "#         for param in self.model.parameters():\n",
    "#             if not param.requires_grad:\n",
    "#                 continue\n",
    "#             params.append(param)\n",
    "#             grads.append(0. if param.grad is None else param.grad + 0.)\n",
    "#         self._params = params\n",
    "#         self._grads = grads\n",
    "#         #return params, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         loss.backward(create_graph=True)\n",
    "#         _, gradsH = get_params_grad(model)\n",
    "#         optimizer.step(gradsH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tst_param(val, grad=None):\n",
    "#     \"Create a tensor with `val` and a gradient of `grad` for testing\"\n",
    "#     res = tensor([val]).float()\n",
    "#     res.grad = tensor([val/10 if grad is None else grad]).float()\n",
    "#     return res\n",
    "\n",
    "# r = L.range(4)\n",
    "# def tst_params(): return r.map(tst_param)\n",
    "\n",
    "# params = tst_params()\n",
    "# opt = Optimizer(params, sgd_step, lr=0.1)\n",
    "# print(params)\n",
    "# print()\n",
    "# print(opt.all_params())\n",
    "# print()\n",
    "# print(opt.state)\n",
    "# opt.step()\n",
    "# print()\n",
    "# print(opt.all_params())\n",
    "# print()\n",
    "# print(opt.all_params(with_grad=True))\n",
    "# print()\n",
    "# #print(opt.state)\n",
    "\n",
    "# test_close([p.item() for p in params], r.map(mul(0.99)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def tst_param(val, grad=None):\n",
    "#     \"Create a tensor with `val` and a gradient of `grad` for testing\"\n",
    "#     res = tensor([val]).float()\n",
    "#     res.grad = tensor([val/10 if grad is None else grad]).float()\n",
    "#     return res\n",
    "\n",
    "# r = L.range(4)\n",
    "\n",
    "# def tst_params(): return r.map(tst_param)\n",
    "\n",
    "# params = tst_params()\n",
    "\n",
    "# grads = []\n",
    "# for p in params:\n",
    "#     p.requires_grad = True\n",
    "#     grads.append(0. if p.grad is None else p.grad + 0.)\n",
    "    \n",
    "# grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NllLossBackward object at 0x7f709145db50>\n",
      "\n",
      "[Parameter containing:\n",
      "tensor([[-0.5158,  0.0392],\n",
      "        [-0.3330,  0.4913]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4275, -0.6492], requires_grad=True)]\n",
      "\n",
      "[tensor([[-0.8369, -0.2466],\n",
      "        [ 0.8369,  0.2466]], grad_fn=<AddBackward0>), tensor([ 0.6518, -0.6518], grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "x = torch.randn(2, 2, requires_grad=True)\n",
    "lin = nn.Linear(2, 2) # your model or manual operations\n",
    "out = lin(x)\n",
    "\n",
    "trg = torch.ones(out.size()[1]).long()\n",
    "\n",
    "loss = criterion(out, trg)\n",
    "\n",
    "print(loss.grad_fn)\n",
    "print()\n",
    "loss.backward(create_graph=True)\n",
    "\n",
    "params = []\n",
    "grads = []\n",
    "for param in lin.parameters():\n",
    "    if not param.requires_grad:\n",
    "        continue\n",
    "    params.append(param)\n",
    "    grads.append(0. if param.grad is None else param.grad + 0.)\n",
    "    \n",
    "print(params)\n",
    "print()      \n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8369, -0.2466],\n",
       "        [ 0.8369,  0.2466]], grad_fn=<CopyBackwards>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #for p,g in zip(params, grads):\n",
    "# for p in params:\n",
    "#     print(get_hutchinson_trace(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = Optimizer(params, hutchinson_trace, lr=0.1)\n",
    "# opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hutchinson_trace(p, **kwargs):\n",
    "#     \"\"\"\n",
    "#         compute the Hessian vector product with a random vector v, at the current gradient point,\n",
    "#         i.e., compute the gradient of <gradsH,v>.\n",
    "#         :param gradsH: a list of torch variables\n",
    "#         :return: a list of torch tensors\n",
    "#     \"\"\"\n",
    "# #     params = p\n",
    "# #     # Get gradsH\n",
    "# #     params = []\n",
    "# #     grads = []\n",
    "# #     for param in self.model.parameters():\n",
    "# #         if not param.requires_grad:\n",
    "# #             continue\n",
    "# #         #params.append(param)\n",
    "# #         grads.append(0. if param.grad is None else param.grad + 0.)\n",
    "# #     #self._params = params\n",
    "# #     gradsH = grads\n",
    "\n",
    "#     #params = self.param_groups[0]['params']\n",
    "#     #params = [p]\n",
    "# #     if gradsH is None:\n",
    "# #         print('yep')\n",
    "#     #print(p.requires_grad)\n",
    "#     #gradsH = [0. if p.grad is None else p.grad + 0.]\n",
    "#     #gradsH = [torch.tensor(0. if p.grad is None else p.grad.clone() + 0., requires_grad=True)]\n",
    "#     if p.grad is None: gradsH = torch.tensor(0. , requires_grad=True)\n",
    "#     else: gradsH = p.grad.clone().detach().requires_grad_(True) + 0.\n",
    "#     #gradsH =  = torch.tensor(0. if p.grad is None else p.grad.clone() + 0., requires_grad=True)\n",
    "#     #torch.tensor(b.grad.clone(), requires_grad=True)\n",
    "#     print(gradsH)\n",
    "\n",
    "#         #gradsH.append(0. if p.grad is None else p.grad + 0.)\n",
    "# #         print(gradsH)\n",
    "# #         for param in self.model.parameters():\n",
    "# # #         if not param.requires_grad:\n",
    "# # #             continue\n",
    "# # #         #params.append(param)\n",
    "# # #         grads.append(0. if param.grad is None else param.grad + 0.)\n",
    "# #     else: gradsH = [gradsH]\n",
    "    \n",
    "#     #v = [torch.randint_like(_p, high=2, device='cuda') for _p in params]\n",
    "#     #v = [torch.randint_like(_p, high=2, device='cuda') for _p in params]\n",
    "#     v = torch.randint_like(p, high=2, device='cuda')\n",
    "    \n",
    "#     for v_i in v:\n",
    "#         v_i[v_i == 0] = -1\n",
    "    \n",
    "#     hvs = torch.autograd.grad(\n",
    "#         list(gradsH),\n",
    "#         list(p),\n",
    "# #         gradsH,\n",
    "# #         params,\n",
    "#         grad_outputs=list(v),\n",
    "#         only_inputs=True,\n",
    "#         retain_graph=True,\n",
    "#         allow_unused=True)\n",
    "#     print(hvs)\n",
    "    \n",
    "#     hutchinson_trace = []\n",
    "#     for hv, vi in zip(hvs, v):\n",
    "#         param_size = hv.size()\n",
    "#         #print(param_size)\n",
    "#         if len(param_size) <= 2:  # for 0/1/2D tensor\n",
    "#             tmp_output = torch.abs(hv * vi)\n",
    "#             #hutchinson_trace.append(tmp_output) # Hessian diagonal block size is 1 here.\n",
    "#             hutchinson_trace = tmp_output\n",
    "#         elif len(param_size) == 4:  # Conv kernel\n",
    "#             tmp_output = torch.abs(torch.sum(torch.abs(hv * vi), dim=[2, 3], keepdim=True)) / vi[0, 1].numel() # Hessian diagonal block size is 9 here: torch.sum() reduces the dim 2/3.\n",
    "#             #hutchinson_trace.append(tmp_output)\n",
    "#             hutchinson_trace = tmp_output\n",
    "    \n",
    "#     #print(len(hutchinson_trace))\n",
    "#     return {'hutchinson_trace':hutchinson_trace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sqr_diag_hessian(p, sqr_mom, dampening=True, sqr_avg_diag_hessian=None, hutchinson_trace=None, **kwargs):\n",
    "#     print(kwargs)\n",
    "    #print(hutchinson_trace)\n",
    "    if sqr_avg_diag_hessian is None: sqr_avg_diag_hessian = torch.zeros_like(p.grad.data)\n",
    "    damp = 1-sqr_mom if dampening else 1.\n",
    "    #sqr_avg_diag_hessian.mul_(sqr_mom).addcmul_(p.grad.data, p.grad.data, value=damp)\n",
    "    \n",
    "    sqr_avg_diag_hessian = (sqr_mom * sqr_avg_diag_hessian) + (damp * hutchinson_trace * hutchinson_trace)\n",
    "    return {'sqr_avg_diag_hessian': sqr_avg_diag_hessian}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adahessian_step(p, lr, mom, step, sqr_mom, grad_avg, sqr_avg_diag_hessian, eps, **kwargs):\n",
    "    \"Step for Adam with `lr` on `p`\"\n",
    "    debias1 = debias(mom,     1-mom,     step)\n",
    "    debias2 = debias(sqr_mom, 1-sqr_mom, step)\n",
    "    p.data.addcdiv_(grad_avg, (sqr_avg_diag_hessian/debias2).sqrt() + eps, value = -lr / debias1)\n",
    "    \n",
    "    # WHERE DOES THE POWER GO??\n",
    "    #p.data = p.data + (grad_avg / (sqr_avg_diag_hessian/debias2).sqrt() + eps) * (-lr / debias1)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if self.hessian_power < 1:\n",
    "#     denom = ((exp_hessian_diag_sq.sqrt() / math.sqrt(bias_correction2)) ** self.hessian_power).add_(group['eps'])\n",
    "# else:\n",
    "#     denom = (exp_hessian_diag_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr=0.15, betas=(0.9, 0.999), eps=1e-4, weight_decay=0, hessian_power=1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam_step._defaults = dict(eps=1e-5)\n",
    "\n",
    "# Cell\n",
    "@log_args(to_return=True, but_as=Optimizer.__init__)\n",
    "def AdaHessian(params, lr, hessian_power=1, mom=0.9, sqr_mom=0.99, eps=1e-5, wd=0.0, decouple_wd=True):\n",
    "    \"A `Optimizer` for Adam with `lr`, `mom`, `sqr_mom`, `eps` and `params`\"\n",
    "    cbs = [weight_decay] if decouple_wd else [l2_reg]\n",
    "#     cbs += [partial(average_grad, dampening=True), average_sqr_diag, step_stat, adam_step]\n",
    "    cbs += [partial(average_grad, dampening=True), average_sqr_diag_hessian, step_stat, adahessian_step]\n",
    "    return Optimizer(params, cbs, lr=lr, mom=mom, sqr_mom=sqr_mom, \n",
    "                     hessian_power=hessian_power,eps=eps, wd=wd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def one_batch(self:Learner, i, b, create_graph=True):\n",
    "    self.iter = i\n",
    "    try:\n",
    "        self._split(b);                                  self('begin_batch')\n",
    "        self.pred = self.model(*self.xb);                self('after_pred')\n",
    "        if len(self.yb) == 0: return\n",
    "        self.loss = self.loss_func(self.pred, *self.yb); self('after_loss')\n",
    "        if not self.training: return\n",
    "        self.loss.backward(create_graph=create_graph);   self('after_backward')    # <---CHANGED HERE\n",
    "        self.opt.step();                                 self('after_step')\n",
    "        self.opt.zero_grad()\n",
    "    except CancelBatchException:                         self('after_cancel_batch')\n",
    "    finally:                                             self('after_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update(state, new=None):\n",
    "    #print(state)\n",
    "    if new is None: return state\n",
    "    if isinstance(new, dict): state.update(new)\n",
    "    return state\n",
    "\n",
    "@patch\n",
    "def step(self:Optimizer):\n",
    "    #self.state['hutchinson_trace'] = self.hutchinson_trace\n",
    "    for p,pg,state,hyper in self.all_params(with_grad=True):\n",
    "        state['hutchinson_trace'] = self.hutchinson_trace[0]\n",
    "        #print(state)\n",
    "        for cb in self.cbs: state = _update(state, cb(p, **{**state, **hyper}))\n",
    "        self.state[p] = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HutchinsonTrace(Callback):\n",
    "    runs_after=MixedPrecision\n",
    "    \n",
    "    def _get_params_grads(self):\n",
    "        params = []\n",
    "        gradsH = []\n",
    "        for p in self.model.parameters():\n",
    "            if not p.requires_grad:\n",
    "                continue\n",
    "            gradsH.append(0. if p.grad is None else p.grad + 0.)\n",
    "            params.append(p)\n",
    "        return params,gradsH\n",
    "    \n",
    "    def after_backward(self):\n",
    "        \"\"\"\n",
    "            compute the Hessian vector product with a random vector v, at the current gradient point,\n",
    "            i.e., compute the gradient of <gradsH,v>.\n",
    "            :param gradsH: a list of torch variables\n",
    "            :return: a list of torch tensors\n",
    "        \"\"\"\n",
    "        params,gradsH = self._get_params_grads()\n",
    "\n",
    "        v = [torch.randint_like(p, high=2, device='cuda') for p in params]\n",
    "        for v_i in v:\n",
    "            v_i[v_i == 0] = -1\n",
    "        \n",
    "        hvs = torch.autograd.grad(\n",
    "            gradsH,\n",
    "            params,\n",
    "            grad_outputs=v,\n",
    "            only_inputs=True,\n",
    "            retain_graph=True,\n",
    "            #allow_unused=True\n",
    "        )\n",
    "        #print(hvs)\n",
    "\n",
    "        hutchinson_trace = []\n",
    "        for hv, vi in zip(hvs, v):\n",
    "            param_size = hv.size()\n",
    "            #print(param_size)\n",
    "            if len(param_size) <= 2:  # for 0/1/2D tensor\n",
    "                tmp_output = torch.abs(hv * vi)\n",
    "                hutchinson_trace.append(tmp_output) # Hessian diagonal block size is 1 here.\n",
    "                #hutchinson_trace = tmp_output\n",
    "            elif len(param_size) == 4:  # Conv kernel\n",
    "                tmp_output = torch.abs(torch.sum(torch.abs(hv * vi), dim=[2, 3], keepdim=True)) / vi[0, 1].numel() # Hessian diagonal block size is 9 here: torch.sum() reduces the dim 2/3.\n",
    "                hutchinson_trace.append(tmp_output)\n",
    "                #hutchinson_trace = tmp_output\n",
    "\n",
    "        #print(len(hutchinson_trace))\n",
    "        #self.learn.opt.state['hutchinson_trace'] = hutchinson_trace\n",
    "        self.learn.opt.hutchinson_trace = hutchinson_trace\n",
    "        #print(f'hutch state: {self.learn.opt.state[\"hutchinson_trace\"]}')\n",
    "        \n",
    "        #print(hutchinson_trace)\n",
    "        #return {'hutchinson_trace':hutchinson_trace}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbs = [CombineInputOutputCallback, RemoveEOSCallback(eos_idx=3), LossTargetShiftCallback, HutchinsonTrace,\n",
    "       WandbLogMore, WandbCallback(log_preds=False)] \n",
    "\n",
    "pad_idx=1\n",
    "assert dls.vocab[1][pad_idx] == 'xxpad' \n",
    "loss_func = CrossEntropyLossFlat(ignore_index=pad_idx)\n",
    "\n",
    "opt_func=AdaHessian\n",
    "\n",
    "# No accuracy metric\n",
    "learn = Learner(dls, model, metrics=[Perplexity(), CorpusBLEUMetric(vocab_sz=n_y_vocab)], opt_func=opt_func,\n",
    "                cbs=cbs, loss_func=loss_func).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#learn.load('paracrawl_en_ga_5e_5e-4_5e_1e-5_v0.2_exp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai2.fp16_utils import convert_network\n",
    "# learn.model = convert_network(learn.model, dtype=torch.float32)\n",
    "# learn.save('paracrawl_en_ga_5e_5e-4_5e_1e-5_v0.2_exp4_no_opt', with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn=learn.to_fp32()\n",
    "# learn.save('paracrawl_en_ga_5e_5e-4_5e_1e-5_v0.2_exp4_no_opt', with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1208) must match the size of tensor b (1112) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-d81c6bd29d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai2/fastai2/callback/schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_plot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-142-5f78db9801c3>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b, create_graph)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# <---CHANGED HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-143-26334f1c3bd5>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hutchinson_trace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhutchinson_trace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#print(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-137-a5370e4d9cfc>\u001b[0m in \u001b[0;36maverage_sqr_diag_hessian\u001b[0;34m(p, sqr_mom, dampening, sqr_avg_diag_hessian, hutchinson_trace, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#sqr_avg_diag_hessian.mul_(sqr_mom).addcmul_(p.grad.data, p.grad.data, value=damp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msqr_avg_diag_hessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msqr_mom\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msqr_avg_diag_hessian\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdamp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhutchinson_trace\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhutchinson_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'sqr_avg_diag_hessian'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msqr_avg_diag_hessian\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1208) must match the size of tensor b (1112) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-124-bb1ce3a72eb6>\u001b[0m(7)\u001b[0;36maverage_sqr_diag_hessian\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      4 \u001b[0;31m    \u001b[0mdamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msqr_mom\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdampening\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m    \u001b[0;31m#sqr_avg_diag_hessian.mul_(sqr_mom).addcmul_(p.grad.data, p.grad.data, value=damp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 7 \u001b[0;31m    \u001b[0msqr_avg_diag_hessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msqr_mom\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msqr_avg_diag_hessian\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdamp\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhutchinson_trace\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhutchinson_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'sqr_avg_diag_hessian'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msqr_avg_diag_hessian\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> hutchinson_trace\n",
      "<function hutchinson_trace at 0x7fe2b03a2cb0>\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.one_batch??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - Adam 2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.06309573650360108, lr_steep=0.5248074531555176)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.559707</td>\n",
       "      <td>1.546616</td>\n",
       "      <td>4.695555</td>\n",
       "      <td>0.357184</td>\n",
       "      <td>10:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.182653</td>\n",
       "      <td>1.253895</td>\n",
       "      <td>3.503965</td>\n",
       "      <td>0.404492</td>\n",
       "      <td>10:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.885465</td>\n",
       "      <td>1.057526</td>\n",
       "      <td>2.879239</td>\n",
       "      <td>0.445343</td>\n",
       "      <td>10:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.723774</td>\n",
       "      <td>0.930569</td>\n",
       "      <td>2.535953</td>\n",
       "      <td>0.473972</td>\n",
       "      <td>10:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.634351</td>\n",
       "      <td>0.891113</td>\n",
       "      <td>2.437842</td>\n",
       "      <td>0.483517</td>\n",
       "      <td>10:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-4, div=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.save('v03_exp2_adahess_basline_2_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp1 - AdaHessian 2/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-d81c6bd29d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai2/fastai2/callback/schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0mcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_plot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-5f78db9801c3>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b, create_graph)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# <---CHANGED HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai2/fastai2/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-75bd35f17d1a>\u001b[0m in \u001b[0;36mhutchinson_trace\u001b[0;34m(p, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0monly_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         retain_graph=True)\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mhutchinson_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    190\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    191\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.559707</td>\n",
       "      <td>1.546616</td>\n",
       "      <td>4.695555</td>\n",
       "      <td>0.357184</td>\n",
       "      <td>10:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.182653</td>\n",
       "      <td>1.253895</td>\n",
       "      <td>3.503965</td>\n",
       "      <td>0.404492</td>\n",
       "      <td>10:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.885465</td>\n",
       "      <td>1.057526</td>\n",
       "      <td>2.879239</td>\n",
       "      <td>0.445343</td>\n",
       "      <td>10:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.723774</td>\n",
       "      <td>0.930569</td>\n",
       "      <td>2.535953</td>\n",
       "      <td>0.473972</td>\n",
       "      <td>10:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.634351</td>\n",
       "      <td>0.891113</td>\n",
       "      <td>2.437842</td>\n",
       "      <td>0.483517</td>\n",
       "      <td>10:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-4, div=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.save('v03_exp2_adahess_basline_2_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate and Process Translations funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, sentence, vocab, to_cuda=True):    \n",
    "    model=model.eval()\n",
    "    \n",
    "    sentence=learn.dls.tokenizer[0].encodes(sentence)\n",
    "    #sentence=learn.dls.tokenizer[0][1].encodes(sentence)\n",
    "    sentence=learn.dls.numericalize[0].encodes(sentence)\n",
    "    \n",
    "    translated_sentence = [2] \n",
    "    i = 0\n",
    "    while int(translated_sentence[-1]) != 3 and i < 75:   \n",
    "        if to_cuda: output = forward_model(model, sentence, translated_sentence, to_cuda).cuda()\n",
    "        else: output = forward_model(model, sentence, translated_sentence, to_cuda).cpu()\n",
    "        values, indices = torch.topk(output, 5)\n",
    "        translated_sentence.append(int(indices[-1][0]))\n",
    "        i+=1\n",
    "\n",
    "    detok_translated_sentence=detokenize(translated_sentence, vocab)\n",
    "    #print(' '.join(detok_translated_sentence))\n",
    "    return ' '.join(detok_translated_sentence)\n",
    "    \n",
    "\n",
    "def forward_model(model, src, tgt, to_cuda=True):\n",
    "    if to_cuda:\n",
    "        src = torch.as_tensor(src).unsqueeze(0).long().cuda()\n",
    "        tgt = torch.as_tensor(tgt).unsqueeze(0).cuda()\n",
    "        tgt_mask = gen_nopeek_mask(tgt.shape[1]).cuda()\n",
    "        src = to_half(src)\n",
    "        tgt = to_half(tgt)\n",
    "    else:\n",
    "        src = torch.as_tensor(src).unsqueeze(0).long().cpu()\n",
    "        tgt = torch.as_tensor(tgt).unsqueeze(0).cpu()\n",
    "        tgt_mask = gen_nopeek_mask(tgt.shape[1]).cpu()\n",
    "#         src = to_half(src)\n",
    "#         tgt = to_half(tgt)\n",
    "    output = model.forward(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "\n",
    "    #return output.squeeze(0).to('cpu')\n",
    "    return output.squeeze(0).detach()\n",
    "\n",
    "\n",
    "# def tokenize(sentence, freq_list, lang_model):\n",
    "#     punctuation = ['(', ')', ':', '\"', ' ']\n",
    "\n",
    "#     sentence = sentence.lower()\n",
    "#     sentence = [tok.text for tok in lang_model.tokenizer(sentence) if tok.text not in punctuation]\n",
    "#     return [freq_list[word] if word in freq_list else freq_list['[OOV]'] for word in sentence]\n",
    "\n",
    "\n",
    "def detokenize(sentence, vocab):\n",
    "    #freq_list = {v: k for k, v in freq_list.items()}\n",
    "    return [vocab[token] for token in sentence]\n",
    "    #return [freq_list[token] for token in sentence]\n",
    "# def detokenize(sentence, freq_list):\n",
    "#     freq_list = {v: k for k, v in freq_list.items()}\n",
    "#     return [freq_list[token] for token in sentence]\n",
    "\n",
    "\n",
    "def gen_nopeek_mask(length):\n",
    "    mask = rearrange(torch.triu(torch.ones(length, length)) == 1, 'h w -> w h')\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trans(trans):\n",
    "    trans_ls=[]\n",
    "    for s in trans: \n",
    "        #print(s)\n",
    "        tmp = s.replace('xxbos','')\n",
    "        tmp = tmp.replace('xxeos','')\n",
    "        tmp = tmp.replace(' .','.')\n",
    "        tmp = tmp.replace(' ,',',')\n",
    "        tmp = tmp.replace(' ?','?')\n",
    "        tmp = tmp.replace(' !','!')\n",
    "        #print(tmp[0])\n",
    "        if tmp.endswith('. '): tmp=tmp[:-1]\n",
    "        if tmp.endswith('? '): tmp=tmp[:-1]\n",
    "        if tmp.endswith('! '): tmp=tmp[:-1]\n",
    "        \n",
    "        for spec in ['xxmaj ', 'xxup ']:\n",
    "            found=[]\n",
    "            for m in re.finditer(spec, tmp):\n",
    "                found.append(m.start())\n",
    "\n",
    "            for f in found:\n",
    "                m = tmp.find(spec)\n",
    "                if m != -1:   \n",
    "                    ml = m+len(spec)\n",
    "                    if m != 0:\n",
    "                        tmp = tmp[:ml] + tmp[ml].upper() + tmp[ml+1:]\n",
    "                        tmp = tmp[:m] + tmp[ml:]\n",
    "                    else: \n",
    "                        tmp = tmp[ml].upper() + tmp[ml+1:]\n",
    "                        tmp = tmp[ml:]\n",
    "        \n",
    "        # Remove space at start\n",
    "        if tmp[0] == ' ': tmp = tmp[1:]\n",
    "            \n",
    "        # Uppercase start of sentence\n",
    "        #tmp = tmp[0].upper() + tmp[1:]\n",
    "            \n",
    "        trans_ls.append(tmp)\n",
    "    return trans_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ga_id</th>\n",
       "      <th>ga</th>\n",
       "      <th>en_id</th>\n",
       "      <th>en</th>\n",
       "      <th>ga_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>557291</td>\n",
       "      <td>Cá bhfuil críochfort na mbus?</td>\n",
       "      <td>35406</td>\n",
       "      <td>Where is the bus terminal?</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>557299</td>\n",
       "      <td>Nuair a dhúisigh mé, bhí brón orm.</td>\n",
       "      <td>1361</td>\n",
       "      <td>When I woke up, I was sad.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>557533</td>\n",
       "      <td>Tosaíonn an t-oideachas sa bhaile.</td>\n",
       "      <td>19122</td>\n",
       "      <td>Education starts at home.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>557579</td>\n",
       "      <td>Táim i ngrá leat.</td>\n",
       "      <td>1434</td>\n",
       "      <td>I love you.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>934942</td>\n",
       "      <td>Tá grá agam duit.</td>\n",
       "      <td>1434</td>\n",
       "      <td>I love you.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ga_id                                  ga  en_id  \\\n",
       "0  557291       Cá bhfuil críochfort na mbus?  35406   \n",
       "1  557299  Nuair a dhúisigh mé, bhí brón orm.   1361   \n",
       "2  557533  Tosaíonn an t-oideachas sa bhaile.  19122   \n",
       "3  557579                   Táim i ngrá leat.   1434   \n",
       "4  934942                   Tá grá agam duit.   1434   \n",
       "\n",
       "                           en  ga_len  \n",
       "0  Where is the bus terminal?       5  \n",
       "1  When I woke up, I was sad.       7  \n",
       "2   Education starts at home.       5  \n",
       "3                 I love you.       4  \n",
       "4                 I love you.       4  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_path = Path('data/irish/parallel_corpora/tatoeba')\n",
    "t_fn = 'tatoeba_en-ga.csv'\n",
    "t_df = pd.read_csv(t_path/t_fn)\n",
    "\n",
    "t_df['ga_len'] = t_df.ga.str.split().str.len()\n",
    "t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.dls.test_dl = t_dls.valid\n",
    "# def act_fn(x): return L(F.softmax(o, dim=-1) for o in x)\n",
    "# o = learn.get_preds(dl=t_dls.valid, act=act_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxup tá mé réidh don deireadh seachtaine ! xxeos'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"I'm ready for the weekend!\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxbos xxmaj más é an críochfort bus ? xxeos',\n",
       " 'xxbos xxmaj nuair mé xxunk suas , bhí mé brónach . xxeos',\n",
       " 'xxbos xxmaj tosaíonn oideachas sa bhaile . xxeos',\n",
       " 'xxbos xxmaj grá mé duit . xxeos',\n",
       " 'xxbos xxmaj grá mé duit . xxeos']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_ls=[]\n",
    "for e in t_df.en.values:\n",
    "    trans_ls.append(generate(learn.model, e, dls.vocab[1]))    \n",
    "trans_ls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('tatoeba_raw_translations_exp{4}_20200810.txt','w')\n",
    "for ele in trans_ls:\n",
    "    f.write(ele+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Más é an críochfort bus?',\n",
       " 'Nuair mé xxunk suas, bhí mé brónach.',\n",
       " 'Tosaíonn oideachas sa bhaile.',\n",
       " 'Grá mé duit.',\n",
       " 'Grá mé duit.',\n",
       " 'Tá mé grá le tú.',\n",
       " 'Glan againn ár seomra ranga tar éis na scoile.',\n",
       " 'Nach bhfuil muid bhuail roimh?']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_final = process_trans(trans_ls)\n",
    "t_final[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('tatoeba_processed_translations_exp4_20200810.txt','w')\n",
    "for ele in t_final:\n",
    "    f.write(ele+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df['translation'] = t_final\n",
    "t_df.to_csv('tatoeba_with_translation_exp{exp}_20200810.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ga</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>Is féidearthacht é domhan eile.</td>\n",
       "      <td>Is domhan eile is féidir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Tá feabhas ar an aimsir.</td>\n",
       "      <td>Tá an aimsir feabhas níos fearr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Níl a fhios agam go díreach.</td>\n",
       "      <td>Ní fhios agam go díreach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Scríobh chugam.</td>\n",
       "      <td>Scríobh mé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>Cheap cailín a méara sa doras.</td>\n",
       "      <td>a gafa cailín a gafa a xxunk sa doras.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>An bhfuil Béarla aige?</td>\n",
       "      <td>An bhfuil sé labhairt Béarla?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Ní fhaca Tomás rud ar bith.</td>\n",
       "      <td>Tom chonaic aon rud.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Tá na laethanta ag éirí níos faide agus níos faide.</td>\n",
       "      <td>Na laethanta atá ag fáil níos faide agus níos faide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Táim i ngrá leat.</td>\n",
       "      <td>Grá mé duit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>Ná féach ar Tom! Féach orm.</td>\n",
       "      <td>Ná breathnú ar Tom. Féach mé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>Bhí Tom ag iarraidh mé gar a dhéanamh dó.</td>\n",
       "      <td>Theastaigh dom a dhéanamh dó bhfabhar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>Is féidir le gach duine páirt a ghlacadh.</td>\n",
       "      <td>Is féidir le duine ar bith páirt a ghlacadh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>Déan é as do neart féin</td>\n",
       "      <td>An bhfuil sé amach as do neart féin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>Tá oraibh dul.</td>\n",
       "      <td>Ní mór duit dul.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>Níl a fhios agam rud ar bith.</td>\n",
       "      <td>Ní fhios agam aon rud.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Ní chanaim.</td>\n",
       "      <td>Ní féidir liom a shíniú.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>Tá sibh ag cócaireacht.</td>\n",
       "      <td>Tá tú cócaireachta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>Úsáideann mé an ríomhaire sin.</td>\n",
       "      <td>Bain úsáid mé ríomhaire sin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>Chuir an rud a dúirt Tom fearg ort, nár chuir?</td>\n",
       "      <td>Cad a dúirt Tom a rinne tú feargach, ní raibh sé?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Ní bhfuair mo bhean bás.</td>\n",
       "      <td>Ní raibh mo bhean chéile bás.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       ga  \\\n",
       "393                       Is féidearthacht é domhan eile.   \n",
       "700                              Tá feabhas ar an aimsir.   \n",
       "914                          Níl a fhios agam go díreach.   \n",
       "1396                                      Scríobh chugam.   \n",
       "1713                       Cheap cailín a méara sa doras.   \n",
       "467                                An bhfuil Béarla aige?   \n",
       "1039                          Ní fhaca Tomás rud ar bith.   \n",
       "100   Tá na laethanta ag éirí níos faide agus níos faide.   \n",
       "3                                       Táim i ngrá leat.   \n",
       "788                           Ná féach ar Tom! Féach orm.   \n",
       "1674            Bhí Tom ag iarraidh mé gar a dhéanamh dó.   \n",
       "844             Is féidir le gach duine páirt a ghlacadh.   \n",
       "1791                              Déan é as do neart féin   \n",
       "1182                                       Tá oraibh dul.   \n",
       "908                         Níl a fhios agam rud ar bith.   \n",
       "409                                           Ní chanaim.   \n",
       "637                               Tá sibh ag cócaireacht.   \n",
       "1956                       Úsáideann mé an ríomhaire sin.   \n",
       "1149       Chuir an rud a dúirt Tom fearg ort, nár chuir?   \n",
       "740                              Ní bhfuair mo bhean bás.   \n",
       "\n",
       "                                               translation  \n",
       "393                              Is domhan eile is féidir.  \n",
       "700                       Tá an aimsir feabhas níos fearr.  \n",
       "914                              Ní fhios agam go díreach.  \n",
       "1396                                           Scríobh mé.  \n",
       "1713                a gafa cailín a gafa a xxunk sa doras.  \n",
       "467                          An bhfuil sé labhairt Béarla?  \n",
       "1039                                  Tom chonaic aon rud.  \n",
       "100   Na laethanta atá ag fáil níos faide agus níos faide.  \n",
       "3                                             Grá mé duit.  \n",
       "788                          Ná breathnú ar Tom. Féach mé.  \n",
       "1674                Theastaigh dom a dhéanamh dó bhfabhar.  \n",
       "844           Is féidir le duine ar bith páirt a ghlacadh.  \n",
       "1791                  An bhfuil sé amach as do neart féin   \n",
       "1182                                      Ní mór duit dul.  \n",
       "908                                 Ní fhios agam aon rud.  \n",
       "409                               Ní féidir liom a shíniú.  \n",
       "637                                    Tá tú cócaireachta.  \n",
       "1956                          Bain úsáid mé ríomhaire sin.  \n",
       "1149     Cad a dúirt Tom a rinne tú feargach, ní raibh sé?  \n",
       "740                          Ní raibh mo bhean chéile bás.  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df[['ga','translation']].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SacreBLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.334313545254766\n"
     ]
    }
   ],
   "source": [
    "refs = [t_df.ga.values.tolist()]\n",
    "sys = t_df.translation.values.tolist()\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(sys, refs)\n",
    "print(bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47239173591863887\n"
     ]
    }
   ],
   "source": [
    "chrf = sacrebleu.corpus_chrf(sys, refs)\n",
    "print(chrf.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({'SacreBLEU':bleu.score, 'chrF':chrf.score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect top losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "# at 30k tokens per vocab sometimes this works, sometimes it doesn't\n",
    "\n",
    "# Couldnt process 30k tokens until I added the 'hi' below, it was getting stuck at 94.87%, no idea why\n",
    "@Numericalize\n",
    "def encodes(self, o): \n",
    "    print('hi')\n",
    "    return TensorText(tensor([self.o2i  [o_] for o_ in o]))\n",
    "\n",
    "class floatify_tfm(Transform):\n",
    "    def encodes(self,o): return o.float()\n",
    "    def decodes(self,o): return o.long()\n",
    "\n",
    "max_vocab=30000\n",
    "#splits = ColSplitter()(df) \n",
    "splits = RandomSplitter(valid_pct=0.2, seed=42)(df)\n",
    "splits = (splits[0], splits[1][:2000])\n",
    "\n",
    "tfms = [[Tokenizer.from_df(text_cols='en' , rules=proc_rules), attrgetter(\"text\"), Numericalize(max_vocab=max_vocab)], \n",
    "       [Tokenizer.from_df(text_cols='ga', lang='ga', rules=proc_rules), attrgetter(\"text\"), Numericalize(max_vocab=max_vocab)]]\n",
    "\n",
    "dl = partial(SortedDL, shuffle=True, res=df.ga_len.values)\n",
    "\n",
    "dsets = Datasets(df, tfms, splits=splits, dl_type=dl)\n",
    "\n",
    "# remove the print from Numericalize\n",
    "@Numericalize\n",
    "def encodes(self, o): return TensorText(tensor([self.o2i  [o_] for o_ in o]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos ( i ) the application of any goods of a kind specified in the xxmaj fourth xxmaj schedule by a person for the purposes of his business and treated as delivered in accordance with section 3 ( 1 ) ( e ) , xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( i ) le duine do bhaint úsáid chun críocha a ghnó as aon earraí de chineál a shonraítear sa xxmaj cheathrú xxmaj sceideal agus a áirítear mar earraí arna seachadadh de réir alt 3 ( 1 ) ( e ) , xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxup xxunk . xxmaj population aged one year and over , usually resident and present in the xxmaj state , whose usual residence one year previously was outside the xxmaj state , classified by former country of usual residence , sex and distinguishing those with xxmaj irish nationality or other nationality xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos › xxup xxunk . xxmaj daonra xxmaj gnáthchónaitheoirí xxmaj aon xxmaj bliain d'aois agus xxmaj níos xxmaj sine a bhí i xxmaj láthair sa xxmaj stát de réir xxmaj náisiúntacht , xxmaj inscne , xxmaj gnátháit xxmaj chónaithe xxmaj bliain xxmaj roimhe agus bliaindaonáirimh › xxup xxunk . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos ( a ) the constituencies for the election of members to the xxmaj dáil , and xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( a ) na dáilcheantair chun comhaltaí a thoghadh chun na xxmaj dála , agus xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos “ but as climate change increases the frequency and severity of droughts and floods and makes food more difficult to produce , we need innovative solutions to support communities on the frontline . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos \" ach mar a ardaíonn an t - athrú aeráide minicíocht agus déine na xxunk agus na dtuilte agus dhéanann sé bia níos deacra le táirgeadh , is gá réitigh nuálacha chun tacú le pobail ar an líne thosaigh . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxbos xxmaj member xxmaj states : xxmaj germany , xxmaj france , xxmaj italy , the xxmaj netherlands , xxmaj belgium and xxmaj luxembourg . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos xxmaj ballstáit : xxmaj an xxmaj ghearmáin , an xxmaj fhrainc , an xxmaj iodáil , an ísiltír , an xxmaj bheilg agus xxmaj lucsamburg . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxbos ( b ) contributions in respect of that service have been returned to him , xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( b ) go mbeifear tar éis ranníoca i leith na seirbhíse sin a thabhairt ar ais dó , xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxbos xxmaj this website is a national shared service for the collection of the charge for xxmaj non xxmaj principal xxmaj private xxmaj residences on behalf of the local authorities . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos xxmaj is seirbhís náisiúnta chomhroinnte an láithreán gréasáin seo chun an muirear d’áiteanna xxmaj cónaithe xxmaj príobháideacha neamhphríomha ar son na n - údarás áitiúil a bhailiú . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxbos ( 2 ) xxmaj the xxmaj minister may order that a person committed under section 14 be released from custody if the xxmaj minister is of the opinion that a request for the person 's surrender is not being proceeded with . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 2 ) xxmaj féadfaidh an taire a ordú duine a cimíodh faoi alt 14 a scaoileadh saor ó choimeád más é tuairim an xxmaj aire nach bhfuiltear ag dul ar aghaidh le hiarraidh chun an duine a thabhairt suas . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xxbos xxmaj posted on xxmaj august 28 , 2013 by xxmaj kaia xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos by xxmaj kaia xxmaj postáilte ar 28 xxmaj lúnasa , 2013 ag xxmaj kaia xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,sl = 32, 512\n",
    "dls = dsets.dataloaders(bs=bs, seq_len=sl, before_batch=partial(pad_input, pad_fields=[0,1]))\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manually calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eos_idx=3\n",
    "dls.valid.bs = 1\n",
    "\n",
    "loss_ls = []\n",
    "en_ls, ga_trg_ls, ga_pred_ls = [], [], []\n",
    "\n",
    "for xb, yb in dls.valid:\n",
    "    yy = yb\n",
    "    eos_mask=(yb!=eos_idx)\n",
    "    sz=torch.tensor(yb.size())\n",
    "    sz[1]=sz[1]-1\n",
    "    yb = yb[eos_mask].view((sz[0],sz[1]))  # drop the last token (\"eos\") for training \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred_logits = model.forward(src=xb, trg=yb)\n",
    "    \n",
    "    yb_loss = yy[:,1:]  # shift target to exclude xxbos\n",
    "    loss = learn.loss_func(y_pred_logits, yb_loss)\n",
    "    loss_ls.append(loss)\n",
    "\n",
    "    y_pred_act = F.softmax(y_pred_logits, dim=-1)\n",
    "    \n",
    "    preds_ls = []\n",
    "    for p in y_pred_act: \n",
    "        preds_ls.append(p.argmax(dim=-1))\n",
    "    \n",
    "    tmp_ls = []\n",
    "    for i in xb[0]:\n",
    "        if (dls.vocab[0][i] != 'xxpad') and (dls.vocab[1][i] != 'xxbos'):\n",
    "            tmp_ls.append(dls.vocab[0][i])\n",
    "    en_ls.append(' '.join(tmp_ls))\n",
    "\n",
    "    tmp_ls = []\n",
    "    for i in yb[0]:\n",
    "        if (dls.vocab[1][i] != 'xxpad') and (dls.vocab[1][i] != 'xxbos'):\n",
    "            tmp_ls.append(dls.vocab[1][i])\n",
    "    ga_trg_ls.append(' '.join(tmp_ls))\n",
    "\n",
    "    tmp_ls = []\n",
    "    for i in preds_ls[0]:\n",
    "        if dls.vocab[1][i] != 'xxpad':\n",
    "            tmp_ls.append(dls.vocab[1][i])\n",
    "    ga_pred_ls.append(' '.join(tmp_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.8346, device='cuda:0'), tensor(0.0034, device='cuda:0'))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_loss_idx = np.argmax(loss_ls)\n",
    "min_loss_idx = np.argmin(loss_ls)\n",
    "loss_ls[max_loss_idx], loss_ls[min_loss_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted indices by loss, (highest loss to lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_sorted_idxs = np.argsort(-np.array(loss_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show `n` top losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 4.834611415863037\n",
      "xxmaj we are currently experiencing technical difficulties with our subtitles on some browsers . xxeos\n",
      "\n",
      "xxup tá deacrachtaí le fotheidil ar roinnt ‘ xxunk ’ faoi láthair .\n",
      "\n",
      "xxmaj tá muid teicniúla deacrachtaí teicniúla ár brabhsálaithe brabhsálaithe faoi faoi láthair atá xxeos\n",
      "\n",
      "\n",
      "LOSS: 4.4953813552856445\n",
      "frosted green cosmetic glass bottle with silver … xxeos\n",
      "\n",
      "frosted buidéal dropper gloine glas do cosmaideacha …\n",
      "\n",
      "xxmaj cosmaideacha gloine cosmaideacha cosmaideacha cosmaideacha airgid le xxeos\n",
      "\n",
      "\n",
      "LOSS: 4.347179412841797\n",
      "xxmaj not even all the end of compulsory schooling despite compulsory schooling . xxeos\n",
      "\n",
      "xxup ní fiú go léir a chuaigh amach bhunscoil ainneoin scolaíocht éigeantach .\n",
      "\n",
      "xxmaj ní fiú amháin léir deireadh deireadh deireadh dheireadh éigeantach in éigeantach in xxeos\n",
      "\n",
      "\n",
      "LOSS: 4.304743766784668\n",
      "p - xxmaj depth of xxmaj foundation xxeos\n",
      "\n",
      "p - xxmaj fondúireacht doimhneacht\n",
      "\n",
      "p - xxmaj doimhneacht na na\n",
      "\n",
      "\n",
      "LOSS: 4.188599586486816\n",
      "xxmaj open 7 days including bank holidays xxeos\n",
      "\n",
      "xxmaj samhradh : xxmaj oscailte 7 lá , laethanta saoire bainc san áireamh\n",
      "\n",
      "7 laethanta 7 laethanta laethanta 7 lá lena laethanta saoire bainc lena áireamh laethanta\n",
      "\n",
      "\n",
      "LOSS: 4.172364234924316\n",
      "xxmaj ok . xxmaj then i reboot and cross the border . xxeos\n",
      "\n",
      "xxmaj ansin leithroinnte agus dtrasnaíonn an teorainn .\n",
      "\n",
      "xxup ok i mé tras an teorainn . xxeos\n",
      "\n",
      "\n",
      "LOSS: 4.111687660217285\n",
      "xxmaj this was equivalent to a 4.5 % unemployment rate , up slightly from 4.4 % in 2002 but still well below the xxup eu average of 8.0 % . xxeos\n",
      "\n",
      "xxmaj b’ionann sin agus 4.5 % ráta dífhostaíochta ardú beagán ó 4.4 % in 2002 ach go maith faoi leibhéal an mheán xxup ae ag 8.0 % . xxmaj d’ardaigh an líon daoine ar dhífhostaíocht fhadtéarmach 1,200 .\n",
      "\n",
      "xxmaj bhí seo agus ráta % xxunk dífhostaíochta , , ón 4.4 % i 2002 ach fós maith faoi bhun an xxup an ae de brath % . xxeos bhí % ráta tí is an % . % xxeos\n",
      "\n",
      "\n",
      "LOSS: 4.084066390991211\n",
      "( i ) substitute “ the actuary to or trustees of ” for “ the trustees of ” , xxeos\n",
      "\n",
      "( i ) “ déanfaidh achtúire nó iontaobhaithe scéime nó iontaobhais xxup cbs ” a chur in ionad “ déanfaidh iontaobhaithe scéime nó iontaobhais xxup cbs ” ,\n",
      "\n",
      "( i ) “ an achtúire do iontaobhaithe ” ” iontaobhaithe ” xxunk iontaobhais a chur in ionad “ iontaobhaithe iontaobhaithe ” ” , ” na ” , xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.9471380710601807\n",
      "xxmaj ensure national mail services packages are posted either without a cover or in a cover which can be easily removed for the purpose of examination . xxeos\n",
      "\n",
      "xxmaj déan cinnte de go seoltar pacáistí gan chlúdach nó i gclúdach atá furasta a bhaint le haghaidh scrúdúcháin sa chóras náisiúnta poist .\n",
      "\n",
      "xxmaj cuirtear pacáistí go pacáistí gcuirfear pacáistí seirbhísí chlúdach nó i xxunk ar féidir a aistriú go go an a phost seirbhísí a a xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.885239362716675\n",
      "a sea change in xxmaj europe 's innovation performance is the only way to create lasting and well - paid jobs that withstand the pressures of globalisation . \" xxeos\n",
      "\n",
      "xxmaj beidh gá le feabhas ó bhonn a dhéanamh ar fheidhmíocht nuálaíochta na heorpa má táthar chun poist bhuana ar phá maith a chruthú , poist a bheidh in ann brú an domhandaithe a sheasamh . \"\n",
      "\n",
      "xxmaj is athrú le hathrú farraige thaobh na xxunk ar fheidhmíocht na san heorpa ar tá chun poist buan buan aghaidh agus agus chruthú a go atá sheasamh sheasamh aice a an domhandú . chur . \" xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.8690526485443115\n",
      "xxmaj heat loss or gains from pipes , xxunk and vessels is to be limited and energy efficient lighting systems provided . xxeos\n",
      "\n",
      "xxup ní mór caillteanas nó gnóthachain teasa trí phíopaí , xxunk agus soithigh a mhaolú agus córas éifeachtach soilse a fheistiú .\n",
      "\n",
      "xxup tá mór córas teasa gnóchain ó ó phíopaí , xxunk agus soithí a bhfuil a a fuinnimh fuinnimh fuinnimh sholáthar ar xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.851304292678833\n",
      "xxmaj provisions in relation to reserve values , transfer values and transfers of insurance . xxeos\n",
      "\n",
      "xxmaj forálacha maidir le cúl - luacha , luacha aistriúcháin agus aistrithe árachais .\n",
      "\n",
      "xxmaj forálacha maidir le luachanna - luachanna , luachanna aistrithe d'aistriú aistrithe luachanna d'aistriú xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.835312604904175\n",
      "xxmaj article xxunk in attack xxeos\n",
      "\n",
      "xxmaj airteagal xxunk i gcás ionsaithe\n",
      "\n",
      "xxmaj airteagal xxunk ionsaí ionsaí ionsaí ionsaí\n",
      "\n",
      "\n",
      "LOSS: 3.74434494972229\n",
      "xxmaj xxunk and licences - construction - road safety - traffic xxmaj management and xxmaj parking xxeos\n",
      "\n",
      "xxmaj xxunk xxmaj tógáil bóthair - sábháilteacht bóthair - bainistíocht xxmaj tráchta\n",
      "\n",
      "xxmaj xxunk agus xxunk agus agus sábháilteacht agus agus agus agus tráchta agus\n",
      "\n",
      "\n",
      "LOSS: 3.710318088531494\n",
      "xxmaj standard link building sources xxeos\n",
      "\n",
      "xxmaj foinsí xxmaj standard tógáil nasc\n",
      "\n",
      "xxmaj foinsí nasc caighdeánach nasc xxmaj tógála\n",
      "\n",
      "\n",
      "LOSS: 3.7060744762420654\n",
      "xxmaj after this the delegates late xxmaj louis xxup xvi to the death , by a majority vote of one vote . xxeos\n",
      "\n",
      "xxmaj tar éis seo an xxmaj toscairí déanach xxmaj louis xxup xvi xxmaj chun an xxmaj bás , xxmaj de a xxmaj formhór na xxmaj vóta haon .\n",
      "\n",
      "xxmaj tar éis na na xxmaj louis xxmaj xxmaj louis xxup xvi le louis an bháis bháis , trí vóta vóta vóta vóta vóta vóta vóta amháin vóta xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.6944961547851562\n",
      "17 . a sensible housing policy in xxmaj xxunk . xxeos\n",
      "\n",
      "17 . xxmaj polasaí ceart tithíochta i mbearna .\n",
      "\n",
      "17 . xxmaj polasaí tithíochta tithíochta ciallmhar xxmaj xxmaj xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.6918556690216064\n",
      "xxup eu budget 2014 by financial framework heading xxeos\n",
      "\n",
      "xxmaj buiséad 2014 de réir na gceannteideal atá sa chreat airgeadais\n",
      "\n",
      "xxmaj buiséad an ag réir réigiúin creat airgeadais ann xxup airgeadais xxup\n",
      "\n",
      "\n",
      "LOSS: 3.656128406524658\n",
      "3.1 xxmaj the purpose of this chapter is to give a brief review of the more important or interesting decisions and developments in the area of criminal law in 2007 . xxeos\n",
      "\n",
      "3.1 xxmaj is é cuspóir atá leis an gcaibidil seo cuntas gairid a thabhairt ar chinntí agus ar chora xxunk eile den tábhacht maidir le réimse dhlí na coireachta i rith na bliana 2007 .\n",
      "\n",
      "3.1 xxmaj is é is na leis an gcaibidil seo athbhreithniú gearr ar thabhairt ar na níos forbairtí na is nó nó dlí níos le forbairtí an coiriúil coiriúil in 2007 2007 bliana 2007 . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.5991711616516113\n",
      "( 5 ) fire or water hose fittings of the following descriptions : xxeos\n",
      "\n",
      "( 5 ) feistisí feadán tóiteáin no feadán uisce de sna xxunk so leanas :\n",
      "\n",
      "( 5 ) xxup xxunk dóiteáin nó uisce uisce de sna saghsanna seo a : xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.5880415439605713\n",
      "xxmaj this play was first performed in 1979 and is a xxunk look at xxmaj irish society , still relevant today . xxeos\n",
      "\n",
      "xxmaj tugann an dráma seo , a léiríodh ar dtús i 1979 , léargas xxunk ar shochaí na héireann , léargas atá fós suntasach inniu .\n",
      "\n",
      "xxmaj an an spraoi seo an ar bhí i dtús i 1979 , agus xxunk ar chumann na héireann , agus ábhartha ábhartha ar sa . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.5831832885742188\n",
      "xxmaj first elections of members of certain public assistance authorities . xxeos\n",
      "\n",
      "xxmaj céad - toghcháin chomhaltaí údarásanna conganta xxunk áirithe .\n",
      "\n",
      "xxmaj na toghcháin toghcháin do údarás cúnaimh phuiblí áirithe . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.514817714691162\n",
      "xxmaj withdrawal xxmaj date of v 1 xxmaj assessments xxeos\n",
      "\n",
      "xxmaj dáta xxmaj xxunk xxmaj measúnaithe l 1\n",
      "\n",
      "xxmaj dáta xxmaj siar v measúnachtaí xxup xxeos xxmaj\n",
      "\n",
      "\n",
      "LOSS: 3.4614880084991455\n",
      "( ii ) certifies that the person , although the person ’s condition is not such as to require the person ’s hospitalisation , is unfit for any questioning for the purpose of the investigation for a specified period , xxeos\n",
      "\n",
      "( ii ) go ndeimhníonn sé nach xxunk an duine chun críche an imscrúdaithe go ceann tréimhse sonraithe , d’ainneoin nach gá an duine a chur isteach in ospidéal de dheasca na baile atá air ,\n",
      "\n",
      "( ii ) go ndeimhneoidh an nó bhfuil an duine , a aon imscrúdaithe ar bhfuil tréimhse sonraithe , cé nach amhlaidh don duine chun cheangal i ar imthosca an shórt xxunk xxunk a sheachaint , xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.3972277641296387\n",
      "xxmaj shoot 2 : xxmaj cruise xxmaj control xxeos\n",
      "\n",
      "xxmaj shoot 2 : cúrsála rialaithe\n",
      "\n",
      "xxmaj shoot 2 : xxmaj xxmaj xxmaj\n",
      "\n",
      "\n",
      "LOSS: 3.344511032104492\n",
      "xxmaj the blue flag campaign today flies in 13 different countries having started life in xxmaj france in 1987 . xxeos\n",
      "\n",
      "xxmaj san xxmaj fhrainc a thosaigh an feachtas seo i 1987 agus anois tá an brat gorm ar foluain i 13 thír éagsúla .\n",
      "\n",
      "xxmaj déanann fheachtas eoraip i cuireadh an feachtas bratach caite 1987 , cuileoga i na feachtas gorm i xxmaj i 13 thír éagsúla a xxmaj\n",
      "\n",
      "\n",
      "LOSS: 3.3257603645324707\n",
      "xxmaj contingency allowances given to compensate for the time required by the workers to perform all necessary additional and periodic activities , e.g. reading drawings , cleaning machinery etc . xxeos\n",
      "\n",
      "liúntais teagmhasacha a tugadh mar chúiteamh ar an am is gá ag na hoibrithe chun gach gníomhaíocht breise agus tréimhsiúla gá , m.sh. líníochtaí léamh , glanadh innealra srl\n",
      "\n",
      "xxmaj teagmhais na thabhairt mar chúiteamh don an am a gá de na hoibrithe chun gach gníomhaíocht bhreise agus thréimhsiúil a a m.sh. ag , , innealra etc etc .\n",
      "\n",
      "\n",
      "LOSS: 3.311084747314453\n",
      "relationship , and supply chain processes . xxeos\n",
      "\n",
      "caidreamh , agus slabhra soláthair próisis .\n",
      "\n",
      "le , próisis próisis soláthair próisis slabhra xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.306642532348633\n",
      "xxmaj in 1963 introduced the first helicopters into service in the xxmaj state and within one year provided a daytime xxmaj search and xxmaj rescue service and within a further year established an inter - hospital air ambulance service , the first of its kind in xxmaj europe . xxeos\n",
      "\n",
      "xxmaj na chéad héileacaptair a thionscnamh i mbun seirbhíse sa xxmaj stát sa bhliain 1963 : soláthraíodh seirbhís xxmaj chuardaigh agus xxmaj tarrthála lae faoi cheann bliana agus bunaíodh seirbhís aerárthaigh othar idir - ospidéil faoi cheann bliana eile , an chéad seirbhís dá leithéid san xxmaj eoraip .\n",
      "\n",
      "i thug chéad uair a tugadh i seirbhís seirbhíse sa xxmaj stát agus bhliain 1963 agus xxmaj an xxmaj cuardaigh agus xxmaj tarrthála agus agus cheann bliana agus laistigh seirbhís ospidéil idir idir - ospidéil bhreise láthair dá breise , an chéad cheann dá chineál san xxmaj eoraip . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.2318711280822754\n",
      "“ in the 25 years since our previous logo was developed , the world has moved from the printed page to an open fluid digital environment where more and more people have access to data . xxeos\n",
      "\n",
      "“ le linn an 25 bliana ó forbraíodh ár sean - lógó , tá an saol mór tar éis bogadh ar aghaidh ó cháipéisí clóite go timpeallacht oscailte solúbtha digiteach ina bhfuil rochtain ar sonraí ag líon méadaithe daoine .\n",
      "\n",
      "“ sa linn an 25 bliana ó rinneadh ár lógó - lógó , tá an domhan bhog ar éis a ón an ar leathanach clóite go dtí digiteach digiteach i i bhfuil rochtain níos níos agus níos daoine agus agus xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.222780704498291\n",
      "xxmaj it takes into account the extent to which individual students ’ characteristics such as gender , age , socio - economic background and prior educational attainment , have an impact on progression . xxeos\n",
      "\n",
      "xxmaj cuireann sé san áireamh an tionchar atá ag éagsúlacht thréithe na mac léinn ar an xxunk , leithéidí inscne , aois , cúlra socheacnamaíoch agus xxunk oideachasúil .\n",
      "\n",
      "xxmaj cuirtear sí san áireamh a méid ar ag mic na na mic léinn aonair leith xxunk , ar , , aois , cúlra eacnamaíoch agus roimh oideachais roimh sula\n",
      "\n",
      "\n",
      "LOSS: 3.1986210346221924\n",
      "xxmaj look at some other items of cutlery . xxmaj can you make drawings of them ? xxeos\n",
      "\n",
      "xxmaj an féidir leat cur síos a dhéanamh air ? xxmaj déan líníocht de . xxmaj amharc ar roinnt míreanna eile sceanra .\n",
      "\n",
      "xxmaj féach féidir leat líníochtaí isteach ar dhéanamh ar ? xxmaj féachaint tú ar roinnt xxmaj is ar roinnt míreanna eile de ? xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.1934149265289307\n",
      "but does not include — xxeos\n",
      "\n",
      "ach ní fholuíonn sí —\n",
      "\n",
      "ach ní fholaíonn sé — ní\n",
      "\n",
      "\n",
      "LOSS: 3.170163154602051\n",
      "xxmaj in all places that were affected by lightning discharges electricity . xxeos\n",
      "\n",
      "i ngach áit xxmaj bhí tionchar ag go tintreach leictreachas sceitheadh .\n",
      "\n",
      "i ngach áiteanna go go tionchar ag scaoileadh raibh scaoileadh scaoilte leictreachais xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.164721727371216\n",
      "xxmaj since 2004 the works programme has focused on preserving the extensive structural remains on the xxmaj south xxmaj peak . xxeos\n",
      "\n",
      "á “ 2004 , xxunk clár na n - oibreacha ar xxunk fairsinge na struchtúr ar an xxunk xxmaj theas a chaomhnú .\n",
      "\n",
      "ó xxup tá tá tá an oibreacha n - oibreacha ar an an atá n mór an xxmaj xxmaj theas a chaomhnú . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.1545069217681885\n",
      "xxmaj please ensure that you provide complete and accurate information ( e.g. on dates of birth and xxup pps numbers ) as failure to do this will delay processing of your application . xxeos\n",
      "\n",
      "xxmaj cinntigh , le do thoil , go soláthraíonn tú faisnéis shoiléir agus chruinn ( dátaí breithe , uimhreacha xxup psp agus sonraí bainc go háirithe ) . xxup má theipeann ort é seo a dhéanamh , beidh moill ar phróiseáil d’iarratais .\n",
      "\n",
      "xxmaj déan go go do thoil go go xxunk tú faisnéis iomlán ( cruinn ( e.g breithe agus agus xxup psp ) uimhreacha xxup xxup mbeidh ) mar xxmaj má dhéantar ar an seo a dhéanamh tuilleadh xxunk tú ar d’iarratas d . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.147977828979492\n",
      "xxmaj fan circulation xxunk optimized for higher efficient heat transfer in the low - temperature application . xxeos\n",
      "\n",
      "xxunk le haghaidh níos airde aistriú teasa éifeachtach i gcur i bhfeidhm íseal\n",
      "\n",
      "xxmaj xxmaj scaipeadh aistriú airde aistriú teasa níos ó bhfeidhm i bhfeidhm teocht –\n",
      "\n",
      "\n",
      "LOSS: 3.143120765686035\n",
      "xxmaj but xxmaj plague knocked people from all those different stalls , but not as many suffered by those of them poor . xxeos\n",
      "\n",
      "xxmaj ach leag plague daoine ó siúd go léir stallaí éagsúla , ach bhí tionchar nach mar go leor acu siúd acu bochta .\n",
      "\n",
      "xxmaj ach tá xxmaj daoine ó gach go léir stallaí éagsúla , ach ní nach ag bhfuil chuid leor ag siúd iad bochta . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.1297659873962402\n",
      "xxmaj poor standards of communication and documentation xxeos\n",
      "\n",
      "droch - chaighdeáin cumarsáide agus doiciméadú\n",
      "\n",
      "xxmaj - caighdeáin na agus doiciméid cumarsáide\n",
      "\n",
      "\n",
      "LOSS: 3.117694139480591\n",
      "xxmaj those who look to achieve the physique of their dreams can look no further than these xxunk , time - tested brands . xxeos\n",
      "\n",
      "xxmaj is féidir leo siúd a thugann aire a bhaint amach an physique a n - aisling breathnú níos faide ná seo xxunk , ama de réir tástála acmhainne brandaí .\n",
      "\n",
      "xxmaj iad féidir leo siúd a breathnú chun a bhaint amach ar dá a bhaint - aisling a a mó ná na xxunk , am - na na - . ama xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.1128244400024414\n",
      "xxmaj this progression is part of the developmental process for the young sailor . xxeos\n",
      "\n",
      "xxmaj is cuid de phróiseas forbartha an mhairnéalaigh óig an dul chun cinn seo .\n",
      "\n",
      "xxmaj is dul den phróiseas forbartha an xxunk do do ea chun cinn seo . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.0744216442108154\n",
      "xxmaj are another generation of xxmaj xxunk children to miss out on the benefits of an all - irish education or will the xxmaj department of xxmaj education and xxmaj skills do the right thing and support xxmaj gaelscoil xxmaj ráth xxup xxunk by giving it official recognition ? ” xxeos\n",
      "\n",
      "“ an bhfuil glúin eile de pháistí xxmaj ráth xxup tó chun an deis sin a chailliúint arís , nó bhfuil an xxmaj roinn xxmaj oideachais agus xxmaj scileanna chun an rud cheart a dhéanamh agus tacú le xxmaj gaelscoil xxmaj ráth xxup tó trí aitheantas a thabhairt di ?\n",
      "\n",
      "xxmaj tá bhfuil glúin eile de leanaí xxmaj xxunk xxmaj xxunk chun aitheantas t a a chailleann as ar ar go an xxmaj roinn xxmaj oideachais agus xxmaj scileanna ag an ceart ceart agus chur agus tacaíocht le xxmaj creidiúnaithe xxmaj ráth xxup xxunk trí aithint oifigiúil thabhairt dó oifigiúil ”\n",
      "\n",
      "\n",
      "LOSS: 3.034301996231079\n",
      "xxmaj the marathon cycle will take place on 28 xxmaj april , so there 's plenty of time to train for the event . xxeos\n",
      "\n",
      "xxmaj beidh an rothaíocht ar siúl ar 28 xxmaj aibreán ; mar sin tá xxunk ama agat le haghaidh traenála chuige .\n",
      "\n",
      "xxmaj beidh an timthriall xxunk siúl an an xxmaj aibreán , agus sin , neart am go chun haghaidh oiliúint ar . xxeos\n",
      "\n",
      "\n",
      "LOSS: 3.0320944786071777\n",
      "xxmaj of the farmers needed more days to erect large structures , such as temple pyramids . xxeos\n",
      "\n",
      "xxmaj as na feirmeoirí ag teastáil níos mó agus níos mó lá gnó le struchtúir mhóra , ar nós pirimidí teampall in airde .\n",
      "\n",
      "xxmaj as na feirmeoirí a teastáil níos mó lá struchtúir mó struchtúir a a struchtúir móra a mar nós na teampall . áirithe . xxeos\n",
      "\n",
      "\n",
      "LOSS: 2.9994633197784424\n",
      "xxmaj undergraduate , xxmaj master 's or phd students xxeos\n",
      "\n",
      "xxmaj mic léinn bunchéime , xxmaj máistreachta nó phd\n",
      "\n",
      "xxmaj mic léinn xxmaj , xxmaj máistir nó mic ,\n",
      "\n",
      "\n",
      "LOSS: 2.971003532409668\n",
      "xxmaj located in the heart of xxmaj europe , several other xxmaj european capitals are only a couple of hours away ( amsterdam , xxmaj paris , xxmaj london ) . xxeos\n",
      "\n",
      "xxmaj is i gcroílár na heorpa atá siad suite , agus níl roinnt príomhchathracha eile ( amstardam , xxmaj páras , xxmaj londain ) ach cúpla uair an chloig taistil uathu .\n",
      "\n",
      "xxmaj suite lánúin gcroílár na heorpa , roinnt , ach agus tá cúpla xxmaj xxmaj xxmaj xxmaj ) xxmaj amstardam , xxmaj londain ) . cúpla uair an chloig de ar . xxeos\n",
      "\n",
      "\n",
      "LOSS: 2.9318175315856934\n",
      "a key work - stream in this unit relates to assessing the xxmaj irish economic implications of xxmaj brexit . xxeos\n",
      "\n",
      "xxmaj ceann de xxunk oibre an aonaid seo ná na himpleachtaí eacnamaíocha a bheidh ag xxmaj imeacht na xxmaj breataine as an xxmaj aontas xxmaj eorpach do éirinn a mheas .\n",
      "\n",
      "xxmaj baineann de na oibre - t seo , baineann xxunk eacnamaíochta na bhaineann ag xxmaj xxunk xxmaj héireann gaeilge - xxmaj xxmaj aontas xxmaj eorpach a bhaint a mheasúnú . xxeos\n",
      "\n",
      "\n",
      "LOSS: 2.9126083850860596\n",
      "xxmaj home page » xxmaj games » xxmaj mutually xxmaj assured xxmaj destruction ( mad ) xxeos\n",
      "\n",
      "xxmaj leathanach xxmaj baile » xxmaj cluichí » xxmaj scrios roicéad\n",
      "\n",
      "xxmaj leathanach xxmaj baile » xxmaj cluichí » xxmaj cinnte xxmaj xxmaj\n",
      "\n",
      "\n",
      "LOSS: 2.9069716930389404\n",
      "xxmaj automatic recording of sickness and absence . xxeos\n",
      "\n",
      "xxmaj breoiteacht agus as láthair taifeadadh go huathoibríoch .\n",
      "\n",
      "xxmaj taifeadadh xxunk taifeadadh láthair a uathoibríoch huathoibríoch . xxeos\n",
      "\n",
      "\n",
      "LOSS: 2.895787239074707\n",
      "xxmaj it shall be embossed with the stamp of the military authority . xxeos\n",
      "\n",
      "xxmaj beidh stampa an údaráis mhíleata múnlaithe air .\n",
      "\n",
      "xxmaj beidh sé ar údaráis mhíleata uirthi . . xxeos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_losses = 50\n",
    "top_losses = loss_sorted_idxs[:n_losses]\n",
    "\n",
    "for i in top_losses:\n",
    "    print(f'LOSS: {float(loss_ls[i])}')\n",
    "    print(en_ls[i])\n",
    "    print()\n",
    "    print(ga_trg_ls[i])\n",
    "    print()\n",
    "    print(ga_pred_ls[i])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show smallest `n` losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.012944857589900494\n",
      "( 2 ) xxmaj this xxmaj act shall come into operation on the 1st day of xxmaj january , 1937 . xxeos\n",
      "\n",
      "( 2 ) xxmaj tiocfaidh an tacht so i ngníomh an 1adh lá d'eanar , 1937 .\n",
      "\n",
      "( 2 ) xxmaj tiocfaidh an tacht so i ngníomh an 1adh lá d'eanar , 1937 . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.012784866616129875\n",
      "( f ) by substituting the following for paragraph 2 of xxmaj schedule 3 : xxeos\n",
      "\n",
      "( f ) tríd an méid seo a leanas a chur in ionad mhír 2 de xxmaj sceideal 3 :\n",
      "\n",
      "( f ) tríd an méid seo a leanas a chur in ionad mhír 2 de xxmaj sceideal 3 : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.012429873459041119\n",
      "xxmaj amendment of section 96 of xxmaj act of 2001 . xxeos\n",
      "\n",
      "xxmaj leasú ar alt 96 d’acht 2001 .\n",
      "\n",
      "xxmaj leasú ar alt 96 d’acht 2001 . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.012094180099666119\n",
      "11 . — this xxmaj act may be cited as the xxmaj transport ( miscellaneous xxmaj provisions ) xxmaj act , 1979 . xxeos\n",
      "\n",
      "11 . — féadfar an tacht xxmaj iompair ( forálacha xxmaj ilghnéitheacha ) , 1979 , a ghairm den xxmaj acht seo .\n",
      "\n",
      "11 . — féadfar an tacht xxmaj iompair ( forálacha xxmaj ilghnéitheacha ) , 1979 , a ghairm den xxmaj acht seo . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.01209115982055664\n",
      "93 . xxmaj amendment of section 1 ( interpretation ) of xxmaj principal xxmaj act . xxeos\n",
      "\n",
      "93 . xxmaj leasú ar alt 1 ( léiriú ) den phríomh - acht .\n",
      "\n",
      "93 . xxmaj leasú ar alt 1 ( léiriú ) den phríomh - acht . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.011882972903549671\n",
      "[ ga ] ( xxrep 3 i ) by inserting the following after paragraph 2 : xxeos\n",
      "\n",
      "( xxrep 3 i ) tríd an méid seo a leanas a chur isteach i ndiaidh mhír 2 :\n",
      "\n",
      "( xxrep 3 i ) tríd an méid seo a leanas a chur isteach i ndiaidh mhír 2 : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.011682409793138504\n",
      "xxmaj number 32 / 2009 : xxmaj criminal xxmaj justice ( amendment ) xxmaj act 2009 xxmaj home xxeos\n",
      "\n",
      "xxmaj uimhir 32 / 2009 : xxmaj an tacht um xxmaj cheartas xxmaj coiriúil ( leasú ) 2009\n",
      "\n",
      "xxmaj uimhir 32 / 2009 : xxmaj an tacht um xxmaj cheartas xxmaj coiriúil ( leasú ) 2009 xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.011207898147404194\n",
      "xxmaj amendment to section 20 of xxmaj act of 2003 . xxeos\n",
      "\n",
      "xxmaj leasú ar alt 20 d’acht 2003 .\n",
      "\n",
      "xxmaj leasú ar alt 20 d’acht 2003 . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.01114108320325613\n",
      "xxmaj central xxmaj bank xxmaj act , 1971 . xxeos\n",
      "\n",
      "xxmaj acht an xxmaj bhainc xxmaj ceannais , 1971 .\n",
      "\n",
      "xxmaj acht an xxmaj bhainc xxmaj ceannais , 1971 . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.01099395751953125\n",
      "“ the xxmaj act of 1995 ” means the xxmaj industrial xxmaj development xxmaj act , 1995 ; xxeos\n",
      "\n",
      "ciallaíonn “ acht 1995 ” an tacht um xxmaj fhorbairt xxmaj tionscail , 1995 ;\n",
      "\n",
      "ciallaíonn “ acht 1995 ” an tacht um xxmaj fhorbairt xxmaj tionscail , 1995 ; xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.010816644877195358\n",
      "45 . — ( 1 ) xxmaj the xxmaj principal xxmaj act is amended by inserting the following section after section 611 : xxeos\n",
      "\n",
      "45 . — ( 1 ) xxmaj leasaítear an príomh - acht tríd an alt seo a leanas a chur isteach i ndiaidh alt 611 :\n",
      "\n",
      "45 . — ( 1 ) xxmaj leasaítear an príomh - acht tríd an alt seo a leanas a chur isteach i ndiaidh alt 611 : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.010740697383880615\n",
      "( xxrep 3 i ) which is not a scheduled ( part xxup i ) pension , and xxeos\n",
      "\n",
      "( xxrep 3 i ) nach pinsean sceidealta ( cuid xxup i ) , agus\n",
      "\n",
      "( xxrep 3 i ) nach pinsean sceidealta ( cuid xxup i ) , agus xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.010490857996046543\n",
      "( 2 ) xxmaj section 11 of the xxmaj act of 1997 is hereby repealed . xxeos\n",
      "\n",
      "( 2 ) xxmaj aisghairtear leis seo alt 11 d'acht 1997 .\n",
      "\n",
      "( 2 ) xxmaj aisghairtear leis seo alt 11 d'acht 1997 . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.010299509391188622\n",
      "22 . — xxmaj the xxmaj second xxmaj schedule to the xxmaj courts and xxmaj court xxmaj officers xxmaj act 1995 is amended by the addition of the following paragraph : xxeos\n",
      "\n",
      "22 . — xxmaj leasaítear an xxmaj dara xxmaj sceideal a ghabhann le hacht na gcúirteanna agus na noifigeach xxmaj cúirte 1995 tríd an mír seo a leanas a chur leis :\n",
      "\n",
      "22 . — xxmaj leasaítear an xxmaj dara xxmaj sceideal a ghabhann le hacht na gcúirteanna agus na noifigeach xxmaj cúirte 1995 tríd an mír seo a leanas a chur leis : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.010137557983398438\n",
      "xxmaj sex ( 3 ) xxmaj general xxmaj health ( 7 ) xxmaj field of xxmaj study ( 45 ) xxeos\n",
      "\n",
      "xxmaj inscne ( 3 ) xxmaj sláinte xxmaj ginearálta ( 7 ) xxmaj réimse xxmaj staidéir ( 45 )\n",
      "\n",
      "xxmaj inscne ( 3 ) xxmaj sláinte xxmaj ginearálta ( 7 ) xxmaj réimse xxmaj staidéir ( 45 ) xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.010010609403252602\n",
      "( b ) by the insertion of the following subsection after subsection ( 1 ) of section 5 : xxeos\n",
      "\n",
      "( b ) tríd an bhfo - alt seo a leanas a chur isteach i ndiaidh fho - alt ( 1 ) d'alt 5 :\n",
      "\n",
      "( b ) tríd an bhfo - alt seo a leanas a chur isteach i ndiaidh fho - alt ( 1 ) d'alt 5 : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.009908217005431652\n",
      "( g ) in subsection ( 9 ) , by substituting for paragraph ( a ) the following : xxeos\n",
      "\n",
      "( g ) i bhfo - alt ( 9 ) , tríd an méid seo a leanas a chur in ionad mhír ( a ) :\n",
      "\n",
      "( g ) i bhfo - alt ( 9 ) , tríd an méid seo a leanas a chur in ionad mhír ( a ) : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.009814311750233173\n",
      "( a ) in paragraph 1 of xxmaj part xxup i , “ £ 158 10s . ” shall be substituted for “ £ 132 ” ( inserted by section 16 of the xxmaj increase xxmaj act of 1961 ) , xxeos\n",
      "\n",
      "( a ) i mír 1 de xxmaj chuid xxup i , cuirfear “ £ 158 10s . ” in ionad “ £ 132 ” ( a cuireadh isteach le halt 16 d'acht xxmaj mhéadú 1961 ) ,\n",
      "\n",
      "( a ) i mír 1 de xxmaj chuid xxup i , cuirfear “ £ 158 10s . ” in ionad “ £ 132 ” ( a cuireadh isteach le halt 16 d'acht xxmaj mhéadú 1961 ) , xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.00944268237799406\n",
      "48 . — xxmaj the xxmaj taxes xxmaj consolidation xxmaj act 1997 is amended by the insertion of the following section after section xxunk : xxeos\n",
      "\n",
      "48 . — xxmaj leasaítear an tacht xxmaj comhdhlúite xxmaj cánacha 1997 tríd an alt seo a leanas a chur isteach i ndiaidh alt xxunk :\n",
      "\n",
      "48 . — xxmaj leasaítear an tacht xxmaj comhdhlúite xxmaj cánacha 1997 tríd an alt seo a leanas a chur isteach i ndiaidh alt xxunk : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.009387349709868431\n",
      "( ii ) on conviction on indictment , to a fine not exceeding £ 100 , xxrep 3 0 or to imprisonment for a term not exceeding five years , or both . xxeos\n",
      "\n",
      "( ii ) ar é a chiontú ar díotáil , fíneáil nach mó ná £ 100 , xxrep 3 0 nó príosúnacht ar feadh téarma nach faide ná cúig bliana , nó iad araon , a chur air .\n",
      "\n",
      "( ii ) ar é a chiontú ar díotáil , fíneáil nach mó ná £ 100 , xxrep 3 0 nó príosúnacht ar feadh téarma nach faide ná cúig bliana , nó iad araon , a chur air . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.009340242482721806\n",
      "( xxrep 3 i ) by inserting the following after paragraph ( c ) : xxeos\n",
      "\n",
      "( xxrep 3 i ) tríd an méid seo a leanas a chur isteach i ndiaidh mhír ( c ) :\n",
      "\n",
      "( xxrep 3 i ) tríd an méid seo a leanas a chur isteach i ndiaidh mhír ( c ) : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.009309934452176094\n",
      "( e ) the substitution of the following subsection for subsection ( 12 ) : xxeos\n",
      "\n",
      "( e ) tríd an bhfo - alt seo a leanas a chur in ionad fho - alt ( 12 ) :\n",
      "\n",
      "( e ) tríd an bhfo - alt seo a leanas a chur in ionad fho - alt ( 12 ) : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.009225739166140556\n",
      "( a ) in subsection ( 1 ) , by substituting for paragraph ( a ) the following : xxeos\n",
      "\n",
      "( a ) i bhfo - alt ( 1 ) , tríd an méid seo a leanas a chur in ionad mhír ( a ) :\n",
      "\n",
      "( a ) i bhfo - alt ( 1 ) , tríd an méid seo a leanas a chur in ionad mhír ( a ) : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.00919419713318348\n",
      "1 . — this xxmaj act may be cited as the xxmaj petroleum and xxmaj other xxmaj minerals xxmaj development xxmaj act , 1960 . xxeos\n",
      "\n",
      "1 . — féadfar an tacht um xxmaj fhorbairt xxmaj pheitriliaim agus xxmaj mianraí xxmaj eile , 1960 , a ghairm den xxmaj acht seo .\n",
      "\n",
      "1 . — féadfar an tacht um xxmaj fhorbairt xxmaj pheitriliaim agus xxmaj mianraí xxmaj eile , 1960 , a ghairm den xxmaj acht seo . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.00910924281924963\n",
      "“ contractor ” has the meaning assigned to it by section 5 ; xxeos\n",
      "\n",
      "tá le “ conraitheoir ” an bhrí a shanntar dó le halt 5 ;\n",
      "\n",
      "tá le “ conraitheoir ” an bhrí a shanntar dó le halt 5 ; xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.008987490087747574\n",
      "xxmaj number 30 / 2007 : xxup part 1 xxmaj preliminary and xxmaj general xxmaj home xxeos\n",
      "\n",
      "xxmaj uimhir 30 / 2007 : xxup cuid 1 xxmaj réamhráiteach agus xxmaj ginearálta\n",
      "\n",
      "xxmaj uimhir 30 / 2007 : xxup cuid 1 xxmaj réamhráiteach agus xxmaj ginearálta xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.008874460123479366\n",
      "“ the xxmaj act of 1952 ” means the xxmaj housing ( amendment ) xxmaj act , 1952 ( no . 16 of 1952 ) ; xxeos\n",
      "\n",
      "ciallaíonn “ acht 1952 ” xxmaj acht na dtithe ( leasú ) , 1952 ( uimh. 16 de 1952 ) ;\n",
      "\n",
      "ciallaíonn “ acht 1952 ” xxmaj acht na dtithe ( leasú ) , 1952 ( uimh. 16 de 1952 ) ; xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.008825826458632946\n",
      "( 2 ) xxmaj this section shall come into operation on the 6th day of xxmaj april , 1983 . xxeos\n",
      "\n",
      "( 2 ) xxmaj tiocfaidh an t - alt seo i ngníomh an 6ú lá d'aibreán , 1983 .\n",
      "\n",
      "( 2 ) xxmaj tiocfaidh an t - alt seo i ngníomh an 6ú lá d'aibreán , 1983 . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.008588433265686035\n",
      "66 . — ( 1 ) xxmaj section 766 of the xxmaj principal xxmaj act is amended — xxeos\n",
      "\n",
      "66 . — ( 1 ) xxmaj leasaítear alt 766 den phríomh - acht —\n",
      "\n",
      "66 . — ( 1 ) xxmaj leasaítear alt 766 den phríomh - acht — xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.008027076721191406\n",
      "“ the xxmaj act of 1976 ” means the xxmaj finance xxmaj act , 1976 ; xxeos\n",
      "\n",
      "ciallaíonn “ acht 1976 ” an tacht xxmaj airgeadais , 1976 ;\n",
      "\n",
      "ciallaíonn “ acht 1976 ” an tacht xxmaj airgeadais , 1976 ; xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.007852774113416672\n",
      "xxmaj type of xxmaj household ( 8) xxmaj religion ( 11 ) censusyear xxeos\n",
      "\n",
      "xxmaj cineál xxmaj teaghlaigh ( 8) xxmaj creideamh ( 11 ) bliaindaonáirimh\n",
      "\n",
      "xxmaj cineál xxmaj teaghlaigh ( 8) xxmaj creideamh ( 11 ) bliaindaonáirimh xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.007078517694026232\n",
      "“ ( xxrep 3 i ) in the case of a person — xxeos\n",
      "\n",
      "“ ( xxrep 3 i ) i gcás duine —\n",
      "\n",
      "“ ( xxrep 3 i ) i gcás duine — xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.007061743643134832\n",
      "28 . — ( 1 ) xxmaj section 224 of the xxmaj principal xxmaj act is hereby amended by the substitution for subsections ( 1 ) and ( 2 ) of the following subsections : xxeos\n",
      "\n",
      "28 . — ( 1 ) xxmaj leasaítear leis seo alt 224 den phríomh - acht trí na fo - ailt seo a leanas a chur in ionad fho - ailt ( 1 ) agus ( 2 ) :\n",
      "\n",
      "28 . — ( 1 ) xxmaj leasaítear leis seo alt 224 den phríomh - acht trí na fo - ailt seo a leanas a chur in ionad fho - ailt ( 1 ) agus ( 2 ) : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.007009965367615223\n",
      "xxmaj the xxmaj finance ( customs xxmaj duties ) ( no . 4 ) xxmaj act , 1932 ( no . 34 of 1932 ) , section 3 . xxeos\n",
      "\n",
      "xxmaj an tacht xxmaj airgid ( diúitéthe xxmaj custum ) ( uimh. 4 ) , 1932 ( uimh. 34 de 1932 ) , alt 3 .\n",
      "\n",
      "xxmaj an tacht xxmaj airgid ( diúitéthe xxmaj custum ) ( uimh. 4 ) , 1932 ( uimh. 34 de 1932 ) , alt 3 . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.006748199462890625\n",
      "( xxrep 3 i ) in subsection ( 5 ) — xxeos\n",
      "\n",
      "( xxrep 3 i ) i bhfo - alt ( 5 ) —\n",
      "\n",
      "( xxrep 3 i ) i bhfo - alt ( 5 ) — xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.006730107590556145\n",
      "2 . — this xxmaj act may be cited as the xxmaj restrictive xxmaj trade xxmaj practices ( confirmation of xxmaj order ) ( no . 3 ) xxmaj act , 1956 . xxeos\n",
      "\n",
      "2 . — féadfar an tacht um xxmaj chleachtais xxmaj srianta xxmaj trádála ( ordú a xxmaj dhaingniú ) ( uimh. 3 ) , 1956 , a ghairm den xxmaj acht seo .\n",
      "\n",
      "2 . — féadfar an tacht um xxmaj chleachtais xxmaj srianta xxmaj trádála ( ordú a xxmaj dhaingniú ) ( uimh. 3 ) , 1956 , a ghairm den xxmaj acht seo . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.006541644688695669\n",
      "xxmaj nature of xxmaj occupancy ( 8) xxmaj towns by xxmaj size ( 205 ) censusyear xxeos\n",
      "\n",
      "xxmaj cineál xxmaj seilbhe ( 8) xxmaj bailte de réir xxmaj méide ( 205 ) bliaindaonáirimh\n",
      "\n",
      "xxmaj cineál xxmaj seilbhe ( 8) xxmaj bailte de réir xxmaj méide ( 205 ) bliaindaonáirimh xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.006427327636629343\n",
      "( a ) by the substitution of “ £ 150 ” for “ twenty pounds ” in paragraph ( a ) , and xxeos\n",
      "\n",
      "( a ) trí “ £ 150 ” a chur in ionad “ fiche punt ” i mír ( a ) , agus\n",
      "\n",
      "( a ) trí “ £ 150 ” a chur in ionad “ fiche punt ” i mír ( a ) , agus xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.005883284844458103\n",
      "35 . — xxmaj section 90 of the xxmaj corporation xxmaj tax xxmaj act , 1976 , is hereby amended by the addition to subsection ( 4 ) ( as amended by the xxmaj act of 1978 ) of the following proviso : xxeos\n",
      "\n",
      "35 . — leasaítear leis seo alt 90 den xxmaj acht xxmaj cánach xxmaj corparáide , 1976 , tríd an gcoinníoll seo a leanas a chur le fo - alt ( 4 ) ( arna leasú le hacht 1978 ) :\n",
      "\n",
      "35 . — leasaítear leis seo alt 90 den xxmaj acht xxmaj cánach xxmaj corparáide , 1976 , tríd an gcoinníoll seo a leanas a chur le fo - alt ( 4 ) ( arna leasú le hacht 1978 ) : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.005392891820520163\n",
      "81 . — section 12 of the xxmaj principal xxmaj act is hereby amended — xxeos\n",
      "\n",
      "81 . — leasaítear leis seo alt 12 den phríomh - acht —\n",
      "\n",
      "81 . — leasaítear leis seo alt 12 den phríomh - acht — xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.005264571402221918\n",
      "2 . — ( 1 ) xxmaj this xxmaj act may be cited as the xxmaj rent xxmaj restrictions ( temporary xxmaj provisions ) ( continuance ) xxmaj act , 1981 . xxeos\n",
      "\n",
      "2 . — ( 1 ) xxmaj féadfar an tacht xxmaj srianta xxmaj cíosa ( forálacha xxmaj sealadacha ) ( buanú ) , 1981 , a ghairm den xxmaj acht seo .\n",
      "\n",
      "2 . — ( 1 ) xxmaj féadfar an tacht xxmaj srianta xxmaj cíosa ( forálacha xxmaj sealadacha ) ( buanú ) , 1981 , a ghairm den xxmaj acht seo . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.004902585409581661\n",
      "xxmaj sex ( 3 ) xxmaj disability xxmaj type ( 14 ) censusyear xxeos\n",
      "\n",
      "xxmaj inscne ( 3 ) xxmaj cineál an xxmaj mhàchumais ( 14 ) bliaindaonáirimh\n",
      "\n",
      "xxmaj inscne ( 3 ) xxmaj cineál an xxmaj mhàchumais ( 14 ) bliaindaonáirimh xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.004811659920960665\n",
      "4 . — the xxmaj act of 1976 is hereby amended by the substitution of the following section for section 29 : xxeos\n",
      "\n",
      "4 . — leasaítear leis seo xxmaj acht 1976 tríd an alt seo a leanas a chur in ionad alt 29 :\n",
      "\n",
      "4 . — leasaítear leis seo xxmaj acht 1976 tríd an alt seo a leanas a chur in ionad alt 29 : xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.004624366760253906\n",
      "7 . — ( 1 ) xxmaj this xxmaj act may be cited as the xxmaj postal and xxmaj telecommunications xxmaj services ( amendment ) xxmaj act , 1984 . xxeos\n",
      "\n",
      "7 . — ( 1 ) xxmaj féadfar an tacht xxmaj seirbhísí xxmaj poist agus xxmaj teileachumarsáide ( leasú ) , 1984 , a ghairm den xxmaj acht seo .\n",
      "\n",
      "7 . — ( 1 ) xxmaj féadfar an tacht xxmaj seirbhísí xxmaj poist agus xxmaj teileachumarsáide ( leasú ) , 1984 , a ghairm den xxmaj acht seo . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.00429901946336031\n",
      "xxmaj sex ( 3 ) xxmaj aggregate xxmaj town or xxmaj rural xxmaj area ( 3 ) xxmaj province xxmaj county or xxmaj city ( 44 ) xxeos\n",
      "\n",
      "xxmaj inscne ( 3 ) xxmaj ceantar xxmaj iomlán xxmaj bhaile nó xxmaj ceantar xxmaj iomlán xxmaj tuaithe ( 3 ) xxmaj cúige , xxmaj contae nó xxmaj cathair ( 44 )\n",
      "\n",
      "xxmaj inscne ( 3 ) xxmaj ceantar xxmaj iomlán xxmaj bhaile nó xxmaj ceantar xxmaj iomlán xxmaj tuaithe ( 3 ) xxmaj cúige , xxmaj contae nó xxmaj cathair ( 44 ) xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.0040727341547608376\n",
      "101 . — ( 1 ) xxmaj the xxmaj principal xxmaj act is amended — xxeos\n",
      "\n",
      "101 . — ( 1 ) xxmaj leasaítear an príomh - acht —\n",
      "\n",
      "101 . — ( 1 ) xxmaj leasaítear an príomh - acht — xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.0039478447288274765\n",
      "56 . — xxmaj section 208 of the xxmaj principal xxmaj act is amended — xxeos\n",
      "\n",
      "56 . — xxmaj leasaítear alt 208 den phríomh - acht —\n",
      "\n",
      "56 . — xxmaj leasaítear alt 208 den phríomh - acht — xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.003833770751953125\n",
      "xxmaj number 5 / 2005 : xxup part 5 xxmaj capital xxmaj acquisitions xxmaj tax xxmaj home xxeos\n",
      "\n",
      "xxmaj uimhir 5 / 2005 : xxup cuid 5 xxmaj cáin xxmaj fháltas xxmaj caipitiúil\n",
      "\n",
      "xxmaj uimhir 5 / 2005 : xxup cuid 5 xxmaj cáin xxmaj fháltas xxmaj caipitiúil xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.0036608653608709574\n",
      "12 . — ( 1 ) xxmaj this xxmaj act may be cited as the xxmaj adoption xxmaj act , 1964 . xxeos\n",
      "\n",
      "12 . — ( 1 ) xxmaj féadfar an tacht xxmaj uchtála , 1964 , a ghairm den xxmaj acht seo .\n",
      "\n",
      "12 . — ( 1 ) xxmaj féadfar an tacht xxmaj uchtála , 1964 , a ghairm den xxmaj acht seo . xxeos\n",
      "\n",
      "\n",
      "LOSS: 0.0034489380195736885\n",
      "xxmaj number 2 / 1 xxrep 3 9 : xxup part 5 xxmaj residential xxmaj property xxmaj tax xxmaj home xxeos\n",
      "\n",
      "xxmaj uimhir 2 / 1 xxrep 3 9 : xxup cuid 5 xxmaj cáin xxmaj mhaoine xxmaj cónaithe\n",
      "\n",
      "xxmaj uimhir 2 / 1 xxrep 3 9 : xxup cuid 5 xxmaj cáin xxmaj mhaoine xxmaj cónaithe xxeos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_losses = 50\n",
    "top_losses = loss_sorted_idxs[-n_losses:]\n",
    "\n",
    "for i in top_losses:\n",
    "    print(f'LOSS: {float(loss_ls[i])}')\n",
    "    print(en_ls[i])\n",
    "    print()\n",
    "    print(ga_trg_ls[i])\n",
    "    print()\n",
    "    print(ga_pred_ls[i])\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_model=pt_Transformer(src_vcbsz=n_x_vocab, trg_vcbsz=n_y_vocab, d_model=d_model, d_inner=d_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_quantized_model = torch.quantization.quantize_dynamic(tmp_model.to('cpu'), {torch.nn.Linear}, dtype=torch.qint8)\n",
    "#print(tmp_quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model.to('cpu'), \n",
    "    {torch.nn.Linear}, \n",
    "    dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_pth_q8 = 'models/paracrawl_en_ga_5e_5e-4_5e_1e-5_v0.2_exp4_no_opt_quantized'\n",
    "state_dict=torch.load(mod_pth_q8, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_quantized_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 346.679325\n",
      "Size (MB): 225.109791\n"
     ]
    }
   ],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(learn.model)\n",
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.model=quantized_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model=quantized_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.dls.to('cpu')\n",
    "learn.dls.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos dia dia duit , conas atá tú ? xxeos'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model.cpu(), \"hello, how are you?\", dls.vocab[1], to_cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ec7698cc6331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hello, how are you?\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-a365c4034e4f>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(model, sentence, vocab)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtranslated_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-a365c4034e4f>\u001b[0m in \u001b[0;36mforward_model\u001b[0;34m(model, src, tgt)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#return output.squeeze(0).to('cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-5c9c38cb5d20>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m                         src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0menc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_tfmr_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_tfmr_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Test whether fp16 is being used or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-cf166625c2a7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#pos = torch.arange(0, inp.size(1), device=inp.device).float()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_sz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1813\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1814\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"hello, how are you?\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/morgan/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m(1814)\u001b[0;36membedding\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1812 \u001b[0;31m        \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1813 \u001b[0;31m        \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1814 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1815 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1816 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> weight.device\n",
      "device(type='cpu')\n",
      "ipdb> input.device\n",
      "device(type='cuda', index=0)\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/morgan/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m(126)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    124 \u001b[0;31m        return F.embedding(\n",
      "\u001b[0m\u001b[0;32m    125 \u001b[0;31m            \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 126 \u001b[0;31m            self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0m\u001b[0;32m    127 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    128 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/morgan/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m(722)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    720 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    721 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 722 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    723 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    724 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> input.device\n",
      "*** AttributeError: 'tuple' object has no attribute 'device'\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-32-cf166625c2a7>\u001b[0m(13)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      9 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m        \u001b[0;31m#pos = torch.arange(0, inp.size(1), device=inp.device).float()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 13 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_sz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_enc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> inp.device\n",
      "device(type='cuda', index=0)\n",
      "ipdb> u\n",
      "> \u001b[0;32m/home/morgan/anaconda3/envs/fastai2_me/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m(722)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    720 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    721 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 722 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    723 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    724 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-63-5c9c38cb5d20>\u001b[0m(20)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     18 \u001b[0;31m                        src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 20 \u001b[0;31m        \u001b[0menc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_tfmr_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_tfmr_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     21 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     22 \u001b[0;31m        \u001b[0;31m# Test whether fp16 is being used or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> src.device\n",
      "device(type='cuda', index=0)\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-82-a365c4034e4f>\u001b[0m(27)\u001b[0;36mforward_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     25 \u001b[0;31m    \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     26 \u001b[0;31m    \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_half\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m    \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m    \u001b[0;31m#return output.squeeze(0).to('cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> tgt.device\n",
      "device(type='cuda', index=0)\n",
      "ipdb> src.device\n",
      "device(type='cuda', index=0)\n",
      "ipdb> u\n",
      "> \u001b[0;32m<ipython-input-82-a365c4034e4f>\u001b[0m(11)\u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      9 \u001b[0;31m    \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m    \u001b[0;32mwhile\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_sentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 11 \u001b[0;31m        \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslated_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     12 \u001b[0;31m        \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m        \u001b[0mtranslated_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> sentence.device\n",
      "device(type='cpu')\n",
      "ipdb> model.device\n",
      "*** torch.nn.modules.module.ModuleAttributeError: 'pt_Transformer' object has no attribute 'device'\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj an féidir leat a insint dúinn i gcás go bhfuil an stáisiún bus le do thoil ? xxeos'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"Can you tell we where the bus station is please?\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj inné xxunk sé , ach amárach beidh amárach a bheith an - xxunk xxeos'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"Yesterday it rained, but tomorrow will be very sunny\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj bhí mé lá mór , xxmaj is é mo aistritheoir ag obair xxeos'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"I had a great day, my translator is working\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj mar sin , tá sé seo scéal ar fad faoi conas mo shaol fuair smeach xxunk síos , mar sin mhaith liom a ghlacadh nóiméad díreach suí ceart go bhfuil , beidh mé go léir faoi conas a tháinig mé an xxunk úr xxeos'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"So this is a story all about how my life got flip turned \\\n",
    "upside down, so I'd like to take a minute just sit right there, I'll you all about how I became the fresh prince\\\n",
    "of belair\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos madra xxeos'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"dog\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos cat cat cat xxeos'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"cat\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos crann crann xxeos'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"tree\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos foirgneamh tógála xxeos'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"building\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos xxmaj cathair cathair cathair xxeos'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"city\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos bean xxeos'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"woman\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos fear xxeos'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"man\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos seacláide xxeos'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"chocolate\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos spásárthach spásárthach xxeos'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(learn.model, \"spaceship\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://forums.fast.ai/t/fastai-v2-text/53529/334\n",
    "from fastai2.text.all import *\n",
    "\n",
    "defaults.device = torch.device('cpu')\n",
    "path = Path('.')\n",
    "learner = load_learner(\"./export.pkl\")\n",
    "\n",
    "f = open(\"/tmp/test.txt\", \"r\")\n",
    "test_file_contents = f.read()\n",
    "\n",
    "_, _, losses = learner.predict(test_file_contents)\n",
    "cats = [learner.dls.categorize.decode(i) for i in range(len(losses))]\n",
    "\n",
    "predictions = sorted(\n",
    "    zip(cats, map(float, losses)),\n",
    "    key=lambda p: p[1],\n",
    "    reverse=True\n",
    ")\n",
    "print(predictions)\n",
    "\n",
    "# OR\n",
    "\n",
    "items = pd.read_csv(\"/tmp/test.txt\", sep = '\\t')\n",
    "test_dl = learner.dls.test_dl(items.values)\n",
    "\n",
    "learner.get_preds(dl=test_dl, with_decoded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
