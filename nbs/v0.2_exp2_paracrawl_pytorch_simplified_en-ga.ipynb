{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v0.2 - Exp2\n",
    "Same as Exp1, but with 30k vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.text.all import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.basics import *\n",
    "import seaborn as sns\n",
    "\n",
    "from einops import rearrange\n",
    "import gc\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#5) [Path('../data/irish/crosslang/en-ga-crosslang.zip'),Path('../data/irish/crosslang/paracrawl_cleaned_en-ga.csv'),Path('../data/irish/crosslang/paracrawl.ga'),Path('../data/irish/crosslang/paracrawl.en'),Path('../data/irish/crosslang/log')],\n",
       " Path('../data/irish/crosslang'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = Path('../data/irish/crosslang')\n",
    "path.ls(), path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746502\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ga</th>\n",
       "      <th>en</th>\n",
       "      <th>ga_len</th>\n",
       "      <th>en_len</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Déan agóid in aghaidh iarratas pleanála : : Fingal County Council</td>\n",
       "      <td>Object to a planning application : : Fingal County Council</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nó cuardach ar ár A-Z</td>\n",
       "      <td>or search our A-Z</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An dteastaíonn Cead Pleanála uait?</td>\n",
       "      <td>Do You Need Planning Permission</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sula dtosaíonn tú ag tógáil</td>\n",
       "      <td>Before you start building</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Déan agóid in aghaidh iarratas pleanála</td>\n",
       "      <td>Object to a planning application</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  ga  \\\n",
       "0  Déan agóid in aghaidh iarratas pleanála : : Fingal County Council   \n",
       "1                                              nó cuardach ar ár A-Z   \n",
       "2                                 An dteastaíonn Cead Pleanála uait?   \n",
       "3                                        Sula dtosaíonn tú ag tógáil   \n",
       "4                            Déan agóid in aghaidh iarratas pleanála   \n",
       "\n",
       "                                                           en  ga_len  en_len  \\\n",
       "0  Object to a planning application : : Fingal County Council      11      10   \n",
       "1                                           or search our A-Z       5       4   \n",
       "2                             Do You Need Planning Permission       5       5   \n",
       "3                                   Before you start building       5       4   \n",
       "4                            Object to a planning application       6       5   \n",
       "\n",
       "   is_valid  \n",
       "0      True  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(path/'paracrawl_cleaned_en-ga.csv')\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "**Remove long texts to make things easier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51.0, 53.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word count 90th percentile\n",
    "np.percentile([o for o in df.en_len.values], 90), np.percentile([o for o in df.ga_len.values], 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 45680 EN samples where len was > 60\n",
      "746502\n",
      "700822\n",
      "Removing 11189 FR samples where len was > 60\n",
      "700822\n",
      "689633\n"
     ]
    }
   ],
   "source": [
    "print(f'Removing {len(df.query(\"en_len > 60\"))} EN samples where len was > 60')\n",
    "print(len(df))\n",
    "df=df[~df.index.isin(df.query(\"en_len > 60\").index)]\n",
    "print(len(df))\n",
    "      \n",
    "print(f'Removing {len(df.query(\"ga_len > 60\"))} FR samples where len was > 60')\n",
    "print(len(df))\n",
    "df=df[~df.index.isin(df.query(\"ga_len > 60\").index)]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.axes._subplots.AxesSubplot at 0x7efbb5161cd0>, 15.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(df['en_len'].values), np.median(df['en_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lowercase everything**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['en'] = df['en'].apply(lambda x:x.lower())\n",
    "df['ga'] = df['ga'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules used as part of tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<function fastai2.text.core.fix_html(x)>,\n",
       " <function fastai2.text.core.replace_rep(t)>,\n",
       " <function fastai2.text.core.replace_wrep(t)>,\n",
       " <function fastai2.text.core.spec_add_spaces(t)>,\n",
       " <function fastai2.text.core.rm_useless_spaces(t)>,\n",
       " <function fastai2.text.core.replace_all_caps(t)>,\n",
       " <function fastai2.text.core.replace_maj(t)>,\n",
       " functools.partial(<function lowercase at 0x7efb8b2d97a0>, add_eos=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_rules=defaults.text_proc_rules[:-1] + [partial(lowercase, add_eos=True)]\n",
    "proc_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load vocab to speed up data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "# at 30k tokens per vocab sometimes this works, sometimes it doesn't\n",
    "\n",
    "# Couldnt process 30k tokens until I added the 'hi' below, it was getting stuck at 94.87%, no idea why\n",
    "@Numericalize\n",
    "def encodes(self, o): \n",
    "    print('hi')\n",
    "    return TensorText(tensor([self.o2i  [o_] for o_ in o]))\n",
    "\n",
    "max_vocab=30000\n",
    "splits = ColSplitter()(df) \n",
    "\n",
    "tfms = [[Tokenizer.from_df(text_cols='en' , rules=proc_rules), attrgetter(\"text\"), Numericalize(max_vocab=max_vocab)], \n",
    "       [Tokenizer.from_df(text_cols='ga', lang='ga', rules=proc_rules), attrgetter(\"text\"), Numericalize(max_vocab=max_vocab)]]\n",
    "\n",
    "dl = partial(SortedDL, shuffle=True)\n",
    "\n",
    "dsets = Datasets(df, tfms, splits=splits, dl_type=dl)\n",
    "\n",
    "# remove the print from Numericalize\n",
    "@Numericalize\n",
    "def encodes(self, o): return TensorText(tensor([self.o2i  [o_] for o_ in o]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_vocab=[]\n",
    "# ga_vocab=[]\n",
    "# with open('paracrawl_vocab_en.csv', newline='') as csvfile:\n",
    "#     v_reader = csv.reader(csvfile, delimiter=',')\n",
    "#     for row in v_reader:\n",
    "#         en_vocab.append(row[0])\n",
    "        \n",
    "# with open('paracrawl_vocab_ga.csv', newline='') as csvfile:\n",
    "#     v_reader = csv.reader(csvfile, delimiter=',')\n",
    "#     for row in v_reader:\n",
    "#         ga_vocab.append(row[0])\n",
    "        \n",
    "#len(en_vocab), len(ga_vocab), en_vocab[:10], ga_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(689633,\n",
       " ((#551742) [1,2,3,4,6,7,9,12,13,14...],\n",
       "  (#137891) [0,5,8,10,11,18,20,25,27,29...]),\n",
       " 7,\n",
       " 8,\n",
       " (TensorText([   2,  152,   61,  497,  442, 1141,    3]),\n",
       "  TensorText([   2,   11, 5234,  542,  715, 3710,  196,    3])))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsets), splits, len(dsets[2][0]), len(dsets[2][1]), dsets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos ( d ) the husband or wife , father , step - father or father - in - law , mother , step - mother or mother - in - law , son , step - son or son - in - law , daughter , step - daughter or daughter - in - law , brother , step - brother or brother - in - law , sister , step - sister or sister - in - law , guardian or trustee , or partner or assistant of any of the persons mentioned in the foregoing paragraphs of this sub - section . xxeos</td>\n",
       "      <td>xxbos ( d ) fear céile nó bean chéile , athair , leas - athair nó athair céile , máthair , leas - mháthair nó máthair chéile , mac , leas - mhac nó xxunk , iníon , leas - iníon , nó xxunk , deartháir , leas - deartháir nó deartháir cleamhnachta , deirfiúr , leas - deirfiúr nó deirfiúr xxunk , caomhnóir nó iontaobhaí , nó páirtnéir nó cúntóir duine ar bith acu san a luaitear sna míreanna san roimhe seo den fho - alt so . xxeos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos [ ga ] ( d ) debentures , debenture stock , certificates of charge or other forms of security issued by the electricity supply board , radio telefís éireann , the industrial credit corporation p.l.c . , bord telecom éireann , irish telecommunications investments p.l.c . , córas iompair éireann , the agricultural credit corporation , limited , bord na móna , aerlínte éireann , teoranta , aer lingus , teoranta or aer rianta , teoranta . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( d ) bintiúir , stoc bintiúir , deimhnithe muirir nó foirmeacha eile urrúis a d'eisigh bord soláthair an leictreachais , radio telefís éireann , corparáid an chairde tionscail c.p.t . , bord telecom éireann , infheistíochtaí teileachumarsáide na héireann c.p.t . , córas iompair éireann , corparáid an chairde talmhaíochta , teoranta , bord na móna , aerlínte éireann , teoranta , aer lingus , teoranta nó aer rianta , teoranta . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxbos ( 2 ) ( a ) in calculating the income , mentioned in paragraph ( b ) of subsection ( 1 ) of section 2 of the old age pensions act , 1911 , of a blind person , no account shall be taken of the earnings of that person except , and in so far as , the annual amount of such earnings is calculated to exceed an amount made up as follows : — xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 2 ) ( a ) nuair a beifear ag ríomh an ioncaim , a luaitear i mír ( b ) d'fho - alt ( 1 ) d'alt 2 den old age pensions act , 1911 , atá ag dall , ní tabharfar aon aird ar thuilleamh an daill sin ach amháin má háirítear , agus a mhéid a háirítear , suim bhliantúil an tuillimh sin a bheith níos mó ná suim arna comhdhéanamh mar leanas : — xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxbos ( 2 ) in section 55 ( 4 ) of the finance act , 1974 , for “ section 214 of the income tax act , 1967 , ” there shall be substituted “ section 15 or 33 ( 2 ) of the corporation tax act , 1976 , ” , and the said section 55 ( 4 ) , as so amended , is set out in the table to this subparagraph . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 2 ) in alt 55 ( 4 ) den acht airgeadais , 1974 , cuirfear “ le halt 15 nó 33 ( 2 ) den acht cánach corparáide , 1976 ” in ionad “ le halt 214 den acht cánach ioncaim , 1967 ” , agus tá an t - alt sin 55 ( 4 ) , arna leasú amhlaidh , leagtha amach sa tábla a ghabhann leis an bhfomhír seo . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxbos ( 4 ) the duty of excise on gaseous hydrocarbons in liquid form imposed by section 41 ( 1 ) of the finance act , 1976 , shall be charged , levied and paid , as on and from the 29th day of january , 1981 , at the rate of £ xxunk per gallon in lieu of the rate specified in section xxunk ) of the act of 1980 . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 4 ) déanfar an dleacht máil ar hidreacarbóin xxunk i bhfoirm leachtach a fhorchuirtear le halt 41 ( 1 ) den acht airgeadais , 1976 , a mhuirearú , a thobhach agus a íoc , amhail ar an agus ón 29ú lá d'eanáir , 1981 , de réir £ xxunk an galún in ionad an ráta a shonraítear in alt 70 ( 14 ) d'acht 1980 . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xxbos ( 3 ) this section applies to the following countries , that is to say , the united states of america , the dominion of canada , the commonwealth of australia , the dominion of new zealand , the union of south africa , and xxunk , and also to every country which is a british possession within the meaning of schedule c of the income tax act , 1918 . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 3 ) baineann an t - alt so leis na tíortha so leanas , sé sin le rá , stáit aontuithe xxunk , tiarnas cheanada , xxunk na hastráile , tiarnas na xxunk nua , xxunk na xxunk theas , agus talamh an eisc , agus fós le gach tír is xxunk briotáineach do réir bhrí sceidil c den income tax act , 1918 . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xxbos 38 . — ( 1 ) the authority may make a grant , on such terms and conditions as it thinks proper , towards the cost of fixed assets required for the re - equipment , modernisation , improvement or expansion of an industrial undertaking or in respect of fixed assets leased by an industrial undertaking for the re - equipment , modernisation , improvement or expansion of the undertaking . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos 38 . — ( 1 ) féadfaidh an tudarás deontas a thabhairt , ar cibé téarmaí agus coinníollacha is cuí leis , faoi chomhair costais sócmhainní dochta a bheidh ag teastáil le haghaidh gnóthas tionscail a xxunk , a xxunk , a fheabhsú nó a mhéadú , nó i leith sócmhainní a xxunk gnóthas tionscail le haghaidh an gnóthas a xxunk , a xxunk , a fheabhsú nó a mhéadú . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxbos ( 2 ) the trustee act , 1 xxrep 3 8 , so far as unrepealed , the trustee act , 1893 , the trustee act , 1893 , amendment act , 1894 , section 18 of the adaptation of enactments act , 1922 ( no . 2 of 1922 ) , and this act may be cited together as the trustee acts , 1 xxrep 3 8 to 1931 . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos ( 2 ) féadfar achtanna na niontaobhaithe , 1 xxrep 3 8 go 1931 , do ghairm den trustee act , 1 xxrep 3 8 , sa mhéid ná fuil sé athghairmthe , den trustee act , 1893 , den trustee act , 1893 , amendment act , 1894 , d'alt 18 den acht um oiriúnú achtanna , 1922 ( uimh. 2 de 1922 ) , agus den acht so le chéile . xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xxbos 4 . — ( 1 ) before making any credit - sale agreement under which the total purchase price exceeds five pounds , the seller shall state in writing to the prospective buyer , otherwise than in the note or memorandum of the agreement , a price at which the goods may be purchased by him for cash ( in this section referred to as the cash price ) : xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "      <td>xxbos 4 . — ( 1 ) sar a ndéantar aon chomhaontú díola - ar - cáirde faoinar mó ná cúig puint an praghas ceannaigh iomlán , sonróidh an díoltóir i scríbhinn don cheannaitheoir ionchasach , ar shlí seachas i nóta nó i xxunk an chomhaontuithe , praghas ar a bhféadfaidh sé na hearraí a cheannach ar réidh - airgead ( dá ngairmtear an praghas réidh - airgid san alt seo ) : xxeos xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs,sl = 48, 108\n",
    "dls = dsets.dataloaders(bs=bs, seq_len=sl, before_batch=partial(pad_input, pad_fields=[0,1]))\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save vocab to speed up data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('paracrawl_vocab_en_v0.2_exp2.csv', 'w', newline='') as csvfile:\n",
    "#     v_writer = csv.writer(csvfile, delimiter=',')\n",
    "#     for l in dls.vocab[0]:\n",
    "#         v_writer.writerow([l])\n",
    "        \n",
    "# with open('paracrawl_vocab_ga_v0.2_exp2.csv', 'w', newline='') as csvfile:\n",
    "#     v_writer = csv.writer(csvfile, delimiter=',')\n",
    "#     for l in dls.vocab[1]:\n",
    "#         v_writer.writerow([l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(689633, 11494, 2873)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.train_ds)+len(dls.valid_ds), len(dls.train), len(dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab lengths are : (30008, 30008)\n"
     ]
    }
   ],
   "source": [
    "print(f'Vocab lengths are : {len(dls.vocab[0]), len(dls.vocab[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 106]),\n",
       " torch.Size([48, 90]),\n",
       " (TensorText([[   2,   15,  197,  ...,   31,   12,    3],\n",
       "          [   2, 1247, 1475,  ...,    1,    1,    1],\n",
       "          [   2,   15,   75,  ...,    1,    1,    1],\n",
       "          ...,\n",
       "          [   2,   15,   46,  ...,    1,    1,    1],\n",
       "          [   2,   24, 1739,  ...,    1,    1,    1],\n",
       "          [   2,   20,  622,  ...,    1,    1,    1]], device='cuda:0'),\n",
       "  TensorText([[    2,    13,   202,  ...,    90,    12,     3],\n",
       "          [    2,  1246,  1179,  ...,     1,     1,     1],\n",
       "          [    2,    13,    94,  ...,     3,     1,     1],\n",
       "          ...,\n",
       "          [    2,    13,    47,  ...,     1,     1,     1],\n",
       "          [    2,  7416,    11,  ...,     1,     1,     1],\n",
       "          [    2,    32, 11761,  ...,     1,     1,     1]], device='cuda:0')))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o=dls.one_batch(); o[0].size(), o[1].size(), o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Encode the position with a sinusoid.\"\n",
    "    def __init__(self, d):\n",
    "        super().__init__()\n",
    "        self.register_buffer('freq', 1 / (10000 ** (torch.arange(0., d, 2.)/d)))\n",
    "    \n",
    "    def forward(self, pos):\n",
    "        inp = torch.ger(pos, self.freq)\n",
    "        enc = torch.cat([inp.sin(), inp.cos()], dim=-1)\n",
    "        return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEmbedding(nn.Module):\n",
    "    \"Embedding + positional encoding + dropout\"\n",
    "    def __init__(self, vocab_sz, emb_sz, inp_p=0.):\n",
    "        super().__init__()\n",
    "        self.emb_sz = emb_sz\n",
    "        self.embed = Embedding(vocab_sz, emb_sz)\n",
    "        self.pos_enc = PositionalEncoding(emb_sz)\n",
    "        self.drop = nn.Dropout(inp_p)\n",
    "    \n",
    "    def forward(self, inp): \n",
    "        pos = torch.arange(0, inp.size(1), device=inp.device).float()        \n",
    "        return self.drop(self.embed(inp) * math.sqrt(self.emb_sz) + self.pos_enc(pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Transformer Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: [src/tgt/memory]_mask should be filled with float(‘-inf’) for the masked positions and float(0.0) else. These masks ensure that predictions for position i depend only on the unmasked positions j and are applied identically for each sequence in a batch. \n",
    "\n",
    "[src/tgt/memory]_key_padding_mask should be a ByteTensor where True values are positions that should be masked with float(‘-inf’) and False values will be unchanged. This mask ensures that no information will be taken from position i if it is masked, and has a separate mask for each sequence in a batch.\n",
    "\n",
    "attn mask with -inf\n",
    "key_padding mask with True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pt_Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class pt_Transformer(Module):\n",
    "    def __init__(self, src_vcbsz, trg_vcbsz, n_enc_layers=6, n_dec_layers=6, n_heads=8, d_model=256, d_head=32, \n",
    "                 d_inner=1024, p=0.1, bias=True, scale=True, double_drop=True, pad_idx=1):\n",
    "        self.pad_idx = pad_idx\n",
    "        self.enc_tfmr_emb = TransformerEmbedding(src_vcbsz, d_model, p)\n",
    "        self.dec_tfmr_emb = TransformerEmbedding(trg_vcbsz, d_model, 0.)        \n",
    "        self.final = nn.Linear(d_model, trg_vcbsz)\n",
    "        \n",
    "        # !!!\n",
    "        #self.final.weight = self.dec_tfmr_emb.embed.weight    # !! What does this do?\n",
    "        \n",
    "        self.transformer_model=torch.nn.Transformer(d_model=d_model, nhead=n_heads, num_encoder_layers=n_enc_layers, \n",
    "                                   num_decoder_layers=n_dec_layers, dim_feedforward=d_inner, dropout=p, \n",
    "                                   activation='relu', custom_encoder=None, custom_decoder=None)\n",
    "    \n",
    "    \n",
    "    def forward(self, src, trg, src_mask=None, tgt_mask=None, memory_mask=None, \n",
    "                        src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "        \n",
    "        enc_emb, dec_emb = self.enc_tfmr_emb(src), self.dec_tfmr_emb(trg)\n",
    "        \n",
    "        src_mask=self.transformer_model.generate_square_subsequent_mask(src.size(1)).cuda()\n",
    "        trg_mask=self.transformer_model.generate_square_subsequent_mask(trg.size(1)).cuda()\n",
    "        \n",
    "        dec_out = self.transformer_model(enc_emb.permute(1,0,2), dec_emb.permute(1,0,2),\n",
    "                                         src_mask=src_mask, tgt_mask=trg_mask, memory_mask=None, \n",
    "                        src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "        \n",
    "        out=self.final(dec_out)\n",
    "        \n",
    "        return out.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusBLEUMetric(Metric):\n",
    "    def __init__(self, vocab_sz=5000, axis=-1):\n",
    "        \"\"\"BLEU Metric calculated over the validation corpus\"\"\"\n",
    "        self.pred_len, self.targ_len, self.corrects, self.counts = 0,0,[0]*4,[0]*4\n",
    "        self.axis, self.vocab_sz = axis, vocab_sz\n",
    "        \n",
    "    def reset(self):\n",
    "        self.pred_len,self.targ_len,self.corrects,self.counts = 0,0,[0]*4,[0]*4\n",
    "        \n",
    "    class NGram():\n",
    "        def __init__(self, ngram, max_n=5000): self.ngram,self.max_n = ngram,max_n\n",
    "        def __eq__(self, other):\n",
    "            if len(self.ngram) != len(other.ngram): return False\n",
    "            return np.all(np.array(self.ngram) == np.array(other.ngram))\n",
    "        def __hash__(self): return int(sum([o * self.max_n**i for i,o in enumerate(self.ngram)]))\n",
    "    \n",
    "    def get_grams(self, x, n, max_n=5000):\n",
    "        return x if n==1 else [self.NGram(x[i:i+n], max_n=max_n) for i in range(len(x)-n+1)]\n",
    "    \n",
    "    def get_correct_ngrams(self, pred, targ, n, max_n=5000):\n",
    "        pred_grams,targ_grams = self.get_grams(pred, n, max_n=max_n),self.get_grams(targ, n, max_n=max_n)\n",
    "        pred_cnt,targ_cnt = Counter(pred_grams),Counter(targ_grams)\n",
    "        return sum([min(c, targ_cnt[g]) for g,c in pred_cnt.items()]),len(pred_grams)\n",
    "        \n",
    "    def accumulate(self, learn):\n",
    "        last_output = learn.pred.argmax(dim=self.axis)\n",
    "        last_target = learn.y\n",
    "        for pred,targ in zip(last_output.cpu().numpy(),last_target.cpu().numpy()):\n",
    "            self.pred_len += len(pred)\n",
    "            self.targ_len += len(targ)\n",
    "            for i in range(4):\n",
    "                c,t = self.get_correct_ngrams(pred, targ, i+1, max_n=self.vocab_sz)\n",
    "                self.corrects[i] += c\n",
    "                self.counts[i]   += t\n",
    "        \n",
    "    @property\n",
    "    def value(self): \n",
    "        if self.counts == 0: return None\n",
    "        else:\n",
    "            precs = [c/t for c,t in zip(self.corrects,self.counts)]\n",
    "            len_penalty = exp(1 - self.targ_len/self.pred_len) if self.pred_len < self.targ_len else 1\n",
    "            return len_penalty * ((precs[0]*precs[1]*precs[2]*precs[3]) ** 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "#### Present Input and Target in a single tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineInputOutputCallback(Callback):\n",
    "    '''Callback to combine the input and target text into self.xb'''\n",
    "    def __init__(self): pass\n",
    "    def begin_batch(self): \n",
    "        self.learn.xb = (self.xb[0], self.yb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting and masking of y, from [Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html#training):\n",
    "\n",
    "> We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target shift/offset explained\n",
    "\n",
    "**Taken from [@bentrevett's brilliant github repo \"pytorch-seq2seq\" tutorials](https://github.com/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb):**\n",
    "\n",
    "As we want our model to predict the <eos> token but not have it be an input into our model we simply slice the <eos> token off the end of the sequence. Thus:\n",
    "\n",
    "$$\\begin{align*}\\text{trg} &= [sos, x_1, x_2, x_3, eos]\\\\\\text{trg[:-1]} &= [sos, x_1, x_2, x_3]\\end{align*}$$\n",
    "\n",
    "$x_i$ denotes **actual** target sequence element. We then feed this into the model to get a predicted sequence that should hopefully predict the <eos> token:\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, eos]\n",
    "\\end{align*}$$\n",
    "\n",
    "$y_i$ denotes **predicted** target sequence element. We then calculate our loss using the original trg tensor with the <sos> token sliced off the front, leaving the <eos> token:\n",
    "\n",
    "$$\\begin{align*} \\text{output} &= [y_1, y_2, y_3, eos]\\\\ \\text{trg[1:]} &= [x_1, x_2, x_3, eos] \\end{align*}$$\n",
    "\n",
    "We then calculate our losses and update our parameters as is standard.\n",
    "    \n",
    "    \n",
    "We don't want to punish the model for not translating the 'sos' token, but we do need it to predict/define the end of the sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RemoveEOSCallback** \n",
    "\n",
    "Cut the *EOS* token token from the **output_x** presented to the model as we are trying to predict the next word. Therefore don't want to model to try anything after the *EOS* token. So the last token given to the model will be the token before *EOS*. This callback is modifies the second element of our learn.xb, (which is the *copied* yb)\n",
    "\n",
    "But this should also ignore padding, as otherwise we'll be just cutting the last padding token and not the EOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemoveEOSCallback(Callback):\n",
    "    '''\n",
    "        Shift the target presented to the model during training to remove the \"eos\" token as \n",
    "        we don't want the model to learn to translate EOS. When it sees EOS.\n",
    "        \n",
    "        In practice we actually mask the EOS token as due to batching the last token will often be a <pad> token,\n",
    "        not EOS\n",
    "    '''\n",
    "    def __init__(self, eos_idx): self.eos_idx=eos_idx\n",
    "    def begin_batch(self):        \n",
    "        eos_mask=(self.learn.xb[1]!=self.eos_idx)\n",
    "        sz=torch.tensor(self.learn.xb[1].size())\n",
    "        sz[1]=sz[1]-1\n",
    "        self.learn.xb = (self.learn.xb[0], self.learn.xb[1][eos_mask].view((sz[0],sz[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LossTargetShiftCallback:** Shift the target shown to the loss to exclude the \"eos\" token, as translating \"bos\" is not part of our language translation objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossTargetShiftCallback(Callback):\n",
    "    '''\n",
    "        Shift the target shown to the loss to exclude the \"bos\" token as the first token we want predicted\n",
    "        should be an actual word, not the \"bos\" token (as we have already given the model \"bos\" )\n",
    "    '''\n",
    "    def __init__(self): pass\n",
    "    def after_pred(self): \n",
    "        self.learn.yb = (self.learn.yb[0][:,1:],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer size from Annotated Transformer:\n",
    "\n",
    "N=6, d_model=512, d_ff=2048, h=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pad_idx=1\n",
    "assert dls.vocab[1][pad_idx] == 'xxpad' \n",
    "n_x_vocab, n_y_vocab = len(dls.vocab[0]), len(dls.vocab[1])\n",
    "d_model=512\n",
    "n_heads=8 #12\n",
    "d_inner=2048  #1024\n",
    "\n",
    "#model = Transformer(n_x_vocab, n_y_vocab, d_model=d_model, n_heads=n_heads, pad_idx=pad_idx)\n",
    "\n",
    "model=pt_Transformer(src_vcbsz=n_x_vocab, trg_vcbsz=n_y_vocab, d_model=d_model, d_inner=d_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pt_Transformer(\n",
       "  (enc_tfmr_emb): TransformerEmbedding(\n",
       "    (embed): Embedding(30008, 512)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (dec_tfmr_emb): TransformerEmbedding(\n",
       "    (embed): Embedding(30008, 512)\n",
       "    (pos_enc): PositionalEncoding()\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (final): Linear(in_features=512, out_features=30008, bias=True)\n",
       "  (transformer_model): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaiming_Normal works terrribly, at least if you apply it to everything except LayerNorm...\n",
    "\n",
    "DistilBERT works ok\n",
    "\n",
    "Could try xavier:\n",
    "\n",
    "```\n",
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.apply(initialize_weights);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DistilBERT initialisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DistilERT HF init weights https://github.com/huggingface/transformers/blob/31e67dd19f1b3fe2bc9a13f86d814f3f7bba48e4/src/transformers/modeling_distilbert.py\n",
    "\n",
    "def distil_apply_leaf(m, f):\n",
    "    \"Apply `f` to children of `m`.\"\n",
    "    c = m.children()\n",
    "    if isinstance(m, nn.Module): f(m)\n",
    "    for l in c: apply_leaf(l,f)\n",
    "\n",
    "\n",
    "def _distilbert_init_weights(module):\n",
    "    \"\"\" Initialize the weights.\n",
    "    \"\"\"\n",
    "    if isinstance(module, nn.Embedding):\n",
    "        if module.weight.requires_grad:\n",
    "            module.weight.data.normal_(mean=0.0, std=0.02) #std=self.config.initializer_range)\n",
    "    if isinstance(module, nn.Linear):\n",
    "        module.weight.data.normal_(mean=0.0, std=0.02) #self.config.initializer_range)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n",
    "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "        module.bias.data.zero_()\n",
    "\n",
    "distil_apply_leaf(model, _distilbert_init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 90,262,840 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbs = [CombineInputOutputCallback, RemoveEOSCallback(eos_idx=3), LossTargetShiftCallback]\n",
    "\n",
    "pad_idx=1\n",
    "assert dls.vocab[1][pad_idx] == 'xxpad' \n",
    "loss_func = CrossEntropyLossFlat(ignore_index=pad_idx)\n",
    "\n",
    "learn = Learner(dls, model, metrics=[accuracy, Perplexity(), CorpusBLEUMetric(vocab_sz=n_y_vocab)], \n",
    "                cbs=cbs, loss_func=loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.load('paracrawl_en_ga_5e_5e-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.002754228748381138, lr_steep=0.001737800776027143)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhb1Z3/8fdX3rfYsWNnd0IWEgghgZglbElaSihlIMC0HYaZ0pYpQ6cd2umUlg6/36/PtKV0pu3QAu20lLUUmKFQWtYSyhYCBMgKIQmQzc4e744tW7Kk8/tDMjEmi51YulfW5/U8eixdXfl8okfR1+eee88x5xwiIpK5Al4HEBERb6kQiIhkOBUCEZEMp0IgIpLhVAhERDKcCoGISIZLWiEws7vMbK+ZrT3Ac980M2dmI5LVvoiI9E8yewT3AOf33Whm44FPAHVJbFtERPopaYXAObcEaDrAUzcD3wJ0JZuIiA+kdIzAzC4Cdjjn1qSyXRERObjsVDVkZoXADcB5/dz/auBqgKKiojnTp09PYjoRkaFnxYoVDc65ysPtl7JCAEwGjgHWmBnAOGClmZ3qnNvdd2fn3O3A7QA1NTVu+fLlKYwqIpL+zKy2P/ulrBA4594Gqnoem9lWoMY515CqDCIi8lHJPH30QeA1YJqZbTezq5LVloiIHLmk9Qicc5cf5vmJyWpbRET6T1cWi4hkOBUCEZEMp0IgIpLhVAhERHyoNdjN4nd209AeSnpbKgQiIj60sb6dq+9bwTs725LelgqBiIgPBcMRAIpys5LelgqBiIgPdYSiABTmJv+6XxUCEREf6gjFewTFeSoEIiIZqefQUGGeDg2JiGSkjnD80FCRDg2JiGSmYChCwCA/J/lf0yoEIiI+1B6KUpSbTWLa/qRSIRAR8aFgOJKS8QFQIRAR8aWOcDQl4wOgQiAi4kvBkHoEIiIZrT0UUY9ARCSTBcNRilJwMRmoEIiI+FJHOEJhCuYZAhUCERFfCoY0WCwiktE6NFgsIpK5nHN0hCMpmXAOVAhERHwnFIkRc6mZghpUCEREfKdnCuoiHRoSEclMqVyUBlQIRER8pyPcsyiNegQiIhnpg0Vp1CMQEclMPYeGNEYgIpKhegaL1SMQEclQPctU6joCEZEMtX+MIM0PDZnZXWa218zW9tr2fTN7y8xWm9liMxuTrPZFRNLV/jGC9O8R3AOc32fbj51zJzrnZgNPAP8vie2LiKSljsTC9XnZqTlok7RWnHNLgKY+29p6PSwCXLLaFxFJVx3hCEV5qVm4HiA1/Y5ezOxG4HNAK7DgEPtdDVwNUF1dnZpwIiI+kMopqMGDwWLn3A3OufHA/cBXD7Hf7c65GudcTWVlZeoCioh4rCOcuimowduzhh4ALvOwfRERX+pI4XrFkOJCYGZTez28CNiQyvZFRNJBRziasquKIYljBGb2IDAfGGFm24HvAheY2TQgBtQC1ySrfRGRdBUMRxhZkp+y9pJWCJxzlx9g853Jak9EZKgIhqIUjhiih4ZEROTw2kMRilJ0VTGoEIiI+E4wHE3ZVcWgQiAi4is9C9erRyAikqG6umM4B4XqEYiIZKb2noXr1SMQEclMPVNQa4xARCRD9UxBnarVyUCFQETEV/b3CHRoSEQkI7WneL1iUCEQEfGVYIrXKwYVAhERX+kIpXa9YlAhEBHxlZ4egc4aEhHJUO3qEYiIZLZgOEJ2wFK2cD2oEIiI+EpHKEphblbKFq4HFQIREV8JhiMpHR8AFQIREV/p6RGkkgqBiIiPdIQjKb2GAFQIRER8JRiKpvSqYlAhEBHxlY5wJKXzDIEKgYiIr3SEIuoRiIhkso4Ur1cMKgQiIr4SDKV2vWJQIRAR8Y1YzBHsjqZ0vWJQIRAR8Y3O7ijOpXa9YlAhEBHxjQ4P1isGFQIREd8IhnqmoFaPQEQkI/X0CHT6qIhIhuro6REMlUJgZneZ2V4zW9tr24/NbIOZvWVmj5pZWbLaFxFJN/vHCIbOoaF7gPP7bHsWOME5dyLwHvCdJLYvIpJW9o8RDJEegXNuCdDUZ9ti51wk8XAZMC5Z7YuIpJv9YwRDp0dwOF8EnvawfRERX+lIrFc8ZMYIDsXMbgAiwP2H2OdqM1tuZsvr6+tTF05ExCPB8BA7NHQwZnYlcCFwhXPOHWw/59ztzrka51xNZWVl6gKKiHikIxQhJ8vITeHC9QApLTtmdj7wbWCecy6YyrZFRPwuGE79ojSQ3NNHHwReA6aZ2XYzuwq4DSgBnjWz1Wb2q2S1LyKSbto9mHkUktgjcM5dfoDNdyarPRGRdBcMR1I+PgC6slhExDc6QqmfghpUCEREfCMY9ubQkAqBiIhP7OvSoSERkYzW1tlNaUFOyttVIRAR8YlWFQIRkczVHY3REY5SpkIgIpKZWju7ASgtVCEQEclIHxQC9QhERDJTSzBeCIapEIiIZKa2RI9AYwQiIhlKh4ZERDKcCoGISIbTGIGISIZr7eymOC+bnKzUfy2rEIiI+IBXVxWDCoGIiC+0dnZ7clgIVAhERHyhtTNMaUHqZx4FFQIREV9o7eymrCDXk7b7VQjMbLKZ5SXuzzeza82sLLnRREQyRzqMETwCRM1sCvF1h48BHkhaKhGRDNPa2e3JhHPQ/0IQc85FgEuAnznn/gUYnbxYIiKZo6s7Sld3zPc9gm4zuxy4Engisc2bxCIiQ0ybh1cVQ/8LwReAucCNzrktZnYM8LvkxRIRyRxeTi8B0K9zlZxz64BrAcxsOFDinPtRMoOJiGQKrwtBf88aetHMhplZObAGuNvM/iu50UREMkPPPEO+LgRAqXOuDbgUuNs5Nwc4N3mxREQyR0+PoMznZw1lm9lo4DPsHywWEZFBkBaHhoDvAc8Am5xzb5rZJOD95MUSEckcPYWgJN/fg8W/B37f6/Fm4LJkhRIRySStnd2U5GeTFTBP2u/vYPE4M3vUzPaa2R4ze8TMxh3mNXcl9l/ba9unzewdM4uZWc3RhhcRGQpaO7s9Gx+A/h8auht4DBgDjAUeT2w7lHuA8/tsW0t8wHlJ/yOKiAxtXs4zBP0vBJXOubudc5HE7R6g8lAvcM4tAZr6bFvvnHv3yKKKiAxN6VIIGszs78wsK3H7O6AxmcFERDJFSzCcFoXgi8RPHd0N7AL+mvi0E0ljZleb2XIzW15fX5/MpkREPNXaGaHUo7UIoJ+FwDlX55y7yDlX6Zyrcs4tIn6sP2mcc7c752qcczWVlYc8CiUikracc7SlyaGhA/nGoKUQEclQXd0xwlHvpqCGoysEhzzh1cweBF4DppnZdjO7yswuMbPtxGcyfdLMnjmK9kVE0l5LZxjw7qpi6OcFZQfhDvmkc5cf5KlHj6JNEZEhxet5huAwhcDM9nHgL3wDCpKSSEQkg7R6PPMoHKYQOOdKUhVERCQTeT3hHBzdGIGIiBylFhUCEZHM9sF6xWkw15CIiCRBa2c3AYPi3KM5d+foqBCIiHiotbObYQU5BDyaghpUCEREPNUS9PaqYlAhEBHxVGtnN2UqBCIimavn0JCXVAhERDzk9VoEoEIgIuIpFQIRkQzmnPN8vWJQIRAR8UxHOEo05tQjEBHJVC1B76egBhUCERHP+GHCOVAhEBHxzP5C4N16xaBCICLimTb1CEREMtuethAAFcXqEYiIZKRVdc1UleRRVZLnaQ7v5j1NgT+u2sHy2ibKC3MZXpRLeVEuo0sLqC4vpKokz9PZ/kREVtQ1M2fCcMy8/S4a0oXg/b37eOrt3TQHw7g+Ky/nZgc4pqKIM6eMYN60Sk47ppz8nCwgfpFHd9QRjTkisRjRWPxxKBIlHIkRisQ+9LM7GiPm4vvHHJhBdsAIBIwsM6LOEYvFnw+YkZMdICdgZGcFCBiY2Qevyc/JIi87QF52Fvk58Z+52QGyVLREhpS9bV1sa+rkyrkTvY4ytAvBdQunc93C6URjjrbObho7Quxo6WJbU5BtTUHW7Wrjd6/XctcrW8jLDlBRlEtHOEpHKEIk5g7fQAplB4zc7AA5WQFyswMU52VTWpDD8MIcSgty9heQnCxyE/vkZgfIyw5QmJtFYW42RXnxn8PycyjJz2ZYQQ4lednqGYl4YGVdMwAnTxjucZIhXgh6ZAWM4UXxw0NTqko+9FxnOMrrWxpZ8l4DbV3dFOdlJ744s8jOCsT/sjcjJ8s++Os8NztAfk6A3Kws8nLi+2Ql9jMD5yDmHJGYwzmHWbxnkBUwYoneRnc0RiTqiLn4zQHRqCMUidHVHaWrV+8j1B2jKxIlEo0leiYx2kMRWoJh6ttDbKxvJ9Sd2DcSJRSJfaQHdDDZAaO8KJeK4jzKi3IoyMmmIDeLgpwAI4rzmFhRxMQRRUysKKSyJM/zLqzIULGitpnc7AAzxgzzOkpmFIJDKcjNYv60KuZPq/I6yqCKRGOEo/Ei0tkd7+X09Hb2dXXT1hmhraubpo4wje1hGjtCNAe7ae7opKs7SjAcpaE99KGeUW52gDGl+YwdXsCoYQVUJga5qoblMaasgHHDC6gsVrEQ6Y8Vtc2cOLaUvOwsr6OoEAxV2VkBsrMCFObCkXY8I9EYO1o62dLQQW1jkJ0tnexI3F7d1EBDe4ju6Ie7HnnZAcYNL2BqVQnHjixmysgSplQWM3FEIYUerskq4idd3VHW7mjjC2dO9DoKoEIgh5CdFWBCRRETKooO+Hws5mjp7Gbvvi52tnSyvTl+29rQwXt79rF43W56D7WMLs1ncmUxp0ws54wpFcwaV0Zuts5glszzzs5WwtGYL8YHQIVAjkIgMb5QXpTL9FEfPc7Z1R1lc30Hmxva2VLfwZaGDjbs3sfPnnuPm/8CBTlZnFRdxuzxiVt1GVUl+R78S0RSa0VtYqC4WoVAhrj8nCyOHzOM4/sMhrUEwyzb3MSyzY2sqG3m9iWbPxiLOG70MM49ropzjxvJzLGlOqNJhqQVtc1MSJyA4QcqBJJyZYW5nH/CKM4/YRQQ7zm8s7OVN7c28/yGvfzihY3c+vxGRhTnctoxFZw+qZzTJlUwtapYA9GS9pxzrKht4ZypI7yO8gEVAvFcfk4WcyaUM2dCOdfMm0xzR5jnN+xl6cYGlm1u5Mm3dwFQVphDzYThzJlQzikThzNrfBk5WRpjkPSyramThvaQb8YHIImFwMzuAi4E9jrnTkhsKwf+F5gIbAU+45xrTlYGSU/Di3K5bM44LpszDucc25o6Wba5keW1TSzf2sxf1u8FoDA3i1MmlnPmlArOmDyC40cP06Ek8b0VdU0A1EzMgEIA3APcBvy217brgeeccz8ys+sTj7+dxAyS5syM6opCqisK+cwp4wFobA/x5tYmXt3UyKubGvnhUxuAeI/h9GMqOHPqCBbOGKmBZ/GlFbXNlORlM7XPxa1eSlohcM4tMbOJfTZfDMxP3L8XeBEVAhmgiuI8zj9hNOefMBqIz9ny6qZGXtnYwKubGvnzO7v57p/WcuaUESyaPZaFJ4yiOE9HQcUfVtS2MLu6zFfzh6X6f8dI59wuAOfcLjM76OW8ZnY1cDVAdXV1iuJJOqoals+ik8ay6KSxOOd4f287f1q9gz+t3sm//n4N/+ePa/nkzFH89ZxxnH5MhQ4fiWfCkRjv7dnHx6ZP8jrKh/j2zyTn3O3A7QA1NTX+mgFOfMvMOHZkCdctnM43z5vGitpm/rBqB4+v2ckfVu5gbFkBXzhzIlecNoGCXO8v7ZfMsqOlk2jMccyIYq+jfEiqT7nYY2ajARI/96a4fckgZkbNxHJ+eMlM3rzhXG65/CTGlxfwgyfXc/Z/Ps+vX9pERyjidUzJILWNHQBMqCj0OMmHpbpH8BhwJfCjxM8/pbh9yVD5OVlcNGsMF80aw5tbm7jlufe56ekN/Py59zllYjmnT4pfrzBjTKmmvZCkqWsKAjChPEMKgZk9SHxgeISZbQe+S7wAPGRmVwF1wKeT1b7IwZwysZz7rjqNlXXNPLpyB69vaeQ//hw/8yg3K8C0USWcMLaUmWNLmTFmGNNGlXywaJHI0ahtDFKQk+WbK4p7JPOsocsP8tTHk9WmyECcXD38g7leGtpDvL65ibe2t/D2jlaefGsnD75RB8TXs5hcWcQpE8v5q1ljOHViuQac5YjUNnZQXV7ouyvkfTtYLJJKI4rz+NSJo/nUifFTUnsuZFu3q5V1O9tYu7ONR1Zu5/7X6xg1LJ9PnTiaj02vYs6E4eotSL/VNgaZOOLAs/l6SYVA5AB6X8jWc71CRyjCcxv28tjqnfz2ta3cuTS+xOkpE8uZd2wl558wivE+O/Yr/hGLOeqagsw7ttLrKB+hQiDST0V52R8MOHeEIryxpYmlGxtY+n4DNz61nhufWs+scaVcMHM0F8wcraIgH7J3X4hQJOa7M4ZAhUDkiBTlZbNgehULpseviaxrDPLU2l08+dYubnp6Azc9vYHZ48u48MTRXHjiGEaVarqLTLf/1FEdGhIZkqorCrlm3mSumTeZusYgT7y9kyfW7OIHT67nh0+tZ8G0Kv72tGrmT6vy1dQCkjq1PaeOqkcgMvRVVxTyT/On8E/zp7C5vp1HVm7noeXbee7e5YwpzeeK0yfwd6dNoLQwx+uokkJ1jUGyAsaYsgKvo3yErpwRSaJJlcVct3A6r17/Mf77ipM5prKIHz/zLnN/9Bzfe3wd25uDXkeUFNna2MHYsgJfrqGhHoFICuRkBfjkzNF8cuZo1u1s4zcvb+a3r23lt69t5YrTqvnaucdSXpTrdUxJorqmoC8PC4F6BCIpd/yYYdz82dks+dYCPnvKeO5bVsu8H7/Ar1/aRCgS9TqeJEltY5Bqn55JpkIg4pExZQXceMlMnvn6OdRMGM5NT2/g3P96iT+v3YVzmnB3KGkNdtPa2a0egYgc2NSRJdz9hVO576pTKczJ5prfreTy3yzjnZ2tXkeTQVLbFD91tLrcf6eOggqBiG+cPbWSJ689i+8vOoF3d+/jwluX8v0n1tHVrcNF6a620b+njoIKgYivZGcF+PvTJ/DidQu44rRq7ly6hU/d8jJrtrV4HU2OQp2PryEAFQIRXyotyOEHi2Zy31WnEgxHufS/X+Unz7xLOBLzOpocga0NHVSW5FGY688TNVUIRHzs7KmV/Pnr57Bo9lhue2EjF//iFdbtbPM6lgxQbVPQd4vR9KZCIOJzpQU5/PQzs/jN52qo3xfi4l8s5dbn3icSVe8gXdQ1Bqn26WEhUCEQSRufOH4kz/7LOSycMYqfPvsen/71a2xr0pXJftfVHWV3WxcTfHrGEKgQiKSV4UW53Pa3J3PL5SexcU87F/z8ZZ54a6fXseQQtvl8oBhUCETS0kWzxvDU185myshivvrAKr798Ft0hnWaqR/1nDqqQ0MiMujGlxfy0D/O5SsLJvPQim0s+sUrbNzb7nUs6eOD6ac1WCwiyZCTFeC6hdO59wun0tAe4qLblvLHVTu8jiUJHaEI//NGfJ1rP08qqEIgMgScc2wlT157NjPGDOPr/7ua7/zhbV2R7DHnHP/26NtsrG/nJ5+ehZl/FyRSIRAZIkaV5vPgl07nmnmTefCNOi7771epa9RZRV753bJa/rR6J98491jOmjrC6ziHpEIgMoRkZwW4/pPTueNzNWxrCnLhrS/z7Lo9XsfKOKu3tfC9J9axYFolX1kwxes4h6VCIDIEnXv8SJ689myqKwr50m+X8/0n1mmtgxTpDEf5yv0rGTksn5s/O5tAGqxRrUIgMkSNLy/k4WvO4Mq5E7hz6RYu/eWrbKrXWUXJ9uK7e9nR0smNl8ykrNC/A8S9qRCIDGH5OVn8+8UncMfnatjZ0smFtyzlgdfriMW08E2yLF63h+GFOZw5ucLrKP2mQiCSAc49fiRPf+0cTqou498efZtLfvkKq+qavY415HRHYzy3fg8fP24k2T5cpP5g0iepiByVUaX53P8Pp/Gzz85mV2sXl/zyVb75+zU0tIe8jjZkvL65ibauCAtnjPI6yoB4UgjM7GtmttbM3jGzr3uRQSQTmRmLThrL89+cz5fnT+ax1Ts57+YlPL5mp9ZJHgTPvLObgpwszvb56aJ9pbwQmNkJwJeAU4FZwIVmNjXVOUQyWXFeNt8+fzpPXnsW48sL+ecHV/Hl362kfp96B0cqFnM8u24P846tJD8ny+s4A+JFj+A4YJlzLuiciwAvAZd4kEMk400dWcIj18zl2+dP5/kNe/nEzS/xyIrt6h0cgbd2tLK7rYvzZoz0OsqAeVEI1gLnmFmFmRUCFwDjPcghIsQvQvvy/Mk89bWzmDSiiH/9/RquvPtNrXUwQIvf2U1WwPjY9CqvowxYyguBc2498B/As8CfgTVApO9+Zna1mS03s+X19fUpTimSeaZUlfDwNWfw7xfNYMXWJs67eQl3vLxZK6H10zPv7Ob0SeVpc+1Ab54MFjvn7nTOneycOwdoAt4/wD63O+dqnHM1lZWVqQ8pkoECAePKMyay+BvzmDu5gh88uZ4Lb13K8q1NXkfztY1729lU38F5x6fX2UI9vDprqCrxsxq4FHjQixwicmBjywq488oafv33c2jr7Oavf/Ua//rQGl2ZfACxmOPRVduB+HKi6Sjbo3YfMbMKoBv4inNOV7aI+IyZsXDGKM6eOoJbn9/InS9v4ZGV2zlrygj+fu4EPj69Kq0umjpaoUiUfV0RYs4Ri0FDe4gn397FY6t3sqOlk7mTKhhTVuB1zCNi6XB2QE1NjVu+fLnXMUQyWv2+EP/7Zh33v17HrtYujhlRxA0XHMfHj6vy9Vz7RyoWc6zZ3sIrGxt4ZWMjK+qaCUc+PF6SFTDOmjKCRSeNYeGMURTmevW39YGZ2QrnXM1h91MhEJGBiERjLF63h58sfpfN9R2cPXUE//fC4zl2ZInX0QbN1oYOvvXIW7yxJT42ctzoYZw5uYIJFYWYGQEz8nMCnHNsJSOK8zxOe3AqBCKSVN3RGPe9VsvP/vIeHeEoi2aP5SsLJjOpstjraEcsGnPc/coWfrL4XXKyAnxr4TQumDmaCh9/2R+KCoGIpERzR5jbXtjI/a/XEo7E+KtZY/jqgilMTZMeQjgS++AQ0DPv7GH9rjbOPa6KGy+Zychh+V7HOyoqBCKSUvX7Qtzx8mbuW1ZLMBxlwbRK/uHsSZwxucJ3Ywjd0RhL3qvnDyt38MK7ewmGo5jBzLGlXHXWMVw0a4zvMh8JFQIR8URTR5jfLavlt69tpaE9zPRRJXz+jIn81awxFOV5O5i6o6WTu5du4Y+rd9DQHqa8KJcLZo7irCmVzJ1UQWlhjqf5BpsKgYh4qqs7ymNrdnLX0i1s2L2PotwsLpo9lktOGsuEikIqinJTdvrptqYgv3xxEw+v2IZz8PHjqrjs5HHMn1ZFbvbQPQVWhUBEfME5x8q6Fh58o44n3tpJV3f8FEwzqCjK5cRxZSw6aSyfOG4kBbmDN2tn/b4QL71Xzwsb9vLMO7sJmPGZU8ZxzbzJjBteOGjt+JkKgYj4TltXN8s2NbJ3X4i9+0Lsae3ipffq2d3WRXFeNgtnjGLhjJGcNXXEgM/Jd86xftc+Fq/bzV/W72HtjjYAKkvy+NTM0fzjvEmMLk3PC76OVH8Lgb+ufhCRIW1Yfg7n9Vm9KxpzvL6lkT+u2sHTb+/mkZXbyc0OcMbkCuYfW8lpkyqYNrKEQODDg7fOObY1dbJqWzMrapt5fsNetjd3YgYnVw/nuoXTmHdsJcePHvaR18qHqUcgIr4RjsR4c2sTz63fy3Mb9lDbGJ8Ku7Qgh5Ory8jJCtAeirCvK8Ku1k4a2sMAFOZmMXdSBefNGMnHpo+ksiQ9z/sfbDo0JCJpb3tzkDe2NPHGliZW1bVgBiX52RTnZTOiOI9Z48s4uXo4x44szqh5j/pLh4ZEJO2NG17IuOGFXHryOK+jDGkqoSIiGU6FQEQkw6kQiIhkOBUCEZEMp0IgIpLhVAhERDKcCoGISIZTIRARyXBpcWWxmdUDtUAp0JrYfLj7PT9HAA1H0Gzv39nf5/tuO9Tjwc58JHmPNPOBtqVLZj98Lg6W8XDZ9Vk+9PP6LH/UBOdc5eHC45xLmxtwe3/v9/q5/Gjb6u/zfbcd6vFgZz6SvEea+SDb0iKzHz4X/fks+C2zPsv+y3y0n4vet3Q7NPT4AO733na0bfX3+b7bDvV4sDMfSd4Dbe9P5oP9OwbKi8x++Fz03abP8uHz9Od5fZaPUFocGjoaZrbc9WPSJT9R5uRLt7ygzKmSbpkHI2+69QiOxO1eBzgCypx86ZYXlDlV0i3zUecd8j0CERE5tEzoEYiIyCGoEIiIZDgVAhGRDJfRhcDMzjazX5nZHWb2qtd5+sPMAmZ2o5ndamZXep3ncMxsvpm9nHif53udp7/MrMjMVpjZhV5n6Q8zOy7xHj9sZl/2Ok9/mNkiM/uNmf3JzM7zOs/hmNkkM7vTzB72OsuhJD679ybe2yv685q0LQRmdpeZ7TWztX22n29m75rZRjO7/lC/wzn3snPuGuAJ4N5k5k1kO+rMwMXAWKAb2J6srIlcg5HXAe1APknOm8g2GJkBvg08lJyUHzZIn+X1ic/yZ4Ckn/o4SJn/6Jz7EvB54LNJjDtYeTc7565KZs6DGWD+S4GHE+/tRf1q4GivSPPqBpwDnAys7bUtC9gETAJygTXA8cBM4l/2vW9VvV73EDAsHTID1wP/mHjtw2mQN5B43Ujg/jR5j88F/ob4F9SF6ZA58ZqLgFeBv02XzInX/RQ4OY3yJvX/3SDk/w4wO7HPA/35/Wm7eL1zbomZTeyz+VRgo3NuM4CZ/Q9wsXPuJuCAXXwzqwZanXNtSYwLDE5mM9sOhBMPo8lLO3jvcUIzkJeMnL0N0nu8ACgi/p+q08yecs7F/Jw58XseAx4zsyeBB5KVN9HWYLzPBvwIeNo5t9Lveb00kPzEe97jgNX086hP2haCgxgLbOv1eDtw2mFecxVwd9ISHd5AM/8BuNXMzgaWJDPYQQwor5ldCiwEyoDbkhvtoAaU2Tl3A4CZfR5oSGYROISBvs/ziR8SyAOeSmqygxvoZ/mfife+Ss1sinPuV8kMdzKWJbkAAAQeSURBVAADfY8rgBuBk8zsO4mC4aWD5b8FuM3MPkU/p6EYaoXADrDtkFfMOee+m6Qs/TWgzM65IPHi5ZWB5v0D8eLlpQF/LgCcc/cMfpR+G+j7/CLwYrLC9NNAM99C/EvLKwPN2whck7w4A3bA/M65DuALA/lFaTtYfBDbgfG9Ho8DdnqUpb/SLXO65QVlTpV0y5xuefsatPxDrRC8CUw1s2PMLJf4gN9jHmc6nHTLnG55QZlTJd0yp1vevgYvf6pHvwdxFP1BYBf7T6O8KrH9AuA94qPpN3idM50zp1teZVbmoZI31fk16ZyISIYbaoeGRERkgFQIREQynAqBiEiGUyEQEclwKgQiIhlOhUBEJMOpEEhaMrP2FLd3h5kdP0i/K2pmq81srZk9bmZlh9m/zMz+aTDaFjkQXUcgacnM2p1zxYP4+7Kdc5HB+n2HaeuD7GZ2L/Cec+7GQ+w/EXjCOXdCKvJJ5lGPQIYMM6s0s0fM7M3E7czE9lPN7FUzW5X4OS2x/fNm9nszexxYbPHV1F60+CpfG8zs/sRUySS21yTut1t8lbg1ZrbMzEYmtk9OPH7TzL7Xz17La8RnkcTMis3sOTNbaWZvm9nFiX1+BExO9CJ+nNj3ukQ7b5nZvw/i2ygZSIVAhpKfAzc7504BLgPuSGzfAJzjnDsJ+H/AD3u9Zi5wpXPuY4nHJwFfJ74WwSTgzAO0UwQsc87NIj4V+Jd6tf/zRPuHnfzLzLKAj7N/fpgu4BLn3MnAAuCniUJ0PbDJOTfbOXedxZd1nEp8PvrZwBwzO+dw7YkczFCbhloy27nA8Yk/4gGGmVkJUArca2ZTiU8znNPrNc8655p6PX7DObcdwMxWAxOBpX3aCRNftQpgBfCJxP25wKLE/QeAnxwkZ0Gv370CeDax3YAfJr7UY8R7CiMP8PrzErdVicfFxAuDF+tTyBCgQiBDSQCY65zr7L3RzG4FXnDOXZI43v5ir6c7+vyOUK/7UQ78f6Tb7R9cO9g+h9LpnJttZqXEC8pXiM/LfwVQCcxxznWb2Vbiaz33ZcBNzrlfD7BdkQPSoSEZShYDX+15YGazE3dLgR2J+59PYvvLiB+SgviUwIfknGsFrgW+aWY5xHPuTRSBBcCExK77gJJeL30G+KKZ9Qw4jzWzqkH6N0gGUiGQdFVoZtt73b5B/Eu1JjGAuo79q0n9J3CTmb1CfMHvZPk68A0zewMYDbQe7gXOuVXEFx3/G+B+4vmXE+8dbEjs0wi8kjjd9MfOucXEDz29ZmZvAw/z4UIhMiA6fVRkkJhZIfHDPs7M/ga43Dl38eFeJ+I1jRGIDJ45xBcNN6AF+KLHeUT6RT0CEZEMpzECEZEMp0IgIpLhVAhERDKcCoGISIZTIRARyXAqBCIiGe7/A6oRqSVtdhoqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.781779</td>\n",
       "      <td>1.747722</td>\n",
       "      <td>0.478246</td>\n",
       "      <td>5.741511</td>\n",
       "      <td>0.312570</td>\n",
       "      <td>24:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.297791</td>\n",
       "      <td>1.373945</td>\n",
       "      <td>0.519854</td>\n",
       "      <td>3.950907</td>\n",
       "      <td>0.363953</td>\n",
       "      <td>24:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.007788</td>\n",
       "      <td>1.144678</td>\n",
       "      <td>0.546649</td>\n",
       "      <td>3.141430</td>\n",
       "      <td>0.405859</td>\n",
       "      <td>24:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.814164</td>\n",
       "      <td>1.010174</td>\n",
       "      <td>0.563252</td>\n",
       "      <td>2.746078</td>\n",
       "      <td>0.433127</td>\n",
       "      <td>24:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.722611</td>\n",
       "      <td>0.969637</td>\n",
       "      <td>0.568647</td>\n",
       "      <td>2.636986</td>\n",
       "      <td>0.442531</td>\n",
       "      <td>24:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-4, div=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('paracrawl_en_ga_5e_5e-4_v0.2_exp2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5e results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, sentence, vocab):\n",
    "    #model = torch.load('output/transformer.pth')\n",
    "#     lang_model = spacy.load('en')\n",
    "#     with open('data/processed/en/freq_list.pkl', 'rb') as f:\n",
    "#         en_freq_list = pickle.load(f)\n",
    "#     with open('data/processed/fr/freq_list.pkl', 'rb') as f:\n",
    "#         fr_freq_list = pickle.load(f)\n",
    "    #sentence = input('Please enter your english sentence: ')\n",
    "    #sentence = tokenize(sentence, en_freq_list, lang_model)\n",
    "    \n",
    "    model=model.eval()\n",
    "    \n",
    "    sentence=learn.dls.tokenizer[0][1].encodes(sentence)\n",
    "    sentence=learn.dls.numericalize[0].encodes(sentence)\n",
    "    \n",
    "    translated_sentence = [2] # xxbos\n",
    "    #translated_sentence = [fr_freq_list['[SOS]']]\n",
    "    i = 0\n",
    "    while int(translated_sentence[-1]) != 3 and i < 75:   # xxeos\n",
    "    #while int(translated_sentence[-1]) != fr_freq_list['[EOS]'] and i < 15:\n",
    "        #output = forward_model(model, sentence, translated_sentence).to('cuda')\n",
    "        output = forward_model(model, sentence, translated_sentence).cuda()\n",
    "        values, indices = torch.topk(output, 5)\n",
    "        translated_sentence.append(int(indices[-1][0]))\n",
    "        i+=1\n",
    "\n",
    "    detok_translated_sentence=detokenize(translated_sentence, vocab)\n",
    "    print(' '.join(detok_translated_sentence))\n",
    "    \n",
    "\n",
    "def forward_model(model, src, tgt):\n",
    "    src = torch.as_tensor(src).unsqueeze(0).long().cuda()\n",
    "    tgt = torch.as_tensor(tgt).unsqueeze(0).cuda()\n",
    "    tgt_mask = gen_nopeek_mask(tgt.shape[1]).cuda()\n",
    "    output = model.forward(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "\n",
    "    #return output.squeeze(0).to('cpu')\n",
    "    return output.squeeze(0).detach()\n",
    "\n",
    "\n",
    "# def tokenize(sentence, freq_list, lang_model):\n",
    "#     punctuation = ['(', ')', ':', '\"', ' ']\n",
    "\n",
    "#     sentence = sentence.lower()\n",
    "#     sentence = [tok.text for tok in lang_model.tokenizer(sentence) if tok.text not in punctuation]\n",
    "#     return [freq_list[word] if word in freq_list else freq_list['[OOV]'] for word in sentence]\n",
    "\n",
    "\n",
    "def detokenize(sentence, vocab):\n",
    "    #freq_list = {v: k for k, v in freq_list.items()}\n",
    "    return [vocab[token] for token in sentence]\n",
    "    #return [freq_list[token] for token in sentence]\n",
    "# def detokenize(sentence, freq_list):\n",
    "#     freq_list = {v: k for k, v in freq_list.items()}\n",
    "#     return [freq_list[token] for token in sentence]\n",
    "\n",
    "\n",
    "def gen_nopeek_mask(length):\n",
    "    mask = rearrange(torch.triu(torch.ones(length, length)) == 1, 'h w -> w h')\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos dia duit , conas a bhfuil tú ? xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"hello, how are you?\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos is féidir xxunk insint duit nuair a bhíonn an stáisiún bus le do thoil ? xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"Can you tell we where the bus station is please?\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxunk inné sé xxunk , ach amárach beidh an - grianmhar xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"Yesterday it rained, but tomorrow will be very sunny\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos bhí mé lá iontach , is é mo aistritheoir ag obair xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"I had a great day, my translator is working\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxunk sin scéal faoi conas a fuair mo ardaitheoir xxunk xxunk síos , mar sin xxunk mhaith liom a ghlacadh nóiméad ach suí ceart ann , xxunk beidh mé tú ar fad faoi conas a tháinig mé ar an xxunk úr xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"So this is a story all about how my lift got flip turned \\\n",
    "upside down, so I'd like to take a minute just sit right there, I'll you all about how I became the fresh prince\\\n",
    "of belair\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos madra xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"dog\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos cat cat xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"cat\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos crann xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"tree\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos foirgneamh xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"building\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos cathair xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"city\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos bhean xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"woman\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos fear xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"man\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos seacláid xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"chocolate\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos spásárthach xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"spaceship\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v0.1 - 5e Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.653487</td>\n",
       "      <td>1.684406</td>\n",
       "      <td>0.479604</td>\n",
       "      <td>5.389246</td>\n",
       "      <td>0.310178</td>\n",
       "      <td>24:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.302716</td>\n",
       "      <td>1.293889</td>\n",
       "      <td>0.524035</td>\n",
       "      <td>3.646941</td>\n",
       "      <td>0.370828</td>\n",
       "      <td>24:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.956889</td>\n",
       "      <td>1.114578</td>\n",
       "      <td>0.547175</td>\n",
       "      <td>3.048281</td>\n",
       "      <td>0.405713</td>\n",
       "      <td>24:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.745926</td>\n",
       "      <td>0.990513</td>\n",
       "      <td>0.564060</td>\n",
       "      <td>2.692616</td>\n",
       "      <td>0.432489</td>\n",
       "      <td>24:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.719075</td>\n",
       "      <td>0.947289</td>\n",
       "      <td>0.569523</td>\n",
       "      <td>2.578710</td>\n",
       "      <td>0.441353</td>\n",
       "      <td>24:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-4, div=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('paracrawl_en_ga_5e_5e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='paracrawl_en_ga_5e_5e-4_learner.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5e results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos dia duit , conas a bhfuil t ? xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"hello, how are you?\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos is fidir xxunk insint duit nuair a bhonn an stisin bus le do thoil ? xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"Can you tell we where the bus station is please?\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxunk inn xxunk s , ach beidh amrach a bheith an - xxunk xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"Yesterday it rained, but tomorrow will be very sunny\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos bh m l iontach , t mo aistritheoir ag obair xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"I had a great day, my translator is working\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxunk mar sin is seo an scal ar fad faoi conas a fuair mo ardaitheoir smeach xxunk sos , mar sin xxunk ba mhaith liom a ghlacadh nimad ach su ceart ann , xxunk m go mbainfidh t go lir faoi conas a thinig m an xxunk r xxunk xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"So this is a story all about how my lift got flip turned \\\n",
    "upside down, so I'd like to take a minute just sit right there, I'll you all about how I became the fresh prince\\\n",
    "of belair\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos madra xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"dog\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos cat cat xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"cat\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos crann xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"tree\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos foirgneamh xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"building\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos cathair na mart xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"city\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos bean xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"woman\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos fear xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"man\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos seaclid seaclid seaclid xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"chocolate\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos spsrthach spsrthach xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"spaceship\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20e Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>corpus_bleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.636746</td>\n",
       "      <td>1.624053</td>\n",
       "      <td>0.490452</td>\n",
       "      <td>5.073614</td>\n",
       "      <td>0.324452</td>\n",
       "      <td>22:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.260920</td>\n",
       "      <td>1.325647</td>\n",
       "      <td>0.520619</td>\n",
       "      <td>3.764619</td>\n",
       "      <td>0.366522</td>\n",
       "      <td>22:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.232290</td>\n",
       "      <td>1.289559</td>\n",
       "      <td>0.525144</td>\n",
       "      <td>3.631185</td>\n",
       "      <td>0.372480</td>\n",
       "      <td>23:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.171967</td>\n",
       "      <td>1.256577</td>\n",
       "      <td>0.530127</td>\n",
       "      <td>3.513375</td>\n",
       "      <td>0.378737</td>\n",
       "      <td>23:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.081539</td>\n",
       "      <td>1.233820</td>\n",
       "      <td>0.534953</td>\n",
       "      <td>3.434322</td>\n",
       "      <td>0.385957</td>\n",
       "      <td>22:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.021572</td>\n",
       "      <td>1.175043</td>\n",
       "      <td>0.540957</td>\n",
       "      <td>3.238282</td>\n",
       "      <td>0.395813</td>\n",
       "      <td>22:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.962378</td>\n",
       "      <td>1.145241</td>\n",
       "      <td>0.546696</td>\n",
       "      <td>3.143200</td>\n",
       "      <td>0.404170</td>\n",
       "      <td>23:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.893671</td>\n",
       "      <td>1.105928</td>\n",
       "      <td>0.551453</td>\n",
       "      <td>3.022028</td>\n",
       "      <td>0.412557</td>\n",
       "      <td>22:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.868382</td>\n",
       "      <td>1.097856</td>\n",
       "      <td>0.555033</td>\n",
       "      <td>2.997732</td>\n",
       "      <td>0.419388</td>\n",
       "      <td>22:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.788918</td>\n",
       "      <td>1.052471</td>\n",
       "      <td>0.559421</td>\n",
       "      <td>2.864722</td>\n",
       "      <td>0.425994</td>\n",
       "      <td>22:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.758427</td>\n",
       "      <td>1.036332</td>\n",
       "      <td>0.563508</td>\n",
       "      <td>2.818857</td>\n",
       "      <td>0.434115</td>\n",
       "      <td>22:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.669327</td>\n",
       "      <td>1.013294</td>\n",
       "      <td>0.567820</td>\n",
       "      <td>2.754659</td>\n",
       "      <td>0.441266</td>\n",
       "      <td>22:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.626715</td>\n",
       "      <td>0.991485</td>\n",
       "      <td>0.570923</td>\n",
       "      <td>2.695234</td>\n",
       "      <td>0.446708</td>\n",
       "      <td>23:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.566517</td>\n",
       "      <td>0.978313</td>\n",
       "      <td>0.574124</td>\n",
       "      <td>2.659965</td>\n",
       "      <td>0.452433</td>\n",
       "      <td>22:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.507054</td>\n",
       "      <td>0.965194</td>\n",
       "      <td>0.576859</td>\n",
       "      <td>2.625298</td>\n",
       "      <td>0.457781</td>\n",
       "      <td>22:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.447324</td>\n",
       "      <td>0.957567</td>\n",
       "      <td>0.578481</td>\n",
       "      <td>2.605351</td>\n",
       "      <td>0.461081</td>\n",
       "      <td>22:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.431767</td>\n",
       "      <td>0.949662</td>\n",
       "      <td>0.580543</td>\n",
       "      <td>2.584836</td>\n",
       "      <td>0.464802</td>\n",
       "      <td>23:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.389824</td>\n",
       "      <td>0.945533</td>\n",
       "      <td>0.581630</td>\n",
       "      <td>2.574185</td>\n",
       "      <td>0.467092</td>\n",
       "      <td>22:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.409436</td>\n",
       "      <td>0.943619</td>\n",
       "      <td>0.582277</td>\n",
       "      <td>2.569263</td>\n",
       "      <td>0.468281</td>\n",
       "      <td>22:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.389287</td>\n",
       "      <td>0.942813</td>\n",
       "      <td>0.582419</td>\n",
       "      <td>2.567193</td>\n",
       "      <td>0.468552</td>\n",
       "      <td>23:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20e, added shuffle to sorteddl, PT Transformer, distilbert init, Adam, distilbert init\n",
    "# CONCLUSION: \n",
    "learn.fit_one_cycle(20, 5e-4, div=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('paracrawl_en_ga_20e_5e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname='paracrawl_en_ga_20e_5e-4_learner.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, sentence, vocab):\n",
    "    #model = torch.load('output/transformer.pth')\n",
    "#     lang_model = spacy.load('en')\n",
    "#     with open('data/processed/en/freq_list.pkl', 'rb') as f:\n",
    "#         en_freq_list = pickle.load(f)\n",
    "#     with open('data/processed/fr/freq_list.pkl', 'rb') as f:\n",
    "#         fr_freq_list = pickle.load(f)\n",
    "    #sentence = input('Please enter your english sentence: ')\n",
    "    #sentence = tokenize(sentence, en_freq_list, lang_model)\n",
    "    \n",
    "    model=model.eval()\n",
    "    \n",
    "    sentence=learn.dls.tokenizer[0][1].encodes(sentence)\n",
    "    sentence=learn.dls.numericalize[0].encodes(sentence)\n",
    "    \n",
    "    translated_sentence = [2] # xxbos\n",
    "    #translated_sentence = [fr_freq_list['[SOS]']]\n",
    "    i = 0\n",
    "    while int(translated_sentence[-1]) != 3 and i < 75:   # xxeos\n",
    "    #while int(translated_sentence[-1]) != fr_freq_list['[EOS]'] and i < 15:\n",
    "        #output = forward_model(model, sentence, translated_sentence).to('cuda')\n",
    "        output = forward_model(model, sentence, translated_sentence).cuda()\n",
    "        values, indices = torch.topk(output, 5)\n",
    "        translated_sentence.append(int(indices[-1][0]))\n",
    "        i+=1\n",
    "\n",
    "    detok_translated_sentence=detokenize(translated_sentence, vocab)\n",
    "    print(' '.join(detok_translated_sentence))\n",
    "    \n",
    "\n",
    "def forward_model(model, src, tgt):\n",
    "    src = torch.as_tensor(src).unsqueeze(0).long().cuda()\n",
    "    tgt = torch.as_tensor(tgt).unsqueeze(0).cuda()\n",
    "    tgt_mask = gen_nopeek_mask(tgt.shape[1]).cuda()\n",
    "    output = model.forward(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "\n",
    "    #return output.squeeze(0).to('cpu')\n",
    "    return output.squeeze(0).detach()\n",
    "\n",
    "\n",
    "# def tokenize(sentence, freq_list, lang_model):\n",
    "#     punctuation = ['(', ')', ':', '\"', ' ']\n",
    "\n",
    "#     sentence = sentence.lower()\n",
    "#     sentence = [tok.text for tok in lang_model.tokenizer(sentence) if tok.text not in punctuation]\n",
    "#     return [freq_list[word] if word in freq_list else freq_list['[OOV]'] for word in sentence]\n",
    "\n",
    "\n",
    "def detokenize(sentence, vocab):\n",
    "    #freq_list = {v: k for k, v in freq_list.items()}\n",
    "    return [vocab[token] for token in sentence]\n",
    "    #return [freq_list[token] for token in sentence]\n",
    "# def detokenize(sentence, freq_list):\n",
    "#     freq_list = {v: k for k, v in freq_list.items()}\n",
    "#     return [freq_list[token] for token in sentence]\n",
    "\n",
    "\n",
    "def gen_nopeek_mask(length):\n",
    "    mask = rearrange(torch.triu(torch.ones(length, length)) == 1, 'h w -> w h')\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20e results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos dia duit , conas a bhfuil t ? xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"hello, how are you?\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxunk an fidir leat insint dinn c bhfuil an stisin bus le do thoil ? xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"Can you tell we where the bus station is please?\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxunk inn xxunk s , ach beidh amrach a bheith an - xxunk xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"Yesterday it rained, but tomorrow will be very sunny\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos bh m l mr , t mo aistritheoir ag obair xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"I had a great day, my translator is working\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxunk mar sin t an scal faoi conas a fuair mo ardaitheoir smeach xxunk sos , mar sin xxunk ba mhaith liom a ghlacadh nimad ach su ceart ann , xxunk beidh m go lir faoi conas a thinig m an xxunk r xxunk xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"So this is a story all about how my lift got flip turned \\\n",
    "upside down, so I'd like to take a minute just sit right there, I'll you all about how I became the fresh prince\\\n",
    "of belair\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos madra xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"dog\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos cat xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"cat\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos crann xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"tree\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos foirgneamh xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"building\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos cathair xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"city\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos bean xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"woman\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos fear xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"man\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos seaclid xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"chocolate\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos spsrthach xxeos\n"
     ]
    }
   ],
   "source": [
    "generate(learn.model, \"spaceship\", dls.vocab[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://forums.fast.ai/t/fastai-v2-text/53529/334\n",
    "from fastai2.text.all import *\n",
    "\n",
    "defaults.device = torch.device('cpu')\n",
    "path = Path('.')\n",
    "learner = load_learner(\"./export.pkl\")\n",
    "\n",
    "f = open(\"/tmp/test.txt\", \"r\")\n",
    "test_file_contents = f.read()\n",
    "\n",
    "_, _, losses = learner.predict(test_file_contents)\n",
    "cats = [learner.dls.categorize.decode(i) for i in range(len(losses))]\n",
    "\n",
    "predictions = sorted(\n",
    "    zip(cats, map(float, losses)),\n",
    "    key=lambda p: p[1],\n",
    "    reverse=True\n",
    ")\n",
    "print(predictions)\n",
    "\n",
    "# OR\n",
    "\n",
    "items = pd.read_csv(\"/tmp/test.txt\", sep = '\\t')\n",
    "test_dl = learner.dls.test_dl(items.values)\n",
    "\n",
    "learner.get_preds(dl=test_dl, with_decoded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
